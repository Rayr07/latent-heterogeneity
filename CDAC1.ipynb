{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPeR1fBGgReDPrbwotRQt2w"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"dLvne99tmug4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1757625644917,"user_tz":-330,"elapsed":24521,"user":{"displayName":"Rishika Ray","userId":"02079523635456342422"}},"outputId":"02b7ea11-21f6-47ee-8576-8e808eb2006a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting rdkit\n","  Downloading rdkit-2025.3.6-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n","Collecting padelpy\n","  Downloading padelpy-0.1.16-py3-none-any.whl.metadata (7.7 kB)\n","Requirement already satisfied: lightgbm in /usr/local/lib/python3.12/dist-packages (4.6.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n","Collecting scikit-optimize\n","  Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl.metadata (9.7 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rdkit) (2.0.2)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from rdkit) (11.3.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from lightgbm) (1.16.1)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n","Collecting pyaml>=16.9 (from scikit-optimize)\n","  Downloading pyaml-25.7.0-py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from scikit-optimize) (25.0)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.2)\n","Downloading rdkit-2025.3.6-cp312-cp312-manylinux_2_28_x86_64.whl (36.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.1/36.1 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading padelpy-0.1.16-py3-none-any.whl (20.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.9/20.9 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading scikit_optimize-0.10.2-py2.py3-none-any.whl (107 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.8/107.8 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pyaml-25.7.0-py3-none-any.whl (26 kB)\n","Installing collected packages: rdkit, pyaml, padelpy, scikit-optimize\n","Successfully installed padelpy-0.1.16 pyaml-25.7.0 rdkit-2025.3.6 scikit-optimize-0.10.2\n"]}],"source":["!pip install rdkit padelpy lightgbm scikit-learn scikit-optimize\n","\n","import pandas as pd\n","import numpy as np\n","from rdkit import Chem\n","from rdkit.Chem import Descriptors\n","from padelpy import padeldescriptor\n","from sklearn.model_selection import train_test_split, StratifiedKFold\n","from sklearn.feature_selection import mutual_info_classif, chi2\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.neural_network import MLPClassifier\n","from lightgbm import LGBMClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, confusion_matrix\n","\n"]},{"cell_type":"code","source":["import os\n","\n","!fusermount -u /content/drive\n","\n","!rm -rf /content/drive/*\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tQqMethaldmh","executionInfo":{"status":"ok","timestamp":1757625645174,"user_tz":-330,"elapsed":205,"user":{"displayName":"Rishika Ray","userId":"02079523635456342422"}},"outputId":"f8be3c36-2fbd-4b68-c718-e268e9b3ca8e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["fusermount: failed to unmount /content/drive: No such file or directory\n"]}]},{"cell_type":"code","source":["\n","import os, time\n","from google.colab import drive\n","drive.mount('/content/drive')\n","WORKDIR = \"/content/drive/MyDrive/moltox_project\"\n","os.makedirs(WORKDIR, exist_ok=True)\n","print(\"Working dir:\", WORKDIR)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8KeubhNExac3","executionInfo":{"status":"ok","timestamp":1757625679972,"user_tz":-330,"elapsed":34806,"user":{"displayName":"Rishika Ray","userId":"02079523635456342422"}},"outputId":"1d0ea4d9-2be3-4bf4-d816-877a31400f0a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Working dir: /content/drive/MyDrive/moltox_project\n"]}]},{"cell_type":"code","source":["\n","!pip install --quiet pubchempy requests tqdm\n","\n","\n","import importlib, sys\n","for pkg in (\"requests\",\"pubchempy\",\"tqdm\"):\n","    try:\n","        importlib.import_module(pkg)\n","        print(pkg, \"OK\")\n","    except Exception as e:\n","        print(pkg, \"FAILED:\", e)\n","        raise\n","\n","import requests\n","r = requests.get(\"http://rest.kegg.jp/list/drug\", timeout=30)\n","print(\"KEGG request status:\", r.status_code)\n","print(\"Sample lines:\", r.text.splitlines()[:3])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ce18ZgpHM_KT","executionInfo":{"status":"ok","timestamp":1757625685763,"user_tz":-330,"elapsed":5808,"user":{"displayName":"Rishika Ray","userId":"02079523635456342422"}},"outputId":"b4d0c455-4aaa-4287-8123-ae5d4a0e364c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["requests OK\n","pubchempy OK\n","tqdm OK\n","KEGG request status: 200\n","Sample lines: ['D00001\\tWater (JP18/USP); Purified water (JP18); Purified water in containers (JP18); Water, purified (USP); Sterile purified water in containers (JP18); Water for injection (JP18); Water for injection in containers (JP18); Sterile water (TN)', 'D00002\\tNadide (JAN/USAN/INN); Nicotinamide adenine dinucleotide', 'D00003\\tOxygen (JP18/USP)']\n"]}]},{"cell_type":"code","source":["import requests, pubchempy as pcp\n","from time import sleep\n","from tqdm import tqdm\n","\n","\n","r = requests.get(\"http://rest.kegg.jp/list/drug\", timeout=30)\n","lines = r.text.splitlines()\n","print(\"KEGG drugs lines:\", len(lines))\n","\n","\n","kegg_entries = []\n","for L in lines:\n","    try:\n","        kid, name = L.split(\"\\t\",1)\n","\n","        name = name.split(\";\")[0].split(\",\")[0].strip()\n","        kegg_entries.append((kid, name))\n","    except:\n","        pass\n","\n","print(\"Parsed KEGG drugs:\", len(kegg_entries))\n","\n","\n","KEGG_LIMIT = 2000\n","mapped = []\n","for i,(kid, name) in enumerate(tqdm(kegg_entries[:KEGG_LIMIT], desc=\"mapping KEGG->PubChem\")):\n","    try:\n","        comps = pcp.get_compounds(name, 'name')\n","        if comps:\n","            cid = comps[0].cid\n","            smi = comps[0].canonical_smiles\n","            mapped.append({'source':'KEGG','kegg_id':kid,'name':name,'CID':cid,'SMILES':smi})\n","    except Exception as e:\n","        pass\n","    sleep(0.12)\n","\n","df_kegg = pd.DataFrame(mapped)\n","print(\"Mapped KEGG entries:\", len(df_kegg))\n","df_kegg.to_csv(os.path.join(WORKDIR,\"kegg_mapped_pubchem.csv\"), index=False)\n","df_kegg.head()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":330},"id":"Jti751UsMsAa","executionInfo":{"status":"ok","timestamp":1757627419636,"user_tz":-330,"elapsed":1733878,"user":{"displayName":"Rishika Ray","userId":"02079523635456342422"}},"outputId":"57e02ddd-7efd-449a-b698-41749c62424f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["KEGG drugs lines: 12684\n","Parsed KEGG drugs: 12684\n"]},{"output_type":"stream","name":"stderr","text":["mapping KEGG->PubChem:   0%|          | 0/2000 [00:00<?, ?it/s]/tmp/ipython-input-3954121770.py:31: PubChemPyDeprecationWarning: canonical_smiles is deprecated: Use connectivity_smiles instead\n","  smi = comps[0].canonical_smiles\n","mapping KEGG->PubChem: 100%|██████████| 2000/2000 [28:51<00:00,  1.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Mapped KEGG entries: 1636\n"]},{"output_type":"execute_result","data":{"text/plain":["  source kegg_id                               name     CID  \\\n","0   KEGG  D00001                   Water (JP18/USP)     962   \n","1   KEGG  D00002              Nadide (JAN/USAN/INN)    5893   \n","2   KEGG  D00003                  Oxygen (JP18/USP)     977   \n","3   KEGG  D00004          Carbon dioxide (JP18/USP)     280   \n","4   KEGG  D00005  Flavin adenine dinucleotide (JAN)  643975   \n","\n","                                              SMILES  \n","0                                                  O  \n","1  C1=CC(=C[N+](=C1)C2C(C(C(O2)COP(=O)(O)OP(=O)(O...  \n","2                                                O=O  \n","3                                            C(=O)=O  \n","4  CC1=CC2=C(C=C1C)N(C3=NC(=O)NC(=O)C3=N2)CC(C(C(...  "],"text/html":["\n","  <div id=\"df-400c4f71-d91b-4283-bd6b-d20e838ef724\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>source</th>\n","      <th>kegg_id</th>\n","      <th>name</th>\n","      <th>CID</th>\n","      <th>SMILES</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>KEGG</td>\n","      <td>D00001</td>\n","      <td>Water (JP18/USP)</td>\n","      <td>962</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>KEGG</td>\n","      <td>D00002</td>\n","      <td>Nadide (JAN/USAN/INN)</td>\n","      <td>5893</td>\n","      <td>C1=CC(=C[N+](=C1)C2C(C(C(O2)COP(=O)(O)OP(=O)(O...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>KEGG</td>\n","      <td>D00003</td>\n","      <td>Oxygen (JP18/USP)</td>\n","      <td>977</td>\n","      <td>O=O</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>KEGG</td>\n","      <td>D00004</td>\n","      <td>Carbon dioxide (JP18/USP)</td>\n","      <td>280</td>\n","      <td>C(=O)=O</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>KEGG</td>\n","      <td>D00005</td>\n","      <td>Flavin adenine dinucleotide (JAN)</td>\n","      <td>643975</td>\n","      <td>CC1=CC2=C(C=C1C)N(C3=NC(=O)NC(=O)C3=N2)CC(C(C(...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-400c4f71-d91b-4283-bd6b-d20e838ef724')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-400c4f71-d91b-4283-bd6b-d20e838ef724 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-400c4f71-d91b-4283-bd6b-d20e838ef724');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-fa3feb72-60c8-455c-afe0-96d3703fb77c\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fa3feb72-60c8-455c-afe0-96d3703fb77c')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-fa3feb72-60c8-455c-afe0-96d3703fb77c button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df_kegg","summary":"{\n  \"name\": \"df_kegg\",\n  \"rows\": 1636,\n  \"fields\": [\n    {\n      \"column\": \"source\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"KEGG\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"kegg_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1636,\n        \"samples\": [\n          \"D00807\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1636,\n        \"samples\": [\n          \"Piperazine (USP)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 18855198,\n        \"min\": 119,\n        \"max\": 171904541,\n        \"num_unique_values\": 1633,\n        \"samples\": [\n          5853\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SMILES\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1624,\n        \"samples\": [\n          \"C(C(C(=O)O)N)SCC(=O)O\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["from google.colab import files\n","import os, pandas as pd\n","from rdkit import Chem\n","\n","WORKDIR = \"/content/drive/MyDrive/moltox_project\"\n","os.makedirs(WORKDIR, exist_ok=True)\n","\n","uploaded = files.upload()\n","fname = list(uploaded.keys())[0]\n","\n","\n","suppl = Chem.SDMolSupplier(fname)\n","smiles = []\n","for m in suppl:\n","    if m is None:\n","        continue\n","    try:\n","        s = Chem.MolToSmiles(m, isomericSmiles=True)\n","        atoms = [a.GetSymbol() for a in m.GetAtoms()]\n","        if 'C' in atoms:\n","            smiles.append(s)\n","    except:\n","        pass\n","\n","\n","smiles = list(dict.fromkeys(smiles))\n","print(\"Extracted toxic SMILES from SDF:\", len(smiles))\n","\n","df_tox = pd.DataFrame({'SMILES_can': smiles, 'label': 1})\n","out = os.path.join(WORKDIR, \"t3db_canon_from_sdf.csv\")\n","df_tox.to_csv(out, index=False)\n","print(\"Saved to\", out)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":958},"id":"j-_wo5odXt-G","executionInfo":{"status":"ok","timestamp":1757627601462,"user_tz":-330,"elapsed":181817,"user":{"displayName":"Rishika Ray","userId":"02079523635456342422"}},"outputId":"22e7433c-3bef-4196-b166-32ce7832a113"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-111e4a39-3212-4fad-bf62-1af169d2882e\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-111e4a39-3212-4fad-bf62-1af169d2882e\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving structures.sdf to structures.sdf\n"]},{"output_type":"stream","name":"stderr","text":["[21:53:19] Explicit valence for atom # 1 N, 3, is greater than permitted\n","[21:53:19] ERROR: Could not sanitize molecule ending on line 3111\n","[21:53:19] ERROR: Explicit valence for atom # 1 N, 3, is greater than permitted\n","[21:53:20] WARNING: not removing hydrogen atom without neighbors\n","[21:53:20] WARNING: not removing hydrogen atom without neighbors\n","[21:53:20] Explicit valence for atom # 0 Ar, 1, is greater than permitted\n","[21:53:20] ERROR: Could not sanitize molecule ending on line 83908\n","[21:53:20] ERROR: Explicit valence for atom # 0 Ar, 1, is greater than permitted\n","[21:53:20] WARNING: not removing hydrogen atom without neighbors\n","[21:53:20] WARNING: not removing hydrogen atom without neighbors\n","[21:53:20] WARNING: not removing hydrogen atom without neighbors\n","[21:53:20] Explicit valence for atom # 0 O, 3, is greater than permitted\n","[21:53:20] ERROR: Could not sanitize molecule ending on line 153360\n","[21:53:20] ERROR: Explicit valence for atom # 0 O, 3, is greater than permitted\n","[21:53:20] Explicit valence for atom # 7 O, 3, is greater than permitted\n","[21:53:20] ERROR: Could not sanitize molecule ending on line 157184\n","[21:53:20] ERROR: Explicit valence for atom # 7 O, 3, is greater than permitted\n","[21:53:20] Explicit valence for atom # 6 Al, 6, is greater than permitted\n","[21:53:20] ERROR: Could not sanitize molecule ending on line 158685\n","[21:53:20] ERROR: Explicit valence for atom # 6 Al, 6, is greater than permitted\n","[21:53:20] Explicit valence for atom # 2 Al, 4, is greater than permitted\n","[21:53:20] ERROR: Could not sanitize molecule ending on line 164877\n","[21:53:20] ERROR: Explicit valence for atom # 2 Al, 4, is greater than permitted\n","[21:53:20] Explicit valence for atom # 2 Br greater than permitted\n","[21:53:20] ERROR: Could not sanitize molecule ending on line 164993\n","[21:53:20] ERROR: Explicit valence for atom # 2 Br greater than permitted\n","[21:53:20] Explicit valence for atom # 9 C, 5, is greater than permitted\n","[21:53:20] ERROR: Could not sanitize molecule ending on line 169121\n","[21:53:20] ERROR: Explicit valence for atom # 9 C, 5, is greater than permitted\n","[21:53:20] Warning: ambiguous stereochemistry - opposing bonds have opposite wedging - at atom 1 ignored.\n","[21:53:20] Warning: ambiguous stereochemistry - opposing bonds have opposite wedging - at atom 1 ignored.\n","[21:53:20] Warning: ambiguous stereochemistry - opposing bonds have opposite wedging - at atom 1 ignored.\n","[21:53:20] Warning: ambiguous stereochemistry - opposing bonds have opposite wedging - at atom 1 ignored.\n","[21:53:20] Explicit valence for atom # 1 F, 2, is greater than permitted\n","[21:53:20] ERROR: Could not sanitize molecule ending on line 172312\n","[21:53:20] ERROR: Explicit valence for atom # 1 F, 2, is greater than permitted\n","[21:53:20] Explicit valence for atom # 0 Br, 1, is greater than permitted\n","[21:53:20] ERROR: Could not sanitize molecule ending on line 186086\n","[21:53:20] ERROR: Explicit valence for atom # 0 Br, 1, is greater than permitted\n","[21:53:20] Explicit valence for atom # 1 Br, 5, is greater than permitted\n","[21:53:20] ERROR: Could not sanitize molecule ending on line 193908\n","[21:53:20] ERROR: Explicit valence for atom # 1 Br, 5, is greater than permitted\n","[21:53:20] Explicit valence for atom # 1 Br, 3, is greater than permitted\n","[21:53:20] ERROR: Could not sanitize molecule ending on line 194011\n","[21:53:20] ERROR: Explicit valence for atom # 1 Br, 3, is greater than permitted\n","[21:53:20] Explicit valence for atom # 4 Sb, 8, is greater than permitted\n","[21:53:20] ERROR: Could not sanitize molecule ending on line 202305\n","[21:53:20] ERROR: Explicit valence for atom # 4 Sb, 8, is greater than permitted\n","[21:53:20] Warning: ambiguous stereochemistry - overlapping neighbors  - at atom 16 ignored\n"]},{"output_type":"stream","name":"stdout","text":["Extracted toxic SMILES from SDF: 2902\n","Saved to /content/drive/MyDrive/moltox_project/t3db_canon_from_sdf.csv\n"]}]},{"cell_type":"code","source":["\n","import os, pandas as pd\n","from rdkit import Chem\n","from rdkit import RDLogger\n","RDLogger.DisableLog('rdApp.*')\n","\n","WORKDIR = os.getenv(\"WORKDIR\", \"/content/drive/MyDrive/moltox_project\")\n","os.makedirs(WORKDIR, exist_ok=True)\n","\n","kegg_path = os.path.join(WORKDIR, \"kegg_mapped_pubchem.csv\")\n","pub_tox_path = os.path.join(WORKDIR, \"tox_pubchem_smiles.csv\")\n","t3_csv = os.path.join(WORKDIR, \"t3db_canon_from_csv.csv\")\n","t3_sdf = os.path.join(WORKDIR, \"t3db_canon_from_sdf.csv\")\n","\n","\n","if os.path.exists(kegg_path):\n","    df_non = pd.read_csv(kegg_path, low_memory=False)\n","\n","    if 'SMILES' in df_non.columns and 'SMILES_can' not in df_non.columns:\n","        df_non['SMILES_can'] = df_non['SMILES']\n","else:\n","    print(\"WARNING: KEGG file not found at\", kegg_path)\n","    df_non = pd.DataFrame(columns=['SMILES_can'])\n","\n","\n","if os.path.exists(pub_tox_path):\n","    df_tox_pub = pd.read_csv(pub_tox_path, low_memory=False)\n","    if 'SMILES' in df_tox_pub.columns and 'SMILES_can' not in df_tox_pub.columns:\n","        df_tox_pub['SMILES_can'] = df_tox_pub['SMILES']\n","else:\n","    df_tox_pub = pd.DataFrame(columns=['SMILES_can'])\n","\n","if os.path.exists(t3_csv):\n","    df_t3 = pd.read_csv(t3_csv, low_memory=False)\n","    if 'SMILES_can' not in df_t3.columns and 'SMILES' in df_t3.columns:\n","        df_t3['SMILES_can'] = df_t3['SMILES']\n","elif os.path.exists(t3_sdf):\n","    df_t3 = pd.read_csv(t3_sdf, low_memory=False)\n","    if 'SMILES_can' not in df_t3.columns and 'SMILES' in df_t3.columns:\n","        df_t3['SMILES_can'] = df_t3['SMILES']\n","else:\n","    df_t3 = pd.DataFrame(columns=['SMILES_can'])\n","\n","def canonicalize_and_filter_series(series):\n","    out = []\n","    for s in series.dropna().astype(str):\n","        m = Chem.MolFromSmiles(s)\n","        if m is None:\n","            continue\n","        atoms = [a.GetSymbol() for a in m.GetAtoms()]\n","        if 'C' not in atoms and 'c' not in atoms:\n","            continue\n","        out.append(Chem.MolToSmiles(m, isomericSmiles=True))\n","    # unique preserve order\n","    seen = set()\n","    unique = []\n","    for x in out:\n","        if x not in seen:\n","            seen.add(x)\n","            unique.append(x)\n","    return unique\n","\n","\n","print(\"Canonicalizing sources...\")\n","non_smiles = []\n","if 'SMILES_can' in df_non.columns:\n","    non_smiles = canonicalize_and_filter_series(df_non['SMILES_can'])\n","    df_non_clean = pd.DataFrame({'SMILES_can': non_smiles, 'label': 0})\n","else:\n","    df_non_clean = pd.DataFrame(columns=['SMILES_can','label'])\n","\n","tox_pub_smiles = []\n","if 'SMILES_can' in df_tox_pub.columns:\n","    tox_pub_smiles = canonicalize_and_filter_series(df_tox_pub['SMILES_can'])\n","    df_tox_pub_clean = pd.DataFrame({'SMILES_can': tox_pub_smiles, 'label': 1})\n","else:\n","    df_tox_pub_clean = pd.DataFrame(columns=['SMILES_can','label'])\n","\n","t3_smiles = []\n","if 'SMILES_can' in df_t3.columns:\n","    t3_smiles = canonicalize_and_filter_series(df_t3['SMILES_can'])\n","    df_t3_clean = pd.DataFrame({'SMILES_can': t3_smiles, 'label': 1})\n","else:\n","    df_t3_clean = pd.DataFrame(columns=['SMILES_can','label'])\n","\n","\n","df_toxic = pd.concat([df_tox_pub_clean, df_t3_clean], ignore_index=True).drop_duplicates(subset=['SMILES_can']).reset_index(drop=True)\n","df_non_toxic = df_non_clean.drop_duplicates(subset=['SMILES_can']).reset_index(drop=True)\n","\n","print(\"Counts -> KEGG non-toxic:\", len(df_non_toxic), \"PubChem toxic:\", len(df_tox_pub_clean), \"T3DB:\", len(df_t3_clean))\n","combined = pd.concat([df_toxic[['SMILES_can','label']], df_non_toxic[['SMILES_can','label']]], ignore_index=True)\n","combined = combined.drop_duplicates(subset=['SMILES_can']).reset_index(drop=True)\n","print(\"Combined dataset size:\", len(combined))\n","\n","outpath = os.path.join(WORKDIR, \"moltox_raw_combined.csv\")\n","combined.to_csv(outpath, index=False)\n","print(\"Saved combined file to:\", outpath)\n","combined.head(10)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":432},"id":"KisXw2mWT09W","executionInfo":{"status":"ok","timestamp":1757627603424,"user_tz":-330,"elapsed":1951,"user":{"displayName":"Rishika Ray","userId":"02079523635456342422"}},"outputId":"faf196f1-3af1-4062-c2ec-b9cb12f7f5f7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Canonicalizing sources...\n","Counts -> KEGG non-toxic: 1595 PubChem toxic: 0 T3DB: 0\n","Combined dataset size: 1595\n","Saved combined file to: /content/drive/MyDrive/moltox_project/moltox_raw_combined.csv\n"]},{"output_type":"execute_result","data":{"text/plain":["                                          SMILES_can  label\n","0  NC(=O)c1ccc[n+](C2OC(COP(=O)(O)OP(=O)(O)OCC3OC...      0\n","1                                              O=C=O      0\n","2  Cc1cc2nc3c(=O)[nH]c(=O)nc-3n(CC(O)C(O)C(O)COP(...      0\n","3                                 NC(CCC(=O)O)C(=O)O      0\n","4                                            CC(=O)O      0\n","5                                           NCC(=O)O      0\n","6                                        CC(N)C(=O)O      0\n","7                                  NC(CC(=O)O)C(=O)O      0\n","8               NC(CCC(=O)NC(CS)C(=O)NCC(=O)O)C(=O)O      0\n","9                                 NC(=O)CCC(N)C(=O)O      0"],"text/html":["\n","  <div id=\"df-fc516bfa-301a-4bc7-a096-b245234663ba\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>SMILES_can</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>NC(=O)c1ccc[n+](C2OC(COP(=O)(O)OP(=O)(O)OCC3OC...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>O=C=O</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Cc1cc2nc3c(=O)[nH]c(=O)nc-3n(CC(O)C(O)C(O)COP(...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>NC(CCC(=O)O)C(=O)O</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>CC(=O)O</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>NCC(=O)O</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>CC(N)C(=O)O</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>NC(CC(=O)O)C(=O)O</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>NC(CCC(=O)NC(CS)C(=O)NCC(=O)O)C(=O)O</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>NC(=O)CCC(N)C(=O)O</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fc516bfa-301a-4bc7-a096-b245234663ba')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-fc516bfa-301a-4bc7-a096-b245234663ba button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-fc516bfa-301a-4bc7-a096-b245234663ba');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-4aac8e68-eed5-42b2-86e8-3ae5b7d57d1d\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4aac8e68-eed5-42b2-86e8-3ae5b7d57d1d')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-4aac8e68-eed5-42b2-86e8-3ae5b7d57d1d button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"combined","summary":"{\n  \"name\": \"combined\",\n  \"rows\": 1595,\n  \"fields\": [\n    {\n      \"column\": \"SMILES_can\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1595,\n        \"samples\": [\n          \"COc1cc(NS(=O)(=O)c2ccc(N)cc2)ncn1\",\n          \"CC(=O)OCC(=O)C1(O)C(C)CC2C3CCC4=CC(=O)C=CC4(C)C3(F)C(O)CC21C\",\n          \"CN1CCN(C2=Nc3ccccc3Sc3ccc(Cl)cc32)CC1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["import os, pandas as pd\n","\n","WORKDIR = \"/content/drive/MyDrive/moltox_project\"\n","\n","\n","df_kegg = pd.read_csv(os.path.join(WORKDIR, \"kegg_mapped_pubchem.csv\"))\n","if 'SMILES' in df_kegg.columns and 'SMILES_can' not in df_kegg.columns:\n","    df_kegg['SMILES_can'] = df_kegg['SMILES']\n","df_kegg = df_kegg[['SMILES_can']].dropna().drop_duplicates()\n","df_kegg['label'] = 0\n","print(\"KEGG molecules:\", df_kegg.shape)\n","\n","df_tox = pd.read_csv(os.path.join(WORKDIR, \"t3db_canon_from_sdf.csv\"))\n","print(\"T3DB molecules:\", df_tox.shape)\n","\n","\n","df_all = pd.concat([df_kegg, df_tox], ignore_index=True).drop_duplicates(subset=['SMILES_can'])\n","print(\"Combined molecules:\", df_all.shape)\n","print(\"Label distribution:\", df_all['label'].value_counts())\n","\n","outpath = os.path.join(WORKDIR, \"moltox_raw_combined.csv\")\n","df_all.to_csv(outpath, index=False)\n","print(\"Saved combined dataset to\", outpath)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FYvVL1aiZLwP","executionInfo":{"status":"ok","timestamp":1757627603548,"user_tz":-330,"elapsed":112,"user":{"displayName":"Rishika Ray","userId":"02079523635456342422"}},"outputId":"26c836df-cece-4426-d633-f9295c4c2a13"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["KEGG molecules: (1624, 2)\n","T3DB molecules: (2902, 2)\n","Combined molecules: (4518, 2)\n","Label distribution: label\n","1    2894\n","0    1624\n","Name: count, dtype: int64\n","Saved combined dataset to /content/drive/MyDrive/moltox_project/moltox_raw_combined.csv\n"]}]},{"cell_type":"code","source":["\n","import os, pandas as pd\n","from rdkit import Chem\n","from rdkit.Chem import AllChem, DataStructs\n","from tqdm import tqdm\n","\n","WORKDIR = os.getenv(\"WORKDIR\", \"/content/drive/MyDrive/moltox_project\")\n","inp = os.path.join(WORKDIR, \"moltox_raw_combined.csv\")\n","if not os.path.exists(inp):\n","    raise FileNotFoundError(f\"{inp} not found — run previous combine cell first.\")\n","\n","df = pd.read_csv(inp, low_memory=False)\n","smiles = df['SMILES_can'].astype(str).tolist()\n","\n","print(\"Computing Morgan fingerprints...\")\n","fps = []\n","for s in tqdm(smiles, desc=\"FPs\"):\n","    m = Chem.MolFromSmiles(s)\n","    if m is None:\n","        fps.append(None)\n","    else:\n","        fps.append(AllChem.GetMorganFingerprintAsBitVect(m, 2, nBits=2048))\n","\n","n = len(fps)\n","keep = []\n","seen = set()\n","for i in tqdm(range(n), desc=\"Deduping by Tanimoto\"):\n","    if i in seen:\n","        continue\n","    fi = fps[i]\n","\n","    keep.append(i)\n","    if fi is None:\n","        continue\n","    for j in range(i+1, n):\n","        if j in seen:\n","            continue\n","        fj = fps[j]\n","        if fj is None:\n","            continue\n","        if DataStructs.TanimotoSimilarity(fi, fj) > 0.95:\n","            seen.add(j)\n","\n","df_dedupe = df.iloc[keep].reset_index(drop=True)\n","outpath = os.path.join(WORKDIR, \"moltox_dedup_t95.csv\")\n","df_dedupe.to_csv(outpath, index=False)\n","print(\"Deduped: from\", len(df), \"->\", len(df_dedupe), \"rows. Saved to:\", outpath)\n","df_dedupe.head()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":275},"id":"ZvGhoS_7T9n-","executionInfo":{"status":"ok","timestamp":1757627627459,"user_tz":-330,"elapsed":23892,"user":{"displayName":"Rishika Ray","userId":"02079523635456342422"}},"outputId":"ee527e89-abfc-47ce-80f1-e43a8ca273fa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Computing Morgan fingerprints...\n"]},{"output_type":"stream","name":"stderr","text":["FPs: 100%|██████████| 4518/4518 [00:00<00:00, 5183.99it/s]\n","Deduping by Tanimoto: 100%|██████████| 4518/4518 [00:22<00:00, 202.73it/s] \n"]},{"output_type":"stream","name":"stdout","text":["Deduped: from 4518 -> 4062 rows. Saved to: /content/drive/MyDrive/moltox_project/moltox_dedup_t95.csv\n"]},{"output_type":"execute_result","data":{"text/plain":["                                          SMILES_can  label\n","0                                                  O      0\n","1  C1=CC(=C[N+](=C1)C2C(C(C(O2)COP(=O)(O)OP(=O)(O...      0\n","2                                                O=O      0\n","3                                            C(=O)=O      0\n","4  CC1=CC2=C(C=C1C)N(C3=NC(=O)NC(=O)C3=N2)CC(C(C(...      0"],"text/html":["\n","  <div id=\"df-766db2f7-b47d-49e3-b6df-6f524c2522ae\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>SMILES_can</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>O</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>C1=CC(=C[N+](=C1)C2C(C(C(O2)COP(=O)(O)OP(=O)(O...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>O=O</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>C(=O)=O</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>CC1=CC2=C(C=C1C)N(C3=NC(=O)NC(=O)C3=N2)CC(C(C(...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-766db2f7-b47d-49e3-b6df-6f524c2522ae')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-766db2f7-b47d-49e3-b6df-6f524c2522ae button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-766db2f7-b47d-49e3-b6df-6f524c2522ae');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-c4912562-4549-4db4-ae22-d7ed62ec133f\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c4912562-4549-4db4-ae22-d7ed62ec133f')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-c4912562-4549-4db4-ae22-d7ed62ec133f button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df_dedupe","summary":"{\n  \"name\": \"df_dedupe\",\n  \"rows\": 4062,\n  \"fields\": [\n    {\n      \"column\": \"SMILES_can\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4062,\n        \"samples\": [\n          \"CC1CCCC(O)CCCCCc2cc(O)cc(O)c2C(=O)O1\",\n          \"CC(C)(O)C#N\",\n          \"O=C1C=C2C[C@@H](C(=O)O)NC2=CC1=O\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["\n","import os, pandas as pd, numpy as np\n","from rdkit import Chem\n","from rdkit.Chem import Descriptors, AllChem\n","from rdkit.Chem import MACCSkeys\n","from rdkit import RDLogger\n","from tqdm import tqdm\n","RDLogger.DisableLog('rdApp.*')\n","\n","WORKDIR = os.getenv(\"WORKDIR\", \"/content/drive/MyDrive/moltox_project\")\n","inp = os.path.join(WORKDIR, \"moltox_dedup_t95.csv\")\n","if not os.path.exists(inp):\n","    raise FileNotFoundError(f\"{inp} not found — run previous cell first.\")\n","\n","df = pd.read_csv(inp, low_memory=False)\n","smiles = df['SMILES_can'].astype(str).tolist()\n","\n","\n","desc_list = Descriptors._descList\n","desc_names = [name for name, _ in desc_list]\n","print(\"Computing\", len(desc_names), \"RDKit descriptors...\")\n","\n","desc_vals = []\n","mols = []\n","for s in tqdm(smiles, desc=\"Descriptors\"):\n","    m = Chem.MolFromSmiles(s)\n","    mols.append(m)\n","    vals = []\n","    for name, func in desc_list:\n","        try:\n","            vals.append(func(m))\n","        except Exception:\n","            vals.append(np.nan)\n","    desc_vals.append(vals)\n","df_desc = pd.DataFrame(desc_vals, columns=desc_names)\n","\n","\n","print(\"Computing fingerprints (MACCS + Morgan 2048)...\")\n","fps_morgan = []\n","fps_maccs = []\n","for m in tqdm(mols, desc=\"Fingerprints\"):\n","    if m is None:\n","        fps_morgan.append(None)\n","        fps_maccs.append(None)\n","        continue\n","    fps_morgan.append(AllChem.GetMorganFingerprintAsBitVect(m, 2, nBits=2048))\n","    try:\n","        fps_maccs.append(MACCSkeys.GenMACCSKeys(m))\n","    except Exception:\n","        fps_maccs.append(None)\n","y\n","from rdkit import DataStructs\n","def bitvect_to_numpy(bv):\n","    if bv is None:\n","        return np.zeros((bv.GetNumBits() if bv is not None else 2048,), dtype=int)\n","    arr = np.zeros((bv.GetNumBits(),), dtype=int)\n","    DataStructs.ConvertToNumpyArray(bv, arr)\n","    return arr\n","\n","X_morgan = np.vstack([bitvect_to_numpy(x) for x in fps_morgan])\n","\n","maccs_len = 167\n","X_maccs = np.vstack([bitvect_to_numpy(x)[:maccs_len] if x is not None else np.zeros((maccs_len,), dtype=int) for x in fps_maccs])\n","\n","\n","df_fp_morgan = pd.DataFrame(X_morgan, columns=[f\"morg_{i}\" for i in range(X_morgan.shape[1])])\n","df_fp_maccs = pd.DataFrame(X_maccs, columns=[f\"maccs_{i}\" for i in range(X_maccs.shape[1])])\n","\n","\n","X = pd.concat([df_desc.reset_index(drop=True), df_fp_maccs.reset_index(drop=True), df_fp_morgan.reset_index(drop=True)], axis=1)\n","y = df['label'].values\n","\n","\n","X.to_parquet(os.path.join(WORKDIR, \"features_raw.parquet\"), index=False)\n","pd.DataFrame({'SMILES_can': df['SMILES_can'], 'label': df['label']}).to_csv(os.path.join(WORKDIR, \"smiles_labels.csv\"), index=False)\n","print(\"Saved features_raw.parquet and smiles_labels.csv. Feature shape:\", X.shape)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K0FtUKCHUB4c","executionInfo":{"status":"ok","timestamp":1757627673167,"user_tz":-330,"elapsed":45700,"user":{"displayName":"Rishika Ray","userId":"02079523635456342422"}},"outputId":"a4d2a846-6760-4b31-ee72-d40b71faa538"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Computing 217 RDKit descriptors...\n"]},{"output_type":"stream","name":"stderr","text":["Descriptors: 100%|██████████| 4062/4062 [00:40<00:00, 101.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Computing fingerprints (MACCS + Morgan 2048)...\n"]},{"output_type":"stream","name":"stderr","text":["Fingerprints: 100%|██████████| 4062/4062 [00:02<00:00, 1586.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Saved features_raw.parquet and smiles_labels.csv. Feature shape: (4062, 2432)\n"]}]},{"cell_type":"code","source":["import pandas as pd, os\n","\n","WORKDIR = \"/content/drive/MyDrive/moltox_project\"\n","df_check = pd.read_csv(os.path.join(WORKDIR, \"moltox_dedup_t95.csv\"))\n","print(\"Shape:\", df_check.shape)\n","print(\"Columns:\", df_check.columns.tolist())\n","print(df_check.head(20))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t1la3pPyal2l","executionInfo":{"status":"ok","timestamp":1757627673276,"user_tz":-330,"elapsed":41,"user":{"displayName":"Rishika Ray","userId":"02079523635456342422"}},"outputId":"40169dca-753b-4f88-d76f-c10dfd124c25"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape: (4062, 2)\n","Columns: ['SMILES_can', 'label']\n","                                           SMILES_can  label\n","0                                                   O      0\n","1   C1=CC(=C[N+](=C1)C2C(C(C(O2)COP(=O)(O)OP(=O)(O...      0\n","2                                                 O=O      0\n","3                                             C(=O)=O      0\n","4   CC1=CC2=C(C=C1C)N(C3=NC(=O)NC(=O)C3=N2)CC(C(C(...      0\n","5                                C(CC(=O)O)C(C(=O)O)N      0\n","6                                                  OO      0\n","7                                             CC(=O)O      0\n","8                                          C(C(=O)O)N      0\n","9                                         CC(C(=O)O)N      0\n","10                                C(C(C(=O)O)N)C(=O)O      0\n","11             C(CC(=O)NC(CS)C(=O)NCC(=O)O)C(C(=O)O)N      0\n","12                               C(CC(=O)N)C(C(=O)O)N      0\n","13                                     C(C(C(=O)O)N)O      0\n","14                                                C=O      0\n","15                         C(C(C1C(=C(C(=O)O1)O)O)O)O      0\n","16                                     CSCCC(C(=O)O)N      0\n","17                   C1=CC=C2C(=C1)C(=CN2)CC(C(=O)O)N      0\n","18                           C1=CC=C(C=C1)CC(C(=O)O)N      0\n","19                          C1=CC(=CC=C1CC(C(=O)O)N)O      0\n"]}]},{"cell_type":"code","source":["from rdkit import Chem\n","\n","smiles = df_check['SMILES_can'].dropna().astype(str).tolist()\n","desc_data, fp_data, bad_smiles = [], [], []\n","\n","for i, s in enumerate(smiles):\n","    m = Chem.MolFromSmiles(s)\n","    if m is None:\n","        bad_smiles.append(s)\n","        continue\n","    try:\n","\n","        Chem.MolToSmiles(m)\n","    except Exception as e:\n","        bad_smiles.append(s)\n","\n","print(\"Total input:\", len(smiles))\n","print(\"Parsed ok:\", len(smiles)-len(bad_smiles))\n","print(\"Bad:\", len(bad_smiles))\n","print(\"Sample bad:\", bad_smiles[:20])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nBQsAk3uasMx","executionInfo":{"status":"ok","timestamp":1757627674170,"user_tz":-330,"elapsed":888,"user":{"displayName":"Rishika Ray","userId":"02079523635456342422"}},"outputId":"425c0b83-9895-470d-a706-4165e1d45776"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total input: 4062\n","Parsed ok: 4062\n","Bad: 0\n","Sample bad: []\n"]}]},{"cell_type":"code","source":["from rdkit import Chem, DataStructs\n","from rdkit.Chem import Descriptors, rdMolDescriptors\n","from rdkit.Avalon import pyAvalonTools\n","from rdkit.Chem.AtomPairs import Pairs\n","import numpy as np\n","\n","s = \"CC(=O)O\"\n","m = Chem.MolFromSmiles(s)\n","\n","\n","desc_vals = [func(m) for name, func in Descriptors.descList]\n","print(\"Num descriptors:\", len(desc_vals))\n","\n","\n","fp = rdMolDescriptors.GetMorganFingerprintAsBitVect(m, 2, nBits=2048)\n","arr = np.zeros((2048,), dtype=int)\n","DataStructs.ConvertToNumpyArray(fp, arr)\n","print(\"Morgan bits set:\", arr.sum())\n","\n","\n","av = pyAvalonTools.GetAvalonFP(m, 256)\n","arr2 = np.zeros((256,), dtype=int)\n","DataStructs.ConvertToNumpyArray(av, arr2)\n","print(\"Avalon bits set:\", arr2.sum())\n","\n","from rdkit.Chem.AtomPairs import Pairs, Torsions\n","\n","\n","ap = rdMolDescriptors.GetHashedAtomPairFingerprintAsBitVect(m, nBits=512)\n","arr3 = np.zeros((512,), dtype=int)\n","DataStructs.ConvertToNumpyArray(ap, arr3)\n","print(\"AtomPairs bits set:\", arr3.sum())\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lkAv4aFqbGII","executionInfo":{"status":"ok","timestamp":1757627674277,"user_tz":-330,"elapsed":112,"user":{"displayName":"Rishika Ray","userId":"02079523635456342422"}},"outputId":"87f77481-d032-4ed2-9195-467fe62ece1b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Num descriptors: 217\n","Morgan bits set: 7\n","Avalon bits set: 10\n","AtomPairs bits set: 6\n"]}]},{"cell_type":"code","source":["\n","import os, pandas as pd, numpy as np\n","from rdkit import Chem, DataStructs\n","from rdkit.Chem import Descriptors, rdMolDescriptors\n","from rdkit.Avalon import pyAvalonTools\n","from sklearn.feature_selection import mutual_info_classif\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.impute import SimpleImputer\n","from joblib import dump\n","\n","WORKDIR = \"/content/drive/MyDrive/moltox_project\"\n","\n","df = pd.read_csv(os.path.join(WORKDIR, \"moltox_dedup_t95.csv\"))\n","print(\"Input dataset:\", df.shape)\n","\n","smiles = df['SMILES_can'].dropna().astype(str).tolist()\n","labels = df['label'].values\n","\n","desc_data, fp_data, bad_smiles = [], [], []\n","\n","for s in smiles:\n","    m = Chem.MolFromSmiles(s)\n","    if m is None:\n","        bad_smiles.append(s)\n","        continue\n","    try:\n","\n","        desc_vals = [func(m) for name, func in Descriptors.descList]\n","        desc_data.append(desc_vals)\n","\n","        fp = rdMolDescriptors.GetMorganFingerprintAsBitVect(m, 2, nBits=2048)\n","        arr = np.zeros((2048,), dtype=int)\n","        DataStructs.ConvertToNumpyArray(fp, arr)\n","\n","\n","        av = pyAvalonTools.GetAvalonFP(m, 256)\n","        arr2 = np.zeros((256,), dtype=int)\n","        DataStructs.ConvertToNumpyArray(av, arr2)\n","\n","\n","        ap = rdMolDescriptors.GetHashedAtomPairFingerprintAsBitVect(m, nBits=512)\n","        arr3 = np.zeros((512,), dtype=int)\n","        DataStructs.ConvertToNumpyArray(ap, arr3)\n","\n","\n","        fp_all = np.concatenate([arr, arr2, arr3])\n","        fp_data.append(fp_all)\n","\n","    except Exception:\n","        bad_smiles.append(s)\n","\n","print(\"Descriptors extracted:\", len(desc_data))\n","print(\"Fingerprints extracted:\", len(fp_data))\n","print(\"Bad SMILES skipped:\", len(bad_smiles))\n","\n","\n","desc_cols = [name for name, func in Descriptors.descList]\n","df_desc = pd.DataFrame(desc_data, columns=desc_cols)\n","df_fp = pd.DataFrame(fp_data)\n","\n","X = pd.concat([df_desc, df_fp], axis=1)\n","print(\"Feature matrix shape:\", X.shape)\n","\n","\n","X = X.replace([np.inf, -np.inf], np.nan)\n","X = X.mask(X.abs() > 1e6)\n","\n","\n","imp = SimpleImputer(strategy='median')\n","X_desc_imp = pd.DataFrame(imp.fit_transform(X[desc_cols]), columns=desc_cols)\n","\n","\n","mi = mutual_info_classif(X_desc_imp, labels, discrete_features=False, random_state=42)\n","mi_sel = pd.Series(mi, index=desc_cols).sort_values(ascending=False)\n","top_desc = mi_sel.index[:200].tolist()\n","\n","print(\"Top descriptors:\", top_desc[:10])\n","\n","X_final = pd.concat(\n","    [X_desc_imp[top_desc], X.drop(columns=desc_cols).reset_index(drop=True)],\n","    axis=1\n",")\n","\n","\n","X_final.columns = X_final.columns.astype(str)\n","print(\"Final feature matrix:\", X_final.shape)\n","\n","\n","scaler = StandardScaler()\n","X_scaled = scaler.fit_transform(X_final)\n","\n","\n","np.save(os.path.join(WORKDIR, \"X_scaled.npy\"), X_scaled)\n","np.save(os.path.join(WORKDIR, \"y.npy\"), labels)\n","dump(scaler, os.path.join(WORKDIR, \"scaler.joblib\"))\n","\n","print(\"Saved X_scaled.npy, y.npy, and scaler.joblib\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nasm61CXUW8q","executionInfo":{"status":"ok","timestamp":1757627729254,"user_tz":-330,"elapsed":54923,"user":{"displayName":"Rishika Ray","userId":"02079523635456342422"}},"outputId":"9c52bcf8-80de-4c6d-8b0a-a353637166d8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Input dataset: (4062, 2)\n","Descriptors extracted: 4062\n","Fingerprints extracted: 4062\n","Bad SMILES skipped: 0\n","Feature matrix shape: (4062, 3033)\n","Top descriptors: ['MaxAbsPartialCharge', 'MinPartialCharge', 'BCUT2D_MWHI', 'MaxPartialCharge', 'MinAbsPartialCharge', 'BalabanJ', 'SlogP_VSA2', 'TPSA', 'PEOE_VSA1', 'BCUT2D_MRHI']\n","Final feature matrix: (4062, 3016)\n","Saved X_scaled.npy, y.npy, and scaler.joblib\n"]}]},{"cell_type":"code","source":["# # Diagnostic: check intermediate files, labels and show sample SMILES\n","# import os, pandas as pd, numpy as np\n","# WORKDIR = \"/content/drive/MyDrive/moltox_project\"\n","# print(\"WORKDIR:\", WORKDIR)\n","# for fname in [\"moltox_raw_combined.csv\", \"moltox_dedup_t95.csv\", \"smiles_labels.csv\", \"t3db_canon_from_csv.csv\", \"t3db_canon_from_sdf.csv\", \"kegg_mapped_pubchem.csv\", \"tox_pubchem_smiles.csv\"]:\n","#     path = os.path.join(WORKDIR, fname)\n","#     exists = os.path.exists(path)\n","#     print(f\"\\n{fname}: exists={exists}\")\n","#     if exists:\n","#         try:\n","#             df = pd.read_csv(path, nrows=20, low_memory=False)\n","#             print(\"  shape:\", pd.read_csv(path).shape if fname in [\"moltox_raw_combined.csv\",\"moltox_dedup_t95.csv\",\"smiles_labels.csv\"] else df.shape)\n","#             print(\"  columns:\", df.columns.tolist())\n","#             if 'label' in df.columns:\n","#                 print(\"  label value counts:\\n\", pd.read_csv(path)['label'].value_counts(dropna=False).to_dict())\n","#             # show first 10 SMILES-like values if present\n","#             for col in ['SMILES_can','SMILES','smiles','SMILES_CAN']:\n","#                 if col in df.columns:\n","#                     print(\"  sample values from\", col, \":\", df[col].dropna().astype(str).unique()[:10].tolist())\n","#                     break\n","#         except Exception as e:\n","#             print(\"  could not preview file:\", e)\n","\n","# # Also check the loaded numpy arrays used by training\n","# xpath = os.path.join(WORKDIR, \"X_scaled.npy\")\n","# ypath = os.path.join(WORKDIR, \"y.npy\")\n","# print(\"\\nX_scaled.npy exists:\", os.path.exists(xpath))\n","# print(\"y.npy exists:\", os.path.exists(ypath))\n","# if os.path.exists(ypath):\n","#     y = np.load(ypath)\n","#     unique, counts = np.unique(y, return_counts=True)\n","#     print(\"y.npy unique:\", dict(zip(unique, counts)))\n"],"metadata":{"id":"xeah9TO5W8GT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","import os, numpy as np, pandas as pd, joblib, warnings, time\n","from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV, cross_val_score\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.neural_network import MLPClassifier\n","from lightgbm import LGBMClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, confusion_matrix, matthews_corrcoef\n","from sklearn.exceptions import ConvergenceWarning\n","warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n","\n","WORKDIR = os.getenv(\"WORKDIR\", \"/content/drive/MyDrive/moltox_project\")\n","X = np.load(os.path.join(WORKDIR, \"X_scaled.npy\"))\n","y = np.load(os.path.join(WORKDIR, \"y.npy\"))\n","\n","print(\"Loaded X shape:\", X.shape, \"y shape:\", y.shape)\n","pos_count = int((y==1).sum()); neg_count = int((y==0).sum())\n","print(\"Dataset class counts -> positive:\", pos_count, \"negative:\", neg_count)\n","\n","\n","if pos_count == 0 or neg_count == 0:\n","    raise ValueError(\"Dataset contains only one class overall. Add examples for the missing class before training.\")\n","\n","def get_positive_proba(est, X_in):\n","    if hasattr(est, \"predict_proba\"):\n","        probs = est.predict_proba(X_in)\n","        if probs.ndim == 2 and probs.shape[1] >= 2:\n","            if hasattr(est, \"classes_\"):\n","                classes = list(est.classes_)\n","                if 1 in classes:\n","                    idx = classes.index(1)\n","                    return probs[:, idx]\n","            return probs[:, 1]\n","        if probs.ndim == 2 and probs.shape[1] == 1:\n","\n","            if hasattr(est, \"classes_\") and len(est.classes_) == 1:\n","                if est.classes_[0] == 1:\n","                    return probs[:, 0]\n","                else:\n","                    return 1.0 - probs[:, 0]\n","            else:\n","                return np.zeros((probs.shape[0],), dtype=float)\n","    try:\n","        preds = est.predict(X_in)\n","        return (preds == 1).astype(float)\n","    except Exception:\n","        return np.zeros((X_in.shape[0],), dtype=float)\n","\n","rf = RandomForestClassifier(class_weight='balanced', random_state=42)\n","rf_params = {'n_estimators':[100,200], 'max_depth':[None,10,30], 'min_samples_leaf':[1,4,10]}\n","\n","lgb = LGBMClassifier(class_weight='balanced', random_state=42, n_jobs=-1)\n","lgb_params = {'num_leaves':[31,63,127], 'learning_rate':[0.05,0.1], 'n_estimators':[100,200]}\n","\n","mlp = MLPClassifier(random_state=42, max_iter=300)\n","mlp_params = {'hidden_layer_sizes':[(128,64),(256,128)], 'alpha':[1e-4,1e-3], 'learning_rate_init':[1e-3,1e-4]}\n","\n","\n","cv_small = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n","def quick_tune(clf, params, Xt, yt, n_iter=6):\n","    rs = RandomizedSearchCV(clf, params, n_iter=n_iter, cv=cv_small, scoring='roc_auc', n_jobs=1, random_state=42)\n","    rs.fit(Xt, yt)\n","    print(f\"Best {type(clf).__name__} AUC {rs.best_score_:.4f}\")\n","    return rs.best_estimator_\n","\n","\n","valid_split = False\n","max_attempts = 12\n","for seed in range(42, 42 + max_attempts):\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=seed)\n","    if len(np.unique(y_train)) >= 2 and len(np.unique(y_test)) >= 2:\n","        print(f\"Using stratified split with random_state={seed}\")\n","        valid_split = True\n","        break\n","    else:\n","        print(f\"Attempt {seed-41}: split invalid (train classes {np.unique(y_train)}, test classes {np.unique(y_test)})\")\n","if not valid_split:\n","    warnings.warn(\"Could not find a stratified train/test split with both classes present in train and test. \"\n","                  \"Falling back to full cross-validated stacking (no separate holdout test).\")\n","\n","\n","if valid_split:\n","    pos_train = int((y_train==1).sum())\n","    requested_folds = 5\n","    n_folds = min(requested_folds, max(2, pos_train))\n","    if n_folds < requested_folds:\n","        warnings.warn(f\"Reduced n_folds to {n_folds} because positive count in train is {pos_train}.\")\n","\n","    print(\"Tuning base learners on training set...\")\n","    best_rf = quick_tune(rf, rf_params, X_train, y_train, n_iter=6)\n","    best_lgb = quick_tune(lgb, lgb_params, X_train, y_train, n_iter=6)\n","    best_mlp = quick_tune(mlp, mlp_params, X_train, y_train, n_iter=6)\n","\n","\n","    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n","    meta_train = np.zeros((X_train.shape[0], 3))\n","    meta_test_blend = np.zeros((X_test.shape[0], 3))\n","\n","    for fold, (tr_idx, val_idx) in enumerate(skf.split(X_train, y_train)):\n","        print(f\"Fold {fold+1}/{n_folds}\")\n","        X_tr, X_val = X_train[tr_idx], X_train[val_idx]\n","        y_tr, y_val = y_train[tr_idx], y_train[val_idx]\n","\n","        if len(np.unique(y_tr)) == 1:\n","            warnings.warn(f\"Fold {fold+1} train has only class {np.unique(y_tr)[0]}\")\n","\n","        est_rf = best_rf.__class__(**best_rf.get_params())\n","        est_lgb = best_lgb.__class__(**best_lgb.get_params())\n","        est_mlp = best_mlp.__class__(**best_mlp.get_params())\n","\n","        est_rf.fit(X_tr, y_tr)\n","        est_lgb.fit(X_tr, y_tr)\n","        est_mlp.fit(X_tr, y_tr)\n","\n","        meta_train[val_idx, 0] = get_positive_proba(est_rf, X_val)\n","        meta_train[val_idx, 1] = get_positive_proba(est_lgb, X_val)\n","        meta_train[val_idx, 2] = get_positive_proba(est_mlp, X_val)\n","\n","        meta_test_blend[:, 0] += get_positive_proba(est_rf, X_test) / n_folds\n","        meta_test_blend[:, 1] += get_positive_proba(est_lgb, X_test) / n_folds\n","        meta_test_blend[:, 2] += get_positive_proba(est_mlp, X_test) / n_folds\n","\n","\n","    if len(np.unique(y_train)) < 2:\n","        raise ValueError(\"After OOF creation y_train contains only one class — cannot train meta learner.\")\n","    meta = LogisticRegression(class_weight='balanced', solver='lbfgs', max_iter=500)\n","    meta.fit(meta_train, y_train)\n","\n","\n","    y_test_prob = meta.predict_proba(meta_test_blend)[:, 1]\n","    y_test_pred = (y_test_prob >= 0.5).astype(int)\n","\n","    auc = roc_auc_score(y_test, y_test_prob)\n","    acc = accuracy_score(y_test, y_test_pred)\n","    f1 = f1_score(y_test, y_test_pred)\n","    tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred).ravel()\n","    sensitivity = tp / (tp + fn) if (tp+fn)>0 else 0.0\n","    specificity = tn / (tn + fp) if (tn+fp)>0 else 0.0\n","    mcc = matthews_corrcoef(y_test, y_test_pred)\n","\n","    print(\"Holdout test results -> AUC: {:.4f}, Acc: {:.4f}, F1: {:.4f}, Sens: {:.4f}, Spec: {:.4f}, MCC: {:.4f}\".format(\n","        auc, acc, f1, sensitivity, specificity, mcc))\n","\n","\n","    pd.DataFrame(meta_train, columns=['rf_prob','lgbm_prob','mlp_prob']).to_csv(os.path.join(WORKDIR, \"meta_train_oof.csv\"), index=False)\n","    joblib.dump(best_rf, os.path.join(WORKDIR, \"best_rf.joblib\"))\n","    joblib.dump(best_lgb, os.path.join(WORKDIR, \"best_lgb.joblib\"))\n","    joblib.dump(best_mlp, os.path.join(WORKDIR, \"best_mlp.joblib\"))\n","    joblib.dump(meta, os.path.join(WORKDIR, \"meta_logreg.joblib\"))\n","    print(\"Saved models and OOF preds.\")\n","\n","else:\n","\n","    print(\"Fallback: performing full cross-validated stacking (OOF on whole dataset).\")\n","    pos_total = int((y==1).sum())\n","    n_folds = min(5, max(2, pos_total))\n","    if n_folds < 3:\n","        warnings.warn(f\"Very few positives ({pos_total}); using n_folds={n_folds}.\")\n","\n","   )\n","    best_rf = quick_tune(rf, rf_params, X, y, n_iter=6)\n","    best_lgb = quick_tune(lgb, lgb_params, X, y, n_iter=6)\n","    best_mlp = quick_tune(mlp, mlp_params, X, y, n_iter=6)\n","\n","    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n","    meta_oof = np.zeros((X.shape[0], 3))\n","\n","    for fold, (tr_idx, val_idx) in enumerate(skf.split(X, y)):\n","        print(f\"Fold {fold+1}/{n_folds}\")\n","        X_tr, X_val = X[tr_idx], X[val_idx]\n","        y_tr, y_val = y[tr_idx], y[val_idx]\n","\n","        est_rf = best_rf.__class__(**best_rf.get_params())\n","        est_lgb = best_lgb.__class__(**best_lgb.get_params())\n","        est_mlp = best_mlp.__class__(**best_mlp.get_params())\n","\n","        est_rf.fit(X_tr, y_tr)\n","        est_lgb.fit(X_tr, y_tr)\n","        est_mlp.fit(X_tr, y_tr)\n","\n","        meta_oof[val_idx, 0] = get_positive_proba(est_rf, X_val)\n","        meta_oof[val_idx, 1] = get_positive_proba(est_lgb, X_val)\n","        meta_oof[val_idx, 2] = get_positive_proba(est_mlp, X_val)\n","\n","\n","    if len(np.unique(y)) < 2:\n","        raise ValueError(\"Cannot train meta: dataset contains only one class.\")\n","    meta = LogisticRegression(class_weight='balanced', solver='lbfgs', max_iter=500)\n","    meta.fit(meta_oof, y)\n","\n","   a)\n","    try:\n","        auc = roc_auc_score(y, meta.predict_proba(meta_oof)[:,1])\n","    except Exception:\n","        auc = float('nan')\n","    preds = (meta.predict_proba(meta_oof)[:,1] >= 0.5).astype(int)\n","    acc = accuracy_score(y, preds)\n","    f1 = f1_score(y, preds)\n","    tn, fp, fn, tp = confusion_matrix(y, preds).ravel()\n","    sensitivity = tp / (tp + fn) if (tp+fn)>0 else 0.0\n","    specificity = tn / (tn + fp) if (tn+fp)>0 else 0.0\n","    mcc = matthews_corrcoef(y, preds)\n","\n","    print(\"CV-stacking results (OOF) -> AUC: {:.4f}, Acc: {:.4f}, F1: {:.4f}, Sens: {:.4f}, Spec: {:.4f}, MCC: {:.4f}\".format(\n","        auc, acc, f1, sensitivity, specificity, mcc))\n","\n","    # save artifacts\n","    pd.DataFrame(meta_oof, columns=['rf_prob','lgbm_prob','mlp_prob']).to_csv(os.path.join(WORKDIR, \"meta_oof_full.csv\"), index=False)\n","    joblib.dump(best_rf, os.path.join(WORKDIR, \"best_rf.joblib\"))\n","    joblib.dump(best_lgb, os.path.join(WORKDIR, \"best_lgb.joblib\"))\n","    joblib.dump(best_mlp, os.path.join(WORKDIR, \"best_mlp.joblib\"))\n","    joblib.dump(meta, os.path.join(WORKDIR, \"meta_logreg.joblib\"))\n","    print(\"Saved models and OOF preds (full CV fallback).\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9S6G7EQFUcPY","executionInfo":{"status":"ok","timestamp":1757628298688,"user_tz":-330,"elapsed":569425,"user":{"displayName":"Rishika Ray","userId":"02079523635456342422"}},"outputId":"a6278ece-7993-4ee5-90c5-559882999a76"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded X shape: (4062, 3016) y shape: (4062,)\n","Dataset class counts -> positive: 2465 negative: 1597\n","Using stratified split with random_state=42\n","Tuning base learners on training set...\n","Best RandomForestClassifier AUC 0.9170\n","[LightGBM] [Info] Number of positive: 1314, number of negative: 852\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022136 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 28455\n","[LightGBM] [Info] Number of data points in the train set: 2166, number of used features: 1773\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n","[LightGBM] [Info] Start training from score 0.000000\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Number of positive: 1315, number of negative: 851\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021916 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 28263\n","[LightGBM] [Info] Number of data points in the train set: 2166, number of used features: 1734\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n","[LightGBM] [Info] Start training from score -0.000000\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Number of positive: 1315, number of negative: 851\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023533 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 28164\n","[LightGBM] [Info] Number of data points in the train set: 2166, number of used features: 1757\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n","[LightGBM] [Info] Start training from score -0.000000\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Number of positive: 1314, number of negative: 852\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022387 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 28455\n","[LightGBM] [Info] Number of data points in the train set: 2166, number of used features: 1773\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n","[LightGBM] [Info] Start training from score 0.000000\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Number of positive: 1315, number of negative: 851\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021804 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 28263\n","[LightGBM] [Info] Number of data points in the train set: 2166, number of used features: 1734\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n","[LightGBM] [Info] Start training from score -0.000000\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Number of positive: 1315, number of negative: 851\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022383 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 28164\n","[LightGBM] [Info] Number of data points in the train set: 2166, number of used features: 1757\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n","[LightGBM] [Info] Start training from score -0.000000\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Number of positive: 1314, number of negative: 852\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022468 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 28455\n","[LightGBM] [Info] Number of data points in the train set: 2166, number of used features: 1773\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n","[LightGBM] [Info] Start training from score 0.000000\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Number of positive: 1315, number of negative: 851\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025513 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 28263\n","[LightGBM] [Info] Number of data points in the train set: 2166, number of used features: 1734\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n","[LightGBM] [Info] Start training from score -0.000000\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Number of positive: 1315, number of negative: 851\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022967 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 28164\n","[LightGBM] [Info] Number of data points in the train set: 2166, number of used features: 1757\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n","[LightGBM] [Info] Start training from score -0.000000\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Number of positive: 1314, number of negative: 852\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023333 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 28455\n","[LightGBM] [Info] Number of data points in the train set: 2166, number of used features: 1773\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n","[LightGBM] [Info] Start training from score 0.000000\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Number of positive: 1315, number of negative: 851\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022588 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 28263\n","[LightGBM] [Info] Number of data points in the train set: 2166, number of used features: 1734\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n","[LightGBM] [Info] Start training from score -0.000000\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Number of positive: 1315, number of negative: 851\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022376 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 28164\n","[LightGBM] [Info] Number of data points in the train set: 2166, number of used features: 1757\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n","[LightGBM] [Info] Start training from score -0.000000\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Number of positive: 1314, number of negative: 852\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022365 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 28455\n","[LightGBM] [Info] Number of data points in the train set: 2166, number of used features: 1773\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n","[LightGBM] [Info] Start training from score 0.000000\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Number of positive: 1315, number of negative: 851\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023261 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 28263\n","[LightGBM] [Info] Number of data points in the train set: 2166, number of used features: 1734\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n","[LightGBM] [Info] Start training from score -0.000000\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Number of positive: 1315, number of negative: 851\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022200 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 28164\n","[LightGBM] [Info] Number of data points in the train set: 2166, number of used features: 1757\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n","[LightGBM] [Info] Start training from score -0.000000\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Number of positive: 1314, number of negative: 852\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031904 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 28455\n","[LightGBM] [Info] Number of data points in the train set: 2166, number of used features: 1773\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n","[LightGBM] [Info] Start training from score 0.000000\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Number of positive: 1315, number of negative: 851\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.110556 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 28263\n","[LightGBM] [Info] Number of data points in the train set: 2166, number of used features: 1734\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n","[LightGBM] [Info] Start training from score -0.000000\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Number of positive: 1315, number of negative: 851\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021901 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 28164\n","[LightGBM] [Info] Number of data points in the train set: 2166, number of used features: 1757\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n","[LightGBM] [Info] Start training from score -0.000000\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Number of positive: 1972, number of negative: 1277\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.119366 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 30179\n","[LightGBM] [Info] Number of data points in the train set: 3249, number of used features: 2161\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n","[LightGBM] [Info] Start training from score 0.000000\n","Best LGBMClassifier AUC 0.9442\n","Best MLPClassifier AUC 0.8938\n","Fold 1/5\n","[LightGBM] [Info] Number of positive: 1577, number of negative: 1022\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033119 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 29205\n","[LightGBM] [Info] Number of data points in the train set: 2599, number of used features: 1938\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n","[LightGBM] [Info] Start training from score -0.000000\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Fold 2/5\n","[LightGBM] [Info] Number of positive: 1577, number of negative: 1022\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033846 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 29230\n","[LightGBM] [Info] Number of data points in the train set: 2599, number of used features: 1948\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n","[LightGBM] [Info] Start training from score -0.000000\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Fold 3/5\n","[LightGBM] [Info] Number of positive: 1578, number of negative: 1021\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042340 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 29198\n","[LightGBM] [Info] Number of data points in the train set: 2599, number of used features: 1934\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n","[LightGBM] [Info] Start training from score -0.000000\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Fold 4/5\n","[LightGBM] [Info] Number of positive: 1578, number of negative: 1021\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.234056 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 29205\n","[LightGBM] [Info] Number of data points in the train set: 2599, number of used features: 1937\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n","[LightGBM] [Info] Start training from score -0.000000\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Fold 5/5\n","[LightGBM] [Info] Number of positive: 1578, number of negative: 1022\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.189108 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 29152\n","[LightGBM] [Info] Number of data points in the train set: 2600, number of used features: 1933\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n","[LightGBM] [Info] Start training from score -0.000000\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Holdout test results -> AUC: 0.9422, Acc: 0.8831, F1: 0.9016, Sens: 0.8824, Spec: 0.8844, MCC: 0.7591\n","Saved models and OOF preds.\n"]}]},{"cell_type":"code","source":["import os, joblib, numpy as np, pandas as pd\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.ensemble import RandomForestClassifier\n","from lightgbm import LGBMClassifier\n","from sklearn.neural_network import MLPClassifier\n","\n","WORKDIR = \"/content/drive/MyDrive/moltox_project\"\n","X = np.load(os.path.join(WORKDIR, \"X_scaled.npy\"))\n","y = np.load(os.path.join(WORKDIR, \"y.npy\"))\n","n = X.shape[0]\n","print(\"X,y shapes:\", X.shape, y.shape)\n","N_FOLDS = 5\n","skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n","\n","base_defs = [\n","    (\"rf\", RandomForestClassifier(n_estimators=200, class_weight='balanced', random_state=42)),\n","    (\"lgbm\", LGBMClassifier(n_estimators=200, class_weight='balanced', random_state=42)),\n","    (\"mlp\", MLPClassifier(hidden_layer_sizes=(256,128), alpha=1e-4, max_iter=300, random_state=42))\n","]\n","\n","meta_oof = pd.DataFrame(index=range(n))\n","\n","for name, model in base_defs:\n","    print(\"Generating OOF for:\", name)\n","    oof = np.zeros(n)\n","    for fold, (tr_idx, val_idx) in enumerate(skf.split(X, y)):\n","        print(\" Fold\", fold+1, \"train\", len(tr_idx), \"val\", len(val_idx))\n","        m = model.__class__(**model.get_params())\n","        m.fit(X[tr_idx], y[tr_idx])\n","        if hasattr(m, \"predict_proba\"):\n","            probs = m.predict_proba(X[val_idx])\n","            if probs.shape[1] == 1:\n","                probs1 = probs[:,0] if (hasattr(m, \"classes_\") and m.classes_[0]==1) else 1-probs[:,0]\n","            else:\n","                probs1 = probs[:, list(m.classes_).index(1)] if 1 in m.classes_ else probs[:,1]\n","        else:\n","            probs1 = m.predict(X[val_idx]).astype(float)\n","        oof[val_idx] = probs1\n","    meta_oof[name + \"_prob\"] = oof\n","\n","    final_m = model.__class__(**model.get_params())\n","    final_m.fit(X, y)\n","    joblib.dump(final_m, os.path.join(WORKDIR, f\"retrained_full_{name}.joblib\"))\n","    print(\"Saved full-data refit for\", name)\n","\n","out_true = os.path.join(WORKDIR, \"meta_oof_true.csv\")\n","meta_oof.to_csv(out_true, index=False)\n","print(\"Saved true OOF to\", out_true, \"shape:\", meta_oof.shape)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TcmZgy6bdDL5","executionInfo":{"status":"ok","timestamp":1757628478849,"user_tz":-330,"elapsed":180163,"user":{"displayName":"Rishika Ray","userId":"02079523635456342422"}},"outputId":"eecfb269-2bf7-4b5a-d3ca-e2be58d5f3bf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["X,y shapes: (4062, 3016) (4062,)\n","Generating OOF for: rf\n"," Fold 1 train 3249 val 813\n"," Fold 2 train 3249 val 813\n"," Fold 3 train 3250 val 812\n"," Fold 4 train 3250 val 812\n"," Fold 5 train 3250 val 812\n","Saved full-data refit for rf\n","Generating OOF for: lgbm\n"," Fold 1 train 3249 val 813\n","[LightGBM] [Info] Number of positive: 1972, number of negative: 1277\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044415 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 30458\n","[LightGBM] [Info] Number of data points in the train set: 3249, number of used features: 2201\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n","[LightGBM] [Info] Start training from score 0.000000\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":[" Fold 2 train 3249 val 813\n","[LightGBM] [Info] Number of positive: 1972, number of negative: 1277\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.051967 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 30361\n","[LightGBM] [Info] Number of data points in the train set: 3249, number of used features: 2183\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n","[LightGBM] [Info] Start training from score 0.000000\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":[" Fold 3 train 3250 val 812\n","[LightGBM] [Info] Number of positive: 1972, number of negative: 1278\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.050314 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 30227\n","[LightGBM] [Info] Number of data points in the train set: 3250, number of used features: 2163\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n","[LightGBM] [Info] Start training from score 0.000000\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":[" Fold 4 train 3250 val 812\n","[LightGBM] [Info] Number of positive: 1972, number of negative: 1278\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.079388 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 30287\n","[LightGBM] [Info] Number of data points in the train set: 3250, number of used features: 2163\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n","[LightGBM] [Info] Start training from score 0.000000\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":[" Fold 5 train 3250 val 812\n","[LightGBM] [Info] Number of positive: 1972, number of negative: 1278\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043111 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 30162\n","[LightGBM] [Info] Number of data points in the train set: 3250, number of used features: 2161\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n","[LightGBM] [Info] Start training from score 0.000000\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Number of positive: 2465, number of negative: 1597\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.127700 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 31314\n","[LightGBM] [Info] Number of data points in the train set: 4062, number of used features: 2395\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n","[LightGBM] [Info] Start training from score 0.000000\n","Saved full-data refit for lgbm\n","Generating OOF for: mlp\n"," Fold 1 train 3249 val 813\n"," Fold 2 train 3249 val 813\n"," Fold 3 train 3250 val 812\n"," Fold 4 train 3250 val 812\n"," Fold 5 train 3250 val 812\n","Saved full-data refit for mlp\n","Saved true OOF to /content/drive/MyDrive/moltox_project/meta_oof_true.csv shape: (4062, 3)\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, recall_score, confusion_matrix, matthews_corrcoef, brier_score_loss\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n","from sklearn.model_selection import StratifiedKFold\n","\n","WORKDIR = \"/content/drive/MyDrive/moltox_project\"\n","meta_path = os.path.join(WORKDIR, \"meta_oof_true.csv\")\n","y_path = os.path.join(WORKDIR, \"y.npy\")\n","\n","meta = pd.read_csv(meta_path)\n","y = np.load(y_path)\n","print(\"Meta shape:\", meta.shape, \"y shape:\", y.shape)\n","\n","candidates = {\n","    \"LogReg(L2)\": LogisticRegression(class_weight=\"balanced\", max_iter=500, solver=\"lbfgs\"),\n","    \"LDA\": LinearDiscriminantAnalysis(),\n","    \"QDA\": QuadraticDiscriminantAnalysis(),\n","    \"NaiveBayes\": GaussianNB(),\n","    \"MLP_small\": MLPClassifier(hidden_layer_sizes=(32,), max_iter=300, random_state=42),\n","    \"RF_meta\": RandomForestClassifier(n_estimators=200, class_weight=\"balanced\", random_state=42),\n","    \"GB_meta\": GradientBoostingClassifier(n_estimators=200, random_state=42),\n","}\n","\n","results = []\n","skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n","\n","for name, clf in candidates.items():\n","    aucs, accs, f1s, sens, specs, mccs, briers = [], [], [], [], [], [], []\n","    for tr, val in skf.split(meta, y):\n","        clf.fit(meta.iloc[tr], y[tr])\n","        preds = clf.predict(meta.iloc[val])\n","        probs = clf.predict_proba(meta.iloc[val])[:,1] if hasattr(clf, \"predict_proba\") else preds.astype(float)\n","\n","        aucs.append(roc_auc_score(y[val], probs))\n","        accs.append(accuracy_score(y[val], preds))\n","        f1s.append(f1_score(y[val], preds))\n","        rec = recall_score(y[val], preds)\n","        sens.append(rec)\n","        tn, fp, fn, tp = confusion_matrix(y[val], preds).ravel()\n","        specs.append(tn/(tn+fp))\n","        mccs.append(matthews_corrcoef(y[val], preds))\n","        briers.append(brier_score_loss(y[val], probs))\n","\n","    results.append({\n","        \"name\": name,\n","        \"AUC\": np.mean(aucs),\n","        \"ACC\": np.mean(accs),\n","        \"F1\": np.mean(f1s),\n","        \"Sens\": np.mean(sens),\n","        \"Spec\": np.mean(specs),\n","        \"MCC\": np.mean(mccs),\n","        \"Brier\": np.mean(briers)\n","    })\n","\n","dfres = pd.DataFrame(results).sort_values(by=[\"AUC\",\"F1\"], ascending=False).reset_index(drop=True)\n","print(dfres)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dOSYAMDTbrf4","executionInfo":{"status":"ok","timestamp":1757628489487,"user_tz":-330,"elapsed":10628,"user":{"displayName":"Rishika Ray","userId":"02079523635456342422"}},"outputId":"d7554944-414c-465f-ad86-83307c1e538c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Meta shape: (4062, 3) y shape: (4062,)\n","         name       AUC       ACC        F1      Sens      Spec       MCC  \\\n","0         LDA  0.946816  0.877154  0.898847  0.899797  0.842230  0.742865   \n","1         QDA  0.946526  0.879862  0.900369  0.894929  0.856634  0.749662   \n","2     GB_meta  0.946307  0.872480  0.895718  0.902231  0.826589  0.732211   \n","3   MLP_small  0.945257  0.880107  0.901541  0.905071  0.841607  0.748818   \n","4  LogReg(L2)  0.944987  0.877894  0.898160  0.887627  0.862900  0.746527   \n","5  NaiveBayes  0.943146  0.872476  0.893320  0.880325  0.860388  0.735821   \n","6     RF_meta  0.942328  0.871247  0.894788  0.902231  0.823450  0.729631   \n","\n","      Brier  \n","0  0.100717  \n","1  0.101201  \n","2  0.090962  \n","3  0.090205  \n","4  0.092464  \n","5  0.113358  \n","6  0.092339  \n"]}]},{"cell_type":"code","source":["!pip install --quiet deepchem rdkit\n","\n","import os, time\n","import numpy as np, pandas as pd\n","from rdkit import Chem\n","from deepchem.feat import MolGraphConvFeaturizer\n","\n","WORKDIR = \"/content/drive/MyDrive/moltox_project\"\n","SMILES_CSV = os.path.join(WORKDIR, \"smiles_labels.csv\")\n","Y_PATH = os.path.join(WORKDIR, \"y.npy\")\n","FAILED_CSV = os.path.join(WORKDIR, \"gcn_failed_smiles_one_by_one.csv\")\n","FEAT_SAVE = os.path.join(WORKDIR, \"gcn_valid_index_map.npy\")\n","\n","df = pd.read_csv(SMILES_CSV)\n","smiles_all = df['SMILES_can'].astype(str).tolist()\n","y = np.load(Y_PATH)\n","assert len(smiles_all) == len(y)\n","\n","valid_idx = []\n","invalid_idx = []\n","for i, s in enumerate(smiles_all):\n","    try:\n","        mol = Chem.MolFromSmiles(s)\n","        if mol is None:\n","            invalid_idx.append(i)\n","        else:\n","            try:\n","                Chem.SanitizeMol(mol)\n","                valid_idx.append(i)\n","            except Exception:\n","                invalid_idx.append(i)\n","    except Exception:\n","        invalid_idx.append(i)\n","\n","print(f\"Total: {len(smiles_all)}  RDKit-sane: {len(valid_idx)}  invalid: {len(invalid_idx)}\")\n","if invalid_idx:\n","    pd.DataFrame({\"index\": invalid_idx, \"smiles\": [smiles_all[i] for i in invalid_idx]}).to_csv(FAILED_CSV, index=False)\n","    print(\"Saved RDKit-invalid SMILES to\", FAILED_CSV)\n","\n","featurizer = MolGraphConvFeaturizer()\n","valid_graphs = []\n","valid_graphs_idx = []\n","failed_after_feat = []\n","\n","t0 = time.time()\n","for pos, orig_i in enumerate(valid_idx):\n","    s = smiles_all[orig_i]\n","    try:\n","        g = featurizer.featurize([s])[0]\n","        if g is None:\n","            failed_after_feat.append(orig_i)\n","        else:\n","            if hasattr(g, 'node_features'):\n","                if getattr(g, 'node_features') is None or len(getattr(g, 'node_features')) == 0:\n","                    failed_after_feat.append(orig_i)\n","                else:\n","                    valid_graphs.append(g)\n","                    valid_graphs_idx.append(orig_i)\n","            else:\n","                valid_graphs.append(g)\n","                valid_graphs_idx.append(orig_i)\n","    except Exception as e:\n","        failed_after_feat.append(orig_i)\n","        if len(failed_after_feat) <= 10:\n","            print(f\"Featurize failed at original idx {orig_i} SMILES: {s}  -> {type(e).__name__}: {e}\")\n","\n","print(f\"Per-molecule featurization done in {time.time()-t0:.1f}s\")\n","print(\"Succeeded:\", len(valid_graphs), \"Failed after RDKit:\", len(failed_after_feat))\n","\n","all_failed = sorted(set(invalid_idx) | set(failed_after_feat))\n","if all_failed:\n","    pd.DataFrame({\"index\": all_failed, \"smiles\": [smiles_all[i] for i in all_failed]}).to_csv(FAILED_CSV, index=False)\n","    print(\"Saved all failed SMILES to\", FAILED_CSV)\n","\n","np.save(FEAT_SAVE, {\"valid_idx\": valid_graphs_idx})\n","print(\"Saved mapping of valid indices to\", FEAT_SAVE)\n","\n","aligned_oof = np.full((len(smiles_all),), np.nan, dtype=float)\n","print(\"Ready. Example: aligned_oof shape\", aligned_oof.shape)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GJeU_D9n39yY","executionInfo":{"status":"ok","timestamp":1757629439289,"user_tz":-330,"elapsed":40814,"user":{"displayName":"Rishika Ray","userId":"02079523635456342422"}},"outputId":"b2afc29e-0da8-469a-a913-09f130dc0ff1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 0, O. Appending empty array\n","WARNING:deepchem.feat.base_classes:Exception message: zero-size array to reduction operation maximum which has no identity\n","WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 0, [S]. Appending empty array\n","WARNING:deepchem.feat.base_classes:Exception message: zero-size array to reduction operation maximum which has no identity\n"]},{"output_type":"stream","name":"stdout","text":["Total: 4062  RDKit-sane: 4062  invalid: 0\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 0, [Mg+2].[OH-].[OH-]. Appending empty array\n","WARNING:deepchem.feat.base_classes:Exception message: zero-size array to reduction operation maximum which has no identity\n","WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 0, [F-].[Na+]. Appending empty array\n","WARNING:deepchem.feat.base_classes:Exception message: zero-size array to reduction operation maximum which has no identity\n","WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 0, [Cl-].[NH4+]. Appending empty array\n","WARNING:deepchem.feat.base_classes:Exception message: zero-size array to reduction operation maximum which has no identity\n","WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 0, N.N.[Ag+].[F-]. Appending empty array\n","WARNING:deepchem.feat.base_classes:Exception message: zero-size array to reduction operation maximum which has no identity\n","WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 0, [Br-].[Br-].[Ca+2]. Appending empty array\n","WARNING:deepchem.feat.base_classes:Exception message: zero-size array to reduction operation maximum which has no identity\n","WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 0, [Xe]. Appending empty array\n","WARNING:deepchem.feat.base_classes:Exception message: zero-size array to reduction operation maximum which has no identity\n","WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 0, [Cl-].[Cl-].[Sr+2]. Appending empty array\n","WARNING:deepchem.feat.base_classes:Exception message: zero-size array to reduction operation maximum which has no identity\n","WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 0, C. Appending empty array\n","WARNING:deepchem.feat.base_classes:Exception message: zero-size array to reduction operation maximum which has no identity\n","WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 0, C.[U]. Appending empty array\n","WARNING:deepchem.feat.base_classes:Exception message: zero-size array to reduction operation maximum which has no identity\n","WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 0, C.C.C.[AlH3].[AlH3].[AlH3].[AlH3]. Appending empty array\n","WARNING:deepchem.feat.base_classes:Exception message: zero-size array to reduction operation maximum which has no identity\n","WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 0, C.[V]. Appending empty array\n","WARNING:deepchem.feat.base_classes:Exception message: zero-size array to reduction operation maximum which has no identity\n","WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 0, [14CH4]. Appending empty array\n","WARNING:deepchem.feat.base_classes:Exception message: zero-size array to reduction operation maximum which has no identity\n"]},{"output_type":"stream","name":"stdout","text":["Per-molecule featurization done in 28.3s\n","Succeeded: 4062 Failed after RDKit: 0\n","Saved mapping of valid indices to /content/drive/MyDrive/moltox_project/gcn_valid_index_map.npy\n","Ready. Example: aligned_oof shape (4062,)\n"]}]},{"cell_type":"code","source":["!pip install --quiet deepchem rdkit-pypi\n","\n","import os, time, pickle\n","import numpy as np, pandas as pd\n","from rdkit import Chem\n","\n","from deepchem.feat import MolGraphConvFeaturizer, ConvMolFeaturizer\n","from deepchem.data import NumpyDataset\n","\n","WORKDIR = \"/content/drive/MyDrive/moltox_project\"\n","SMILES_CSV = os.path.join(WORKDIR, \"smiles_labels.csv\")\n","Y_PATH = os.path.join(WORKDIR, \"y.npy\")\n","OUT_FAILED = os.path.join(WORKDIR, \"gcn_failed_smiles_debug.csv\")\n","OUT_GOOD_PKL = os.path.join(WORKDIR, \"gcn_valid_graphs.pkl\")\n","OUT_IDX = os.path.join(WORKDIR, \"gcn_valid_idx.npy\")\n","\n","# load\n","df = pd.read_csv(SMILES_CSV)\n","smiles_all = df['SMILES_can'].astype(str).tolist()\n","y = np.load(Y_PATH)\n","assert len(smiles_all) == len(y)\n","\n","# instantiate featurizers\n","mg_featurizer = MolGraphConvFeaturizer()\n","conv_featurizer = ConvMolFeaturizer()\n","\n","good_graphs = []\n","good_idx = []\n","failed_records = []\n","\n","t0 = time.time()\n","for i, s in enumerate(smiles_all):\n","    try:\n","        mol = Chem.MolFromSmiles(s)\n","        if mol is None:\n","            failed_records.append({\"index\": i, \"smiles\": s, \"stage\": \"rdkit_parse\", \"error\": \"RDKit MolFromSmiles returned None\"})\n","            continue\n","        try:\n","            Chem.SanitizeMol(mol)\n","        except Exception as e:\n","            failed_records.append({\"index\": i, \"smiles\": s, \"stage\": \"rdkit_sanitize\", \"error\": repr(e)})\n","    except Exception as e:\n","        failed_records.append({\"index\": i, \"smiles\": s, \"stage\": \"rdkit_exception\", \"error\": repr(e)})\n","        continue\n","\n","    try:\n","        g = mg_featurizer.featurize([s])[0]\n","        if g is None:\n","            raise ValueError(\"MolGraphConvFeaturizer returned None\")\n","        if hasattr(g, \"node_features\") and (getattr(g, \"node_features\") is None or len(getattr(g, \"node_features\")) == 0):\n","            raise ValueError(\"MolGraphConvFeaturizer returned empty node_features\")\n","        # success\n","        good_graphs.append(g)\n","        good_idx.append(i)\n","        continue\n","    except Exception as e_mg:\n","        mg_err = repr(e_mg)\n","        try:\n","            g2 = conv_featurizer.featurize([s])[0]\n","            if g2 is None:\n","                raise ValueError(\"ConvMolFeaturizer returned None\")\n","            good_graphs.append(g2)\n","            good_idx.append(i)\n","            continue\n","        except Exception as e_conv:\n","            conv_err = repr(e_conv)\n","            failed_records.append({\n","                \"index\": i,\n","                \"smiles\": s,\n","                \"stage\": \"featurization_both_failed\",\n","                \"error\": f\"MolGraphErr: {mg_err} | ConvMolErr: {conv_err}\"\n","            })\n","            continue\n","\n","elapsed = time.time() - t0\n","print(f\"Featurization loop done in {elapsed:.1f}s\")\n","print(\"Good graphs:\", len(good_graphs), \"Failed entries:\", len(failed_records))\n","\n","if failed_records:\n","    pd.DataFrame(failed_records).to_csv(OUT_FAILED, index=False)\n","    print(\"Saved failure debug CSV to:\", OUT_FAILED)\n","\n","with open(OUT_GOOD_PKL, \"wb\") as f:\n","    pickle.dump(good_graphs, f)\n","np.save(OUT_IDX, np.array(good_idx, dtype=int))\n","print(\"Saved valid graphs pickle to:\", OUT_GOOD_PKL)\n","print(\"Saved valid index mapping to:\", OUT_IDX)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bdrlyhu-ho4Q","executionInfo":{"status":"ok","timestamp":1757630254067,"user_tz":-330,"elapsed":35086,"user":{"displayName":"Rishika Ray","userId":"02079523635456342422"}},"outputId":"19b66f57-c1ee-42bf-92f0-1e1114fbfab1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[31mERROR: Could not find a version that satisfies the requirement rdkit-pypi (from versions: none)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for rdkit-pypi\u001b[0m\u001b[31m\n","\u001b[0m"]},{"output_type":"stream","name":"stderr","text":["WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 0, O. Appending empty array\n","WARNING:deepchem.feat.base_classes:Exception message: zero-size array to reduction operation maximum which has no identity\n","WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 0, [S]. Appending empty array\n","WARNING:deepchem.feat.base_classes:Exception message: zero-size array to reduction operation maximum which has no identity\n","WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 0, [Mg+2].[OH-].[OH-]. Appending empty array\n","WARNING:deepchem.feat.base_classes:Exception message: zero-size array to reduction operation maximum which has no identity\n","WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 0, [F-].[Na+]. Appending empty array\n","WARNING:deepchem.feat.base_classes:Exception message: zero-size array to reduction operation maximum which has no identity\n","WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 0, [Cl-].[NH4+]. Appending empty array\n","WARNING:deepchem.feat.base_classes:Exception message: zero-size array to reduction operation maximum which has no identity\n","WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 0, N.N.[Ag+].[F-]. Appending empty array\n","WARNING:deepchem.feat.base_classes:Exception message: zero-size array to reduction operation maximum which has no identity\n","WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 0, [Br-].[Br-].[Ca+2]. Appending empty array\n","WARNING:deepchem.feat.base_classes:Exception message: zero-size array to reduction operation maximum which has no identity\n","WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 0, [Xe]. Appending empty array\n","WARNING:deepchem.feat.base_classes:Exception message: zero-size array to reduction operation maximum which has no identity\n","WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 0, [Cl-].[Cl-].[Sr+2]. Appending empty array\n","WARNING:deepchem.feat.base_classes:Exception message: zero-size array to reduction operation maximum which has no identity\n","WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 0, C. Appending empty array\n","WARNING:deepchem.feat.base_classes:Exception message: zero-size array to reduction operation maximum which has no identity\n","WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 0, C.[U]. Appending empty array\n","WARNING:deepchem.feat.base_classes:Exception message: zero-size array to reduction operation maximum which has no identity\n","WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 0, C.C.C.[AlH3].[AlH3].[AlH3].[AlH3]. Appending empty array\n","WARNING:deepchem.feat.base_classes:Exception message: zero-size array to reduction operation maximum which has no identity\n","WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 0, C.[V]. Appending empty array\n","WARNING:deepchem.feat.base_classes:Exception message: zero-size array to reduction operation maximum which has no identity\n","WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 0, [14CH4]. Appending empty array\n","WARNING:deepchem.feat.base_classes:Exception message: zero-size array to reduction operation maximum which has no identity\n"]},{"output_type":"stream","name":"stdout","text":["Featurization loop done in 30.3s\n","Good graphs: 4062 Failed entries: 0\n","Saved valid graphs pickle to: /content/drive/MyDrive/moltox_project/gcn_valid_graphs.pkl\n","Saved valid index mapping to: /content/drive/MyDrive/moltox_project/gcn_valid_idx.npy\n"]}]},{"cell_type":"code","source":["\n","\n","import os, time, pickle, traceback\n","import numpy as np, pandas as pd\n","from sklearn.model_selection import StratifiedKFold\n","\n","WORKDIR = \"/content/drive/MyDrive/moltox_project\"\n","GOOD_PKL = os.path.join(WORKDIR, \"gcn_valid_graphs.pkl\")\n","IDX_NPY  = os.path.join(WORKDIR, \"gcn_valid_idx.npy\")\n","Y_PATH   = os.path.join(WORKDIR, \"y.npy\")\n","OUT_OOF  = os.path.join(WORKDIR, \"gcn_oof_aligned_cpu.csv\")\n","GCN_DIR  = os.path.join(WORKDIR, \"gcn_models\")\n","LOGFILE  = os.path.join(WORKDIR, \"gcn_oof_error_cpu.log\")\n","os.makedirs(GCN_DIR, exist_ok=True)\n","\n","N_FOLDS    = 3\n","EPOCHS     = 6\n","BATCH_SIZE = 8\n","LEARNING_RATE = 1e-3\n","SEED = 42\n","\n","def info(msg): print(\"[INFO]\", msg)\n","\n","info(\"Loading pickled graph objects and index mapping...\")\n","with open(GOOD_PKL, \"rb\") as f:\n","    valid_graphs = pickle.load(f)\n","valid_idx = np.load(IDX_NPY).tolist()\n","y = np.load(Y_PATH)\n","n_total = len(y)\n","info(f\"Total rows: {n_total}, valid graphs: {len(valid_graphs)}\")\n","\n","if len(valid_graphs) != len(valid_idx):\n","    raise RuntimeError(\"valid_graphs and valid_idx length mismatch - re-create mapping.\")\n","\n","gcn_oof_full = np.full((n_total,), np.nan, dtype=float)\n","\n","fold_done = []\n","for f in os.listdir(WORKDIR):\n","    if f.startswith(\"gcn_oof_partial_fold_\") and f.endswith(\".npy\"):\n","        try:\n","            idx = int(f.split(\"_\")[-1].split(\".\")[0])\n","            fold_done.append(idx)\n","        except:\n","            pass\n","fold_done = sorted(set(fold_done))\n","if fold_done:\n","    info(f\"Resuming: found partial fold outputs for folds: {fold_done}\")\n","    for fd in fold_done:\n","        partial = np.load(os.path.join(WORKDIR, f\"gcn_oof_partial_fold_{fd}.npy\"), allow_pickle=True).item()\n","        for orig_i, prob in partial.items():\n","            gcn_oof_full[int(orig_i)] = float(prob)\n","\n","valid_y = np.array([ y[i] for i in valid_idx ])\n","\n","skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n","\n","from deepchem.data import NumpyDataset\n","from deepchem.models import GraphConvModel\n","\n","fold_no = 0\n","for tr_sub, val_sub in skf.split(np.zeros(len(valid_y)), valid_y):\n","    fold_no += 1\n","    if fold_no in fold_done:\n","        info(f\"Skipping fold {fold_no} (already completed).\")\n","        continue\n","\n","    info(f\"Starting fold {fold_no} -> train {len(tr_sub)} val {len(val_sub)}\")\n","    try:\n","        X_tr = [ valid_graphs[i] for i in tr_sub ]\n","        y_tr = valid_y[tr_sub].reshape(-1,1)\n","        X_val = [ valid_graphs[i] for i in val_sub ]\n","        y_val = valid_y[val_sub].reshape(-1,1)\n","\n","        ds_tr = NumpyDataset(X_tr, y_tr)\n","        ds_val = NumpyDataset(X_val, y_val)\n","\n","        model_dir = os.path.join(GCN_DIR, f\"gcn_fold_cpu_{fold_no}\")\n","        model = GraphConvModel(n_tasks=1, mode='classification',\n","                               batch_size=BATCH_SIZE, model_dir=model_dir,\n","                               learning_rate=LEARNING_RATE, verbose=0)\n","\n","        t0 = time.time()\n","        model.fit(ds_tr, nb_epoch=EPOCHS)\n","        info(f\"Fold {fold_no} trained in {time.time()-t0:.1f}s (epochs={EPOCHS})\")\n","\n","        preds = model.predict(ds_val).reshape(-1)\n","        info(f\"Fold {fold_no} preds min/max: {float(np.min(preds)):.6f}/{float(np.max(preds)):.6f}\")\n","\n","        partial_dict = {}\n","        for local_i, orig_idx in enumerate([ valid_idx[i] for i in val_sub ]):\n","            prob = float(preds[local_i])\n","            gcn_oof_full[orig_idx] = prob\n","            partial_dict[int(orig_idx)] = prob\n","\n","        np.save(os.path.join(WORKDIR, f\"gcn_oof_partial_fold_{fold_no}.npy\"), partial_dict)\n","        info(f\"Saved partial OOF for fold {fold_no} to gcn_oof_partial_fold_{fold_no}.npy\")\n","\n","        # cleanup\n","        del model\n","\n","    except Exception as e:\n","        tb = traceback.format_exc()\n","        with open(LOGFILE, \"a\") as lf:\n","            lf.write(f\"=== Fold {fold_no} EXCEPTION ===\\n\")\n","            lf.write(tb + \"\\n\\n\")\n","        info(f\"Exception in fold {fold_no}; logged to {LOGFILE}. Continuing to next fold.\")\n","        continue\n","\n","pd.DataFrame({\"gcn_prob\": gcn_oof_full}).to_csv(OUT_OOF, index=False)\n","info(f\"Saved aligned OOF (CPU) to {OUT_OOF}. NaNs count: {int(np.isnan(gcn_oof_full).sum())} / {n_total}\")\n","\n","try:\n","    info(\"Refitting final GCN on entire valid set (low-epoch) and saving to gcn_full_cpu/ ...\")\n","    ds_full = NumpyDataset(valid_graphs, np.array([ y[i] for i in valid_idx ]).reshape(-1,1))\n","    final_dir = os.path.join(GCN_DIR, \"gcn_full_cpu\")\n","    final_model = GraphConvModel(n_tasks=1, mode='classification',\n","                                 batch_size=BATCH_SIZE, model_dir=final_dir,\n","                                 learning_rate=LEARNING_RATE, verbose=0)\n","    final_model.fit(ds_full, nb_epoch=EPOCHS)\n","    info(f\"Final CPU GCN trained and saved at {final_dir}\")\n","except Exception as e:\n","    tb = traceback.format_exc()\n","    with open(LOGFILE, \"a\") as lf:\n","        lf.write(\"=== Final refit EXCEPTION ===\\n\")\n","        lf.write(tb + \"\\n\\n\")\n","    info(\"Exception during final refit; logged to \" + LOGFILE)\n","\n","info(\"CPU run complete. If any folds logged exceptions, open the log file to inspect.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6tpmBx2U7lX6","executionInfo":{"status":"ok","timestamp":1757630764534,"user_tz":-330,"elapsed":272,"user":{"displayName":"Rishika Ray","userId":"02079523635456342422"}},"outputId":"353e3d79-51f9-4257-cef9-c8fa5ced82d3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[INFO] Loading pickled graph objects and index mapping...\n","[INFO] Total rows: 4062, valid graphs: 4062\n","[INFO] Starting fold 1 -> train 2708 val 1354\n","[INFO] Exception in fold 1; logged to /content/drive/MyDrive/moltox_project/gcn_oof_error_cpu.log. Continuing to next fold.\n","[INFO] Starting fold 2 -> train 2708 val 1354\n","[INFO] Exception in fold 2; logged to /content/drive/MyDrive/moltox_project/gcn_oof_error_cpu.log. Continuing to next fold.\n","[INFO] Starting fold 3 -> train 2708 val 1354\n","[INFO] Exception in fold 3; logged to /content/drive/MyDrive/moltox_project/gcn_oof_error_cpu.log. Continuing to next fold.\n","[INFO] Saved aligned OOF (CPU) to /content/drive/MyDrive/moltox_project/gcn_oof_aligned_cpu.csv. NaNs count: 4062 / 4062\n","[INFO] Refitting final GCN on entire valid set (low-epoch) and saving to gcn_full_cpu/ ...\n","[INFO] Exception during final refit; logged to /content/drive/MyDrive/moltox_project/gcn_oof_error_cpu.log\n","[INFO] CPU run complete. If any folds logged exceptions, open the log file to inspect.\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","WORKDIR = \"/content/drive/MyDrive/moltox_project\"\n","\n","meta = pd.read_csv(f\"{WORKDIR}/meta_oof_true.csv\")\n","\n","gcn = pd.read_csv(f\"{WORKDIR}/gcn_oof_aligned_cpu.csv\")\n","\n","print(\"Meta shape:\", meta.shape, \"GCN shape:\", gcn.shape)\n","\n","meta[\"gcn_prob\"] = gcn[\"gcn_prob\"]\n","\n","meta.to_csv(f\"{WORKDIR}/meta_oof_true_with_gcn.csv\", index=False)\n","print(\"Extended meta saved at meta_oof_true_with_gcn.csv\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6i4PoN0t9hJU","executionInfo":{"status":"ok","timestamp":1757630841320,"user_tz":-330,"elapsed":89,"user":{"displayName":"Rishika Ray","userId":"02079523635456342422"}},"outputId":"c0172d28-1f06-42c4-8171-46e16de04a42"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Meta shape: (4062, 3) GCN shape: (4062, 1)\n","Extended meta saved at meta_oof_true_with_gcn.csv\n"]}]},{"cell_type":"code","source":["import numpy as np\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, confusion_matrix, matthews_corrcoef, brier_score_loss\n","\n","WORKDIR = \"/content/drive/MyDrive/moltox_project\"\n","meta = pd.read_csv(f\"{WORKDIR}/meta_oof_true_with_gcn.csv\")\n","y = np.load(f\"{WORKDIR}/y.npy\")\n","\n","models = {\n","    \"LogReg(L2)\": LogisticRegression(class_weight=\"balanced\", max_iter=500, solver=\"lbfgs\"),\n","    \"LDA\": LinearDiscriminantAnalysis(),\n","    \"QDA\": QuadraticDiscriminantAnalysis(),\n","    \"MLP_small\": MLPClassifier(hidden_layer_sizes=(32,), max_iter=300),\n","    \"GB_meta\": GradientBoostingClassifier(),\n","    \"RF_meta\": RandomForestClassifier(),\n","    \"NaiveBayes\": GaussianNB()\n","}\n","\n","results = []\n","for name, clf in models.items():\n","    try:\n","        clf.fit(meta, y)\n","        preds = clf.predict(meta)\n","        probs = clf.predict_proba(meta)[:,1]\n","\n","        tn, fp, fn, tp = confusion_matrix(y, preds).ravel()\n","        results.append({\n","            \"name\": name,\n","            \"AUC\": roc_auc_score(y, probs),\n","            \"ACC\": accuracy_score(y, preds),\n","            \"F1\": f1_score(y, preds),\n","            \"Sens\": tp / (tp + fn),\n","            \"Spec\": tn / (tn + fp),\n","            \"MCC\": matthews_corrcoef(y, preds),\n","            \"Brier\": brier_score_loss(y, probs)\n","        })\n","    except Exception as e:\n","        print(f\"[ERROR] {name}: {e}\")\n","\n","dfres = pd.DataFrame(results).sort_values(by=[\"AUC\",\"F1\"], ascending=False).reset_index(drop=True)\n","print(dfres)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lrbL9_za9pRo","executionInfo":{"status":"ok","timestamp":1757630866883,"user_tz":-330,"elapsed":883,"user":{"displayName":"Rishika Ray","userId":"02079523635456342422"}},"outputId":"adc76832-f376-465a-a705-76ec604dbe97"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[ERROR] LogReg(L2): Input X contains NaN.\n","LogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n","[ERROR] LDA: Input X contains NaN.\n","LinearDiscriminantAnalysis does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n","[ERROR] QDA: Input X contains NaN.\n","QuadraticDiscriminantAnalysis does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n","[ERROR] MLP_small: Input X contains NaN.\n","MLPClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n","[ERROR] GB_meta: Input X contains NaN.\n","GradientBoostingClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n","[ERROR] NaiveBayes: Input X contains NaN.\n","GaussianNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n","      name  AUC  ACC   F1  Sens  Spec  MCC     Brier\n","0  RF_meta  1.0  1.0  1.0   1.0   1.0  1.0  0.013235\n"]}]},{"cell_type":"code","source":["# Proper cross-validated\n","import numpy as np, pandas as pd\n","from sklearn.model_selection import StratifiedKFold, cross_val_score\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, confusion_matrix, matthews_corrcoef, brier_score_loss\n","\n","WORKDIR = \"/content/drive/MyDrive/moltox_project\"\n","meta = pd.read_csv(WORKDIR + \"/meta_oof_true_with_gcn.csv\")\n","y = np.load(WORKDIR + \"/y.npy\")\n","print(\"meta shape:\", meta.shape, \"y shape:\", y.shape)\n","\n","candidates = {\n","    \"LogReg(L2)\": LogisticRegression(class_weight=\"balanced\", solver='lbfgs', max_iter=1000),\n","    \"LDA\": LinearDiscriminantAnalysis(),\n","    \"QDA\": QuadraticDiscriminantAnalysis(),\n","    \"MLP_small\": MLPClassifier(hidden_layer_sizes=(32,), max_iter=500, random_state=42),\n","    \"RF_meta\": RandomForestClassifier(n_estimators=200, class_weight='balanced', random_state=42),\n","    \"GB_meta\": GradientBoostingClassifier(n_estimators=200, random_state=42),\n","    \"NaiveBayes\": GaussianNB()\n","}\n","\n","skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n","results = []\n","for name, clf in candidates.items():\n","    aucs = []; accs = []; f1s = []; sens = []; specs = []; mccs = []; briers = []\n","    for tr, val in skf.split(meta, y):\n","        clf.fit(meta.iloc[tr], y[tr])\n","        if hasattr(clf, \"predict_proba\"):\n","            probs = clf.predict_proba(meta.iloc[val])[:,1]\n","        else:\n","            probs = clf.predict(meta.iloc[val]).astype(float)\n","        preds = (probs >= 0.5).astype(int)\n","\n","        aucs.append(roc_auc_score(y[val], probs))\n","        accs.append(accuracy_score(y[val], preds))\n","        f1s.append(f1_score(y[val], preds))\n","        tn, fp, fn, tp = confusion_matrix(y[val], preds).ravel()\n","        sens.append(tp/(tp+fn) if (tp+fn)>0 else 0)\n","        specs.append(tn/(tn+fp) if (tn+fp)>0 else 0)\n","        mccs.append(matthews_corrcoef(y[val], preds))\n","        briers.append(brier_score_loss(y[val], probs))\n","\n","    results.append({\n","        \"name\": name,\n","        \"AUC\": np.mean(aucs),\n","        \"ACC\": np.mean(accs),\n","        \"F1\": np.mean(f1s),\n","        \"Sens\": np.mean(sens),\n","        \"Spec\": np.mean(specs),\n","        \"MCC\": np.mean(mccs),\n","        \"Brier\": np.mean(briers)\n","    })\n","\n","dfres = pd.DataFrame(results).sort_values(by=[\"AUC\",\"F1\"], ascending=False).reset_index(drop=True)\n","print(dfres.to_string(index=False, float_format=\"%.4f\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":443},"id":"-ClypDbs-EVj","executionInfo":{"status":"error","timestamp":1757630977846,"user_tz":-330,"elapsed":115,"user":{"displayName":"Rishika Ray","userId":"02079523635456342422"}},"outputId":"8903fcac-d2e5-41d9-ebdb-8c7ec3a661a7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["meta shape: (4062, 4) y shape: (4062,)\n"]},{"output_type":"error","ename":"ValueError","evalue":"Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1497165123.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0maucs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0maccs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mf1s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0msens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mspecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mmccs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mbriers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mskf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"predict_proba\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1220\u001b[0m             \u001b[0m_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1222\u001b[0;31m         X, y = validate_data(\n\u001b[0m\u001b[1;32m   1223\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2959\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2960\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2961\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2962\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1368\u001b[0m     \u001b[0mensure_all_finite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deprecate_force_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforce_all_finite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_all_finite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m     X = check_array(\n\u001b[0m\u001b[1;32m   1371\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1107\u001b[0;31m             _assert_all_finite(\n\u001b[0m\u001b[1;32m   1108\u001b[0m                 \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m                 \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m     _assert_all_finite_element_wise(\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0;34m\"#estimators-that-handle-nan-values\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             )\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"]}]},{"cell_type":"code","source":["\n","import os, numpy as np, pandas as pd\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, confusion_matrix, matthews_corrcoef, brier_score_loss\n","\n","WORKDIR = \"/content/drive/MyDrive/moltox_project\"\n","META_FILE = os.path.join(WORKDIR, \"meta_oof_true_with_gcn.csv\")\n","Y_PATH = os.path.join(WORKDIR, \"y.npy\")\n","OUT_CLEAN = os.path.join(WORKDIR, \"meta_oof_true_with_gcn.cleaned.csv\")\n","\n","# 0) Load\n","meta = pd.read_csv(META_FILE)\n","y = np.load(Y_PATH)\n","print(\"Loaded meta shape:\", meta.shape, \"y shape:\", y.shape)\n","print(\"Columns:\", list(meta.columns))\n","\n","# 1) NaN diagnostics\n","nan_counts = meta.isna().sum()\n","print(\"\\nNaN counts per column:\\n\", nan_counts.to_string())\n","\n","rows_with_any_nan = meta.isna().any(axis=1)\n","n_nan_rows = rows_with_any_nan.sum()\n","frac_nan = n_nan_rows / len(meta)\n","print(f\"\\nRows with any NaN: {n_nan_rows} / {len(meta)}  (fraction = {frac_nan:.4f})\")\n","\n","if n_nan_rows > 0:\n","    print(\"\\nSample rows with NaN (first 10):\")\n","    display(meta[rows_with_any_nan].head(10))\n","\n","    bad_idx = np.where(rows_with_any_nan)[0].tolist()\n","    print(\"Bad row indices (first 30):\", bad_idx[:30])\n","\n","THRESH = 0.05\n","action = None\n","if n_nan_rows == 0:\n","    action = \"none\"\n","elif frac_nan <= THRESH:\n","    action = \"drop\"\n","else:\n","    if 'gcn_prob' in meta.columns:\n","        other_cols = [c for c in meta.columns if c.endswith('_prob') and c != 'gcn_prob']\n","        if len(other_cols) >= 2:\n","            action = \"impute_gcn\"\n","        else:\n","            action = \"drop\"\n","    else:\n","        action = \"drop\"\n","\n","print(\"\\nChosen action ->\", action)\n","\n","meta_clean = meta.copy()\n","if action == \"drop\":\n","    print(\"Dropping rows with NaN from both meta and y (will reduce dataset size).\")\n","    keep_mask = ~rows_with_any_nan\n","    meta_clean = meta_clean[keep_mask].reset_index(drop=True)\n","    y_clean = y[keep_mask]\n","elif action == \"impute_gcn\":\n","    print(\"Imputing gcn_prob NaNs with mean of other base probabilities (per-row mean).\")\n","    base_cols = [c for c in meta_clean.columns if c.endswith('_prob') and c != 'gcn_prob']\n","    row_mean = meta_clean[base_cols].mean(axis=1)\n","    meta_clean['gcn_prob'] = meta_clean['gcn_prob'].fillna(row_mean)\n","    y_clean = y.copy()\n","elif action == \"none\":\n","    print(\"No NaNs found; proceeding without modification.\")\n","    meta_clean = meta.copy()\n","    y_clean = y.copy()\n","else:\n","    raise RuntimeError(\"Unknown action\")\n","\n","print(\"After remediation meta_clean shape:\", meta_clean.shape, \"y_clean shape:\", y_clean.shape)\n","meta_clean.to_csv(OUT_CLEAN, index=False)\n","print(\"Saved cleaned meta matrix to:\", OUT_CLEAN)\n","\n","print(\"\\nPost-clean NaN counts:\\n\", meta_clean.isna().sum().to_string())\n","\n","skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n","candidates = {\n","    \"LogReg(L2)\": LogisticRegression(class_weight=\"balanced\", solver='lbfgs', max_iter=1000),\n","    \"LDA\": LinearDiscriminantAnalysis(),\n","    \"QDA\": QuadraticDiscriminantAnalysis(),\n","    \"MLP_small\": MLPClassifier(hidden_layer_sizes=(32,), max_iter=500, random_state=42),\n","    \"RF_meta\": RandomForestClassifier(n_estimators=200, class_weight='balanced', random_state=42),\n","    \"GB_meta\": GradientBoostingClassifier(n_estimators=200, random_state=42),\n","    \"NaiveBayes\": GaussianNB()\n","}\n","\n","results = []\n","X = meta_clean\n","Y = y_clean\n","for name, clf in candidates.items():\n","    aucs, accs, f1s, sens, specs, mccs, briers = [], [], [], [], [], [], []\n","    for tr, val in skf.split(X, Y):\n","        clf.fit(X.iloc[tr], Y[tr])\n","        if hasattr(clf, \"predict_proba\"):\n","            probs = clf.predict_proba(X.iloc[val])[:,1]\n","        else:\n","            probs = clf.predict(X.iloc[val]).astype(float)\n","        preds = (probs >= 0.5).astype(int)\n","\n","        try:\n","            aucs.append(roc_auc_score(Y[val], probs))\n","        except Exception:\n","            aucs.append(float('nan'))\n","        accs.append(accuracy_score(Y[val], preds))\n","        f1s.append(f1_score(Y[val], preds))\n","        tn, fp, fn, tp = confusion_matrix(Y[val], preds).ravel()\n","        sens.append(tp/(tp+fn) if (tp+fn)>0 else 0)\n","        specs.append(tn/(tn+fp) if (tn+fp)>0 else 0)\n","        mccs.append(matthews_corrcoef(Y[val], preds))\n","        briers.append(brier_score_loss(Y[val], probs))\n","\n","    results.append({\n","        \"name\": name,\n","        \"AUC\": np.nanmean(aucs),\n","        \"ACC\": np.mean(accs),\n","        \"F1\": np.mean(f1s),\n","        \"Sens\": np.mean(sens),\n","        \"Spec\": np.mean(specs),\n","        \"MCC\": np.mean(mccs),\n","        \"Brier\": np.mean(briers)\n","    })\n","    print(\"Completed meta:\", name)\n","\n","import pandas as pd\n","dfres = pd.DataFrame(results).sort_values(by=[\"AUC\",\"F1\"], ascending=False).reset_index(drop=True)\n","print(\"\\nMeta-learner comparison AFTER NaN remediation:\")\n","print(dfres.to_string(index=False, float_format='%.4f'))\n","\n","if dfres[['AUC','ACC','F1']].max().max() >= 0.9999:\n","    print(\"\\n***** ALERT: some metrics are ~1.0 after cleaning. Run the earlier diagnostics to check for leakage. *****\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"5AF-UaBX-c7E","executionInfo":{"status":"ok","timestamp":1757631094207,"user_tz":-330,"elapsed":17329,"user":{"displayName":"Rishika Ray","userId":"02079523635456342422"}},"outputId":"78340c83-4661-4776-f05f-cabe0ebd9ad4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded meta shape: (4062, 4) y shape: (4062,)\n","Columns: ['rf_prob', 'lgbm_prob', 'mlp_prob', 'gcn_prob']\n","\n","NaN counts per column:\n"," rf_prob         0\n","lgbm_prob       0\n","mlp_prob        0\n","gcn_prob     4062\n","\n","Rows with any NaN: 4062 / 4062  (fraction = 1.0000)\n","\n","Sample rows with NaN (first 10):\n"]},{"output_type":"display_data","data":{"text/plain":["   rf_prob  lgbm_prob  mlp_prob  gcn_prob\n","0    0.505   0.054440  0.000788       NaN\n","1    0.395   0.074604  0.976633       NaN\n","2    0.280   0.059310  0.067400       NaN\n","3    0.625   0.391126  0.999629       NaN\n","4    0.460   0.304130  0.858056       NaN\n","5    0.505   0.292985  0.127587       NaN\n","6    0.425   0.012757  0.000014       NaN\n","7    0.875   0.975748  0.999894       NaN\n","8    0.780   0.965487  0.998715       NaN\n","9    0.520   0.206818  0.983485       NaN"],"text/html":["\n","  <div id=\"df-daa5ccc7-9f39-4d5a-a0c8-8941b524c24e\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>rf_prob</th>\n","      <th>lgbm_prob</th>\n","      <th>mlp_prob</th>\n","      <th>gcn_prob</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.505</td>\n","      <td>0.054440</td>\n","      <td>0.000788</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.395</td>\n","      <td>0.074604</td>\n","      <td>0.976633</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.280</td>\n","      <td>0.059310</td>\n","      <td>0.067400</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.625</td>\n","      <td>0.391126</td>\n","      <td>0.999629</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.460</td>\n","      <td>0.304130</td>\n","      <td>0.858056</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.505</td>\n","      <td>0.292985</td>\n","      <td>0.127587</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.425</td>\n","      <td>0.012757</td>\n","      <td>0.000014</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.875</td>\n","      <td>0.975748</td>\n","      <td>0.999894</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0.780</td>\n","      <td>0.965487</td>\n","      <td>0.998715</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0.520</td>\n","      <td>0.206818</td>\n","      <td>0.983485</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-daa5ccc7-9f39-4d5a-a0c8-8941b524c24e')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-daa5ccc7-9f39-4d5a-a0c8-8941b524c24e button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-daa5ccc7-9f39-4d5a-a0c8-8941b524c24e');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-4fb1d397-3ec9-447e-81b6-d5c892fe7fe3\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4fb1d397-3ec9-447e-81b6-d5c892fe7fe3')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-4fb1d397-3ec9-447e-81b6-d5c892fe7fe3 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"    print(\\\"\\\\n***** ALERT: some metrics are ~1\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"rf_prob\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.17890407112938114,\n        \"min\": 0.28,\n        \"max\": 0.875,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0.78,\n          0.395,\n          0.425\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lgbm_prob\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3585032471786054,\n        \"min\": 0.012757340001595,\n        \"max\": 0.9757481440287792,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.9654871872072188,\n          0.0746041137946139,\n          0.2929853409911371\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mlp_prob\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4784184864336902,\n        \"min\": 1.3749401516477993e-05,\n        \"max\": 0.9998936798119992,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.9987146143558728,\n          0.9766330873758612,\n          0.1275866238135063\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gcn_prob\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Bad row indices (first 30): [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n","\n","Chosen action -> impute_gcn\n","Imputing gcn_prob NaNs with mean of other base probabilities (per-row mean).\n","After remediation meta_clean shape: (4062, 4) y_clean shape: (4062,)\n","Saved cleaned meta matrix to: /content/drive/MyDrive/moltox_project/meta_oof_true_with_gcn.cleaned.csv\n","\n","Post-clean NaN counts:\n"," rf_prob      0\n","lgbm_prob    0\n","mlp_prob     0\n","gcn_prob     0\n","Completed meta: LogReg(L2)\n","Completed meta: LDA\n","Completed meta: QDA\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 0 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 1 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 0 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 1 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 0 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 1 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 0 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 1 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 0 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 1 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Completed meta: MLP_small\n","Completed meta: RF_meta\n","Completed meta: GB_meta\n","Completed meta: NaiveBayes\n","\n","Meta-learner comparison AFTER NaN remediation:\n","      name    AUC    ACC     F1   Sens   Spec    MCC  Brier\n","       LDA 0.9468 0.8772 0.8988 0.8998 0.8422 0.7429 0.1007\n","   GB_meta 0.9462 0.8735 0.8966 0.9043 0.8260 0.7343 0.0909\n"," MLP_small 0.9450 0.8779 0.8999 0.9051 0.8360 0.7440 0.0901\n","LogReg(L2) 0.9449 0.8779 0.8982 0.8876 0.8629 0.7465 0.0925\n","NaiveBayes 0.9427 0.8712 0.8922 0.8783 0.8604 0.7334 0.1183\n","       QDA 0.9421 0.8754 0.8952 0.8767 0.8735 0.7434 0.1063\n","   RF_meta 0.9406 0.8717 0.8954 0.9043 0.8216 0.7304 0.0940\n"]}]},{"cell_type":"code","source":["import os, traceback, joblib\n","import numpy as np, pandas as pd\n","from sklearn.model_selection import StratifiedKFold, train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, confusion_matrix, matthews_corrcoef, brier_score_loss\n","\n","WORKDIR = \"/content/drive/MyDrive/moltox_project\"\n","META_IN = os.path.join(WORKDIR, \"meta_oof_true_with_gcn.csv\")\n","Y_PATH  = os.path.join(WORKDIR, \"y.npy\")\n","CLEAN_META_OUT = os.path.join(WORKDIR, \"meta_oof_true_with_gcn.cleaned.csv\")\n","CLEAN_Y_OUT = os.path.join(WORKDIR, \"y_clean.npy\")\n","BEST_META_OUT = os.path.join(WORKDIR, \"best_meta_after_clean.joblib\")\n","LOGFILE = os.path.join(WORKDIR, \"final_wrapup.log\")\n","\n","def log(msg):\n","    print(msg)\n","\n","try:\n","    log(\"1) Loading meta and labels...\")\n","    meta = pd.read_csv(META_IN)\n","    y = np.load(Y_PATH)\n","    log(f\"   meta shape: {meta.shape}   y shape: {y.shape}\")\n","    log(\"   columns: \" + \", \".join(meta.columns.tolist()))\n","\n","    log(\"\\n2) NaN diagnostics\")\n","    nan_counts = meta.isna().sum()\n","    log(\"   NaN counts per column:\\n\" + nan_counts.to_string())\n","    rows_with_any_nan = meta.isna().any(axis=1)\n","    n_nan_rows = int(rows_with_any_nan.sum())\n","    frac_nan = n_nan_rows / len(meta)\n","    log(f\"   Rows with any NaN: {n_nan_rows} / {len(meta)} (fraction {frac_nan:.4f})\")\n","    if n_nan_rows > 0:\n","        log(\"   Example rows with NaN (first 6):\")\n","        display(meta[rows_with_any_nan].head(6))\n","\n","    DROP_THRESHOLD = 0.05\n","    action = None\n","    if n_nan_rows == 0:\n","        action = \"none\"\n","    else:\n","        if frac_nan <= DROP_THRESHOLD:\n","            action = \"drop\"\n","        else:\n","            action = \"impute_gcn\"\n","    log(f\"\\n3) Chosen remediation action: {action}\")\n","\n","    meta_clean = meta.copy()\n","    y_clean = y.copy()\n","    if action == \"none\":\n","        log(\"   No NaNs found; nothing to remediate.\")\n","    elif action == \"drop\":\n","        log(\"   Dropping rows with NaNs (safer when only a few rows missing).\")\n","        keep_mask = ~rows_with_any_nan\n","        meta_clean = meta_clean[keep_mask].reset_index(drop=True)\n","        y_clean = y[keep_mask]\n","        np.save(CLEAN_Y_OUT, y_clean)    # save cleaned y\n","        log(f\"   Dropped {n_nan_rows} rows; new meta shape: {meta_clean.shape}; saved cleaned y to {CLEAN_Y_OUT}\")\n","    elif action == \"impute_gcn\":\n","        log(\"   Imputing gcn_prob NaNs using per-row mean of other base probabilities.\")\n","        if \"gcn_prob\" not in meta_clean.columns:\n","            raise RuntimeError(\"gcn_prob column missing; cannot impute.\")\n","        base_cols = [c for c in meta_clean.columns if c.endswith(\"_prob\") and c != \"gcn_prob\"]\n","        if len(base_cols) < 1:\n","            raise RuntimeError(\"Not enough base prob columns for imputation.\")\n","        row_mean = meta_clean[base_cols].mean(axis=1)\n","        meta_clean[\"gcn_prob\"] = meta_clean[\"gcn_prob\"].fillna(row_mean)\n","        log(f\"   Imputed gcn_prob using columns: {base_cols}\")\n","    else:\n","        raise RuntimeError(\"Unknown remediation action\")\n","\n","    meta_clean.to_csv(CLEAN_META_OUT, index=False)\n","    np.save(CLEAN_Y_OUT, y_clean)\n","    log(f\"4) Saved cleaned meta to: {CLEAN_META_OUT}\")\n","    log(f\"   Saved cleaned y to: {CLEAN_Y_OUT}\")\n","\n","    nan_counts_post = meta_clean.isna().sum()\n","    log(\"\\n5) Post-clean NaN counts per column:\\n\" + nan_counts_post.to_string())\n","    if meta_clean.shape[0] != len(y_clean):\n","        raise RuntimeError(f\"Length mismatch after cleaning: meta rows {meta_clean.shape[0]} vs y {len(y_clean)}\")\n","\n","    log(\"\\n6) Evaluating meta-learners via StratifiedKFold CV (5 splits)...\")\n","    X = meta_clean\n","    Y = y_clean\n","    # Candidate meta models\n","    candidates = {\n","        \"LogReg(L2)\": LogisticRegression(class_weight=\"balanced\", solver='lbfgs', max_iter=1000),\n","        \"LDA\": LinearDiscriminantAnalysis(),\n","        \"QDA\": QuadraticDiscriminantAnalysis(),\n","        \"MLP_small\": MLPClassifier(hidden_layer_sizes=(32,), max_iter=500, random_state=42),\n","        \"RF_meta\": RandomForestClassifier(n_estimators=200, class_weight='balanced', random_state=42),\n","        \"GB_meta\": GradientBoostingClassifier(n_estimators=200, random_state=42),\n","        \"NaiveBayes\": GaussianNB()\n","    }\n","\n","    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n","    results = []\n","    for name, clf in candidates.items():\n","        aucs, accs, f1s, sens, specs, mccs, briers = [], [], [], [], [], [], []\n","        for tr, val in skf.split(X, Y):\n","            clf.fit(X.iloc[tr], Y[tr])\n","            if hasattr(clf, \"predict_proba\"):\n","                probs = clf.predict_proba(X.iloc[val])[:,1]\n","            else:\n","                probs = clf.predict(X.iloc[val]).astype(float)\n","            preds = (probs >= 0.5).astype(int)\n","\n","            # Safe metrics\n","            try:\n","                aucs.append(roc_auc_score(Y[val], probs))\n","            except Exception:\n","                aucs.append(float('nan'))\n","            accs.append(accuracy_score(Y[val], preds))\n","            f1s.append(f1_score(Y[val], preds))\n","            tn, fp, fn, tp = confusion_matrix(Y[val], preds).ravel()\n","            sens.append(tp/(tp+fn) if (tp+fn)>0 else 0.0)\n","            specs.append(tn/(tn+fp) if (tn+fp)>0 else 0.0)\n","            mccs.append(matthews_corrcoef(Y[val], preds))\n","            briers.append(brier_score_loss(Y[val], probs))\n","\n","        results.append({\n","            \"name\": name,\n","            \"AUC\": np.nanmean(aucs),\n","            \"ACC\": np.mean(accs),\n","            \"F1\": np.mean(f1s),\n","            \"Sens\": np.mean(sens),\n","            \"Spec\": np.mean(specs),\n","            \"MCC\": np.mean(mccs),\n","            \"Brier\": np.mean(briers)\n","        })\n","        log(f\"   Completed meta: {name}\")\n","\n","    dfres = pd.DataFrame(results).sort_values(by=[\"AUC\",\"F1\"], ascending=False).reset_index(drop=True)\n","    log(\"\\nMeta-learner comparison (CV results):\")\n","    print(dfres.to_string(index=False, float_format=\"%.4f\"))\n","\n","    best_name = dfres.loc[0, \"name\"]\n","    best_clf = candidates[best_name]\n","    best_clf.fit(X, Y)\n","    joblib.dump(best_clf, BEST_META_OUT)\n","    log(f\"\\n7) Saved best meta model: {best_name} -> {BEST_META_OUT}\")\n","\n","    max_metric = dfres[['AUC','ACC','F1']].max().max()\n","    if max_metric >= 0.9999:\n","        log(\"\\n*** WARNING: some metrics are ~1.0 after cleaning — investigate leakage. ***\")\n","    else:\n","        log(\"\\nAll good: no perfect-metric alert.\")\n","\n","    log(\"\\n=== SUMMARY (copy into slides) ===\")\n","    print(f\"- Issue detected: {n_nan_rows} rows had NaN values in meta (fraction {frac_nan:.4f}).\")\n","    if action == \"drop\":\n","        print(\"- Remediation: dropped rows with NaN (safe when few missing).\")\n","    elif action == \"impute_gcn\":\n","        print(\"- Remediation: imputed missing gcn_prob with the per-row mean of other base model probabilities (conservative).\")\n","    else:\n","        print(\"- Remediation: none required.\")\n","\n","    print(f\"- Final meta evaluation (top rows):\\n{dfres.head(5).to_string(index=False)}\")\n","    print(\"\\nSuggested next steps (short bullets):\")\n","    print(\"  1) Re-generate true GCN OOF predictions (replace imputation) by re-running the GCN OOF cell.\")\n","    print(\"  2) Tune GCN & meta hyperparameters (grid/optuna) and try other graph models (MPNN, GAT, AttentiveFP).\")\n","    print(\"  3) Keep a held-out test set (10-20%) untouched until final evaluation for the author/benchmarks.\")\n","    print(\"  4) For slides: show 'problem -> fix -> result' flow, and include the CV table above.\")\n","\n","    log(\"\\nDone. Cleaned files saved:\")\n","    log(\" - cleaned meta: \" + CLEAN_META_OUT)\n","    log(\" - cleaned y:    \" + CLEAN_Y_OUT)\n","    log(\" - best meta:    \" + BEST_META_OUT)\n","\n","except Exception as e:\n","    with open(LOGFILE, \"a\") as lf:\n","        lf.write(\"Exception in final wrapup:\\n\")\n","        lf.write(traceback.format_exc() + \"\\n\")\n","    print(\"ERROR during final wrapup. Traceback saved to\", LOGFILE)\n","    raise"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"SETDFxIr_Oqe","executionInfo":{"status":"ok","timestamp":1757631302590,"user_tz":-330,"elapsed":21128,"user":{"displayName":"Rishika Ray","userId":"02079523635456342422"}},"outputId":"f2e758be-71d7-4f77-b7c4-55863225164c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1) Loading meta and labels...\n","   meta shape: (4062, 4)   y shape: (4062,)\n","   columns: rf_prob, lgbm_prob, mlp_prob, gcn_prob\n","\n","2) NaN diagnostics\n","   NaN counts per column:\n","rf_prob         0\n","lgbm_prob       0\n","mlp_prob        0\n","gcn_prob     4062\n","   Rows with any NaN: 4062 / 4062 (fraction 1.0000)\n","   Example rows with NaN (first 6):\n"]},{"output_type":"display_data","data":{"text/plain":["   rf_prob  lgbm_prob  mlp_prob  gcn_prob\n","0    0.505   0.054440  0.000788       NaN\n","1    0.395   0.074604  0.976633       NaN\n","2    0.280   0.059310  0.067400       NaN\n","3    0.625   0.391126  0.999629       NaN\n","4    0.460   0.304130  0.858056       NaN\n","5    0.505   0.292985  0.127587       NaN"],"text/html":["\n","  <div id=\"df-cd44a2a5-52c9-4adf-8c86-d6611e72c680\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>rf_prob</th>\n","      <th>lgbm_prob</th>\n","      <th>mlp_prob</th>\n","      <th>gcn_prob</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.505</td>\n","      <td>0.054440</td>\n","      <td>0.000788</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.395</td>\n","      <td>0.074604</td>\n","      <td>0.976633</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.280</td>\n","      <td>0.059310</td>\n","      <td>0.067400</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.625</td>\n","      <td>0.391126</td>\n","      <td>0.999629</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.460</td>\n","      <td>0.304130</td>\n","      <td>0.858056</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.505</td>\n","      <td>0.292985</td>\n","      <td>0.127587</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cd44a2a5-52c9-4adf-8c86-d6611e72c680')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-cd44a2a5-52c9-4adf-8c86-d6611e72c680 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-cd44a2a5-52c9-4adf-8c86-d6611e72c680');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-adfde6c2-412d-4aa4-8a3a-69fc9bc9e618\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-adfde6c2-412d-4aa4-8a3a-69fc9bc9e618')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-adfde6c2-412d-4aa4-8a3a-69fc9bc9e618 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"    raise\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"rf_prob\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.116518954109049,\n        \"min\": 0.28,\n        \"max\": 0.625,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.395,\n          0.46,\n          0.28\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lgbm_prob\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.15008865139624505,\n        \"min\": 0.054439534653406,\n        \"max\": 0.3911262725620272,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.054439534653406,\n          0.0746041137946139,\n          0.2929853409911371\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mlp_prob\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.48577947689226986,\n        \"min\": 0.00078775639445,\n        \"max\": 0.9996285830875976,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.00078775639445,\n          0.9766330873758612,\n          0.1275866238135063\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gcn_prob\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","3) Chosen remediation action: impute_gcn\n","   Imputing gcn_prob NaNs using per-row mean of other base probabilities.\n","   Imputed gcn_prob using columns: ['rf_prob', 'lgbm_prob', 'mlp_prob']\n","4) Saved cleaned meta to: /content/drive/MyDrive/moltox_project/meta_oof_true_with_gcn.cleaned.csv\n","   Saved cleaned y to: /content/drive/MyDrive/moltox_project/y_clean.npy\n","\n","5) Post-clean NaN counts per column:\n","rf_prob      0\n","lgbm_prob    0\n","mlp_prob     0\n","gcn_prob     0\n","\n","6) Evaluating meta-learners via StratifiedKFold CV (5 splits)...\n","   Completed meta: LogReg(L2)\n","   Completed meta: LDA\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 0 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 1 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 0 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 1 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 0 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 1 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 0 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 1 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 0 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 1 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["   Completed meta: QDA\n","   Completed meta: MLP_small\n","   Completed meta: RF_meta\n","   Completed meta: GB_meta\n","   Completed meta: NaiveBayes\n","\n","Meta-learner comparison (CV results):\n","      name    AUC    ACC     F1   Sens   Spec    MCC  Brier\n","       LDA 0.9468 0.8772 0.8988 0.8998 0.8422 0.7429 0.1007\n","   GB_meta 0.9462 0.8735 0.8966 0.9043 0.8260 0.7343 0.0909\n"," MLP_small 0.9450 0.8779 0.8999 0.9051 0.8360 0.7440 0.0901\n","LogReg(L2) 0.9449 0.8779 0.8982 0.8876 0.8629 0.7465 0.0925\n","NaiveBayes 0.9427 0.8712 0.8922 0.8783 0.8604 0.7334 0.1183\n","       QDA 0.9421 0.8754 0.8952 0.8767 0.8735 0.7434 0.1063\n","   RF_meta 0.9406 0.8717 0.8954 0.9043 0.8216 0.7304 0.0940\n","\n","7) Saved best meta model: LDA -> /content/drive/MyDrive/moltox_project/best_meta_after_clean.joblib\n","\n","All good: no perfect-metric alert.\n","\n","=== SUMMARY (copy into slides) ===\n","- Issue detected: 4062 rows had NaN values in meta (fraction 1.0000).\n","- Remediation: imputed missing gcn_prob with the per-row mean of other base model probabilities (conservative).\n","- Final meta evaluation (top rows):\n","      name      AUC      ACC       F1     Sens     Spec      MCC    Brier\n","       LDA 0.946816 0.877154 0.898847 0.899797 0.842230 0.742865 0.100717\n","   GB_meta 0.946236 0.873464 0.896634 0.904260 0.825960 0.734310 0.090941\n"," MLP_small 0.945024 0.877892 0.899906 0.905071 0.835972 0.744040 0.090093\n","LogReg(L2) 0.944944 0.877894 0.898160 0.887627 0.862900 0.746527 0.092507\n","NaiveBayes 0.942700 0.871246 0.892187 0.878296 0.860384 0.733433 0.118324\n","\n","Suggested next steps (short bullets):\n","  1) Re-generate true GCN OOF predictions (replace imputation) by re-running the GCN OOF cell.\n","  2) Tune GCN & meta hyperparameters (grid/optuna) and try other graph models (MPNN, GAT, AttentiveFP).\n","  3) Keep a held-out test set (10-20%) untouched until final evaluation for the author/benchmarks.\n","  4) For slides: show 'problem -> fix -> result' flow, and include the CV table above.\n","\n","Done. Cleaned files saved:\n"," - cleaned meta: /content/drive/MyDrive/moltox_project/meta_oof_true_with_gcn.cleaned.csv\n"," - cleaned y:    /content/drive/MyDrive/moltox_project/y_clean.npy\n"," - best meta:    /content/drive/MyDrive/moltox_project/best_meta_after_clean.joblib\n"]}]},{"cell_type":"code","source":["import joblib\n","os.makedirs(os.path.join(WORKDIR,\"models\"), exist_ok=True)\n","joblib.dump(best_rf, os.path.join(WORKDIR,\"models\",\"best_rf.joblib\"))\n","joblib.dump(best_lgb, os.path.join(WORKDIR,\"models\",\"best_lgb.joblib\"))\n","joblib.dump(best_mlp, os.path.join(WORKDIR,\"models\",\"best_mlp.joblib\"))\n","joblib.dump(meta, os.path.join(WORKDIR,\"models\",\"meta_logreg.joblib\"))\n","joblib.dump(scaler, os.path.join(WORKDIR,\"models\",\"scaler.joblib\"))\n","pd.DataFrame(meta_train, columns=['rf_prob','lgbm_prob','mlp_prob']).to_csv(os.path.join(WORKDIR,\"meta_train_oof.csv\"), index=False)\n","print(\"Saved models to\", os.path.join(WORKDIR,\"models\"))\n"],"metadata":{"id":"ZPLOkZObhPWY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","\n","workdir = \"/content/drive/MyDrive/moltox_project\"\n","for f in os.listdir(workdir):\n","    print(f)\n"],"metadata":{"id":"120foDBn_8FX"},"execution_count":null,"outputs":[]}]}