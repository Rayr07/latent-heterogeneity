{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1NOKfQpqblr3sMHTkKmObtyuvpnmlWqtf","timestamp":1767717032672}],"authorship_tag":"ABX9TyN9iZNJMFtLTHs3KDwNDVKb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lmZZK-ou7_wR","executionInfo":{"status":"ok","timestamp":1767716978681,"user_tz":-330,"elapsed":253457,"user":{"displayName":"Rishika Ray","userId":"02079523635456342422"}},"outputId":"2f70f2b8-bb9a-48d8-8661-0e4b910d9b49"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: torch 2.9.0+cpu\n","Uninstalling torch-2.9.0+cpu:\n","  Successfully uninstalled torch-2.9.0+cpu\n","Found existing installation: torchvision 0.24.0+cpu\n","Uninstalling torchvision-0.24.0+cpu:\n","  Successfully uninstalled torchvision-0.24.0+cpu\n","Found existing installation: torchaudio 2.9.0+cpu\n","Uninstalling torchaudio-2.9.0+cpu:\n","  Successfully uninstalled torchaudio-2.9.0+cpu\n","Looking in indexes: https://download.pytorch.org/whl/cu121\n","Collecting torch\n","  Downloading https://download.pytorch.org/whl/cu121/torch-2.5.1%2Bcu121-cp312-cp312-linux_x86_64.whl (780.4 MB)\n","\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m780.4/780.4 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torchvision\n","  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.20.1%2Bcu121-cp312-cp312-linux_x86_64.whl (7.3 MB)\n","\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torchaudio\n","  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.5.1%2Bcu121-cp312-cp312-linux_x86_64.whl (3.4 MB)\n","\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nccl-cu12==2.21.5 (from torch)\n","  Downloading https://download.pytorch.org/whl/nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n","\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting triton==3.1.0 (from torch)\n","  Downloading https://download.pytorch.org/whl/triton-3.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.6 MB)\n","\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m209.6/209.6 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n","Collecting sympy==1.13.1 (from torch)\n","  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n","  Downloading https://download.pytorch.org/whl/nvidia_nvjitlink_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n","Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n","\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading https://download.pytorch.org/whl/nvidia_nvjitlink_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.7 MB)\n","\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m39.7/39.7 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n","  Attempting uninstall: sympy\n","    Found existing installation: sympy 1.14.0\n","    Uninstalling sympy-1.14.0:\n","      Successfully uninstalled sympy-1.14.0\n","  Attempting uninstall: nvidia-nccl-cu12\n","    Found existing installation: nvidia-nccl-cu12 2.28.9\n","    Uninstalling nvidia-nccl-cu12-2.28.9:\n","      Successfully uninstalled nvidia-nccl-cu12-2.28.9\n","Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.9.86 nvidia-nvtx-cu12-12.1.105 sympy-1.13.1 torch-2.5.1+cu121 torchaudio-2.5.1+cu121 torchvision-0.20.1+cu121 triton-3.1.0\n","Collecting pydicom\n","  Downloading pydicom-3.0.1-py3-none-any.whl.metadata (9.4 kB)\n","Collecting lifelines\n","  Downloading lifelines-0.30.0-py3-none-any.whl.metadata (3.2 kB)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n","Requirement already satisfied: openpyxl in /usr/local/lib/python3.12/dist-packages (3.1.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (1.5.3)\n","Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from lifelines) (2.0.2)\n","Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from lifelines) (1.16.3)\n","Requirement already satisfied: pandas>=2.1 in /usr/local/lib/python3.12/dist-packages (from lifelines) (2.2.2)\n","Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.12/dist-packages (from lifelines) (3.10.0)\n","Requirement already satisfied: autograd>=1.5 in /usr/local/lib/python3.12/dist-packages (from lifelines) (1.8.0)\n","Collecting autograd-gamma>=0.3 (from lifelines)\n","  Downloading autograd-gamma-0.5.0.tar.gz (4.0 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting formulaic>=0.2.2 (from lifelines)\n","  Downloading formulaic-1.2.1-py3-none-any.whl.metadata (7.0 kB)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n","Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.12/dist-packages (from openpyxl) (2.0.0)\n","Collecting interface-meta>=1.2.0 (from formulaic>=0.2.2->lifelines)\n","  Downloading interface_meta-1.3.0-py3-none-any.whl.metadata (6.7 kB)\n","Requirement already satisfied: narwhals>=1.17 in /usr/local/lib/python3.12/dist-packages (from formulaic>=0.2.2->lifelines) (2.13.0)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.12/dist-packages (from formulaic>=0.2.2->lifelines) (4.15.0)\n","Requirement already satisfied: wrapt>=1.0 in /usr/local/lib/python3.12/dist-packages (from formulaic>=0.2.2->lifelines) (2.0.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0->lifelines) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0->lifelines) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0->lifelines) (4.61.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0->lifelines) (1.4.9)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0->lifelines) (25.0)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0->lifelines) (11.3.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0->lifelines) (3.2.5)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0->lifelines) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.1->lifelines) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.1->lifelines) (2025.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0->lifelines) (1.17.0)\n","Downloading pydicom-3.0.1-py3-none-any.whl (2.4 MB)\n","\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lifelines-0.30.0-py3-none-any.whl (349 kB)\n","\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m349.3/349.3 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading formulaic-1.2.1-py3-none-any.whl (117 kB)\n","\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m117.3/117.3 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading interface_meta-1.3.0-py3-none-any.whl (14 kB)\n","Building wheels for collected packages: autograd-gamma\n","  Building wheel for autograd-gamma (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for autograd-gamma: filename=autograd_gamma-0.5.0-py3-none-any.whl size=4030 sha256=15c014a8464319310802552d8886c824d61fecd8e1639d5a1de5da6119337d0c\n","  Stored in directory: /root/.cache/pip/wheels/50/37/21/0a719b9d89c635e89ff24bd93b862882ad675279552013b2fb\n","Successfully built autograd-gamma\n","Installing collected packages: pydicom, interface-meta, autograd-gamma, formulaic, lifelines\n","Successfully installed autograd-gamma-0.5.0 formulaic-1.2.1 interface-meta-1.3.0 lifelines-0.30.0 pydicom-3.0.1\n"]}],"source":["# Restart runtime after this cell\n","!pip uninstall -y torch torchvision torchaudio\n","!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n","!pip install pydicom lifelines scikit-learn openpyxl tqdm joblib\n"]},{"cell_type":"code","source":["import os, json, numpy as np, pandas as pd, torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","from tqdm import tqdm\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Device:\", device)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hFwJ9Odq9RVd","executionInfo":{"status":"ok","timestamp":1767716986332,"user_tz":-330,"elapsed":7647,"user":{"displayName":"Rishika Ray","userId":"02079523635456342422"}},"outputId":"ad7b9866-4b6a-4d69-8288-ae2244917216"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Device: cpu\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tmyjYRf0-KMF","executionInfo":{"status":"ok","timestamp":1767717030344,"user_tz":-330,"elapsed":44009,"user":{"displayName":"Rishika Ray","userId":"02079523635456342422"}},"outputId":"88db5658-607f-4bae-cd27-18b09e711f6f"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import os\n","\n","# ===== PATHS =====\n","BASE = \"/content/drive/MyDrive/personalised survival treatment\"\n","EXCEL_PATH = os.path.join(BASE, \"I-SPY-1-All-Patient-Clinical-and-Outcome-Data.xlsx\")\n","CLIN_ARRAY_PATH = os.path.join(BASE, \"embeddings\", \"ispy1_clinical_array_processed.npy\")\n","\n","OUT_DIR = os.path.join(BASE, \"clinical\")\n","os.makedirs(OUT_DIR, exist_ok=True)\n","OUT_CSV = os.path.join(OUT_DIR, \"clinical_processed.csv\")\n","\n","# ===== LOAD EXCEL (SURVIVAL LABELS) =====\n","df = pd.read_excel(EXCEL_PATH, sheet_name=3, engine=\"openpyxl\")\n","\n","df = df.rename(columns={\n","    \"SUBJECTID\": \"patient_id\",\n","    \"RFS\": \"time\",\n","    \"rfs_ind\": \"event\"\n","})[[\"patient_id\", \"time\", \"event\"]]\n","\n","df[\"patient_id\"] = df[\"patient_id\"].astype(str)\n","df[\"time\"] = pd.to_numeric(df[\"time\"], errors=\"coerce\")\n","df[\"event\"] = pd.to_numeric(df[\"event\"], errors=\"coerce\").fillna(0).astype(int)\n","\n","df = df.dropna(subset=[\"time\"])\n","\n","print(\"Loaded survival labels:\", df.shape)\n","\n","# ===== LOAD PROCESSED CLINICAL FEATURES =====\n","X = np.load(CLIN_ARRAY_PATH)\n","print(\"Clinical feature array shape:\", X.shape)\n","\n","assert len(df) == X.shape[0], \"Mismatch between clinical rows and feature array!\"\n","\n","# ===== BUILD FINAL DATAFRAME =====\n","clin_feat_df = pd.DataFrame(\n","    X,\n","    index=df[\"patient_id\"].values,\n","    columns=[f\"clin_{i}\" for i in range(X.shape[1])]\n",")\n","\n","final_df = pd.concat(\n","    [df.set_index(\"patient_id\"), clin_feat_df],\n","    axis=1\n",")\n","\n","final_df.to_csv(OUT_CSV)\n","print(\"Saved:\", OUT_CSV)\n","print(\"Final clinical shape:\", final_df.shape)\n"],"metadata":{"id":"5WK_LJ3p_m7j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import pandas as pd\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","from sklearn.impute import SimpleImputer\n","\n","# ---------- PATHS ----------\n","BASE = \"/content/drive/MyDrive/personalised survival treatment\"\n","EXCEL_PATH = f\"{BASE}/I-SPY-1-All-Patient-Clinical-and-Outcome-Data.xlsx\"\n","\n","# ---------- LOAD BASELINE CLINICAL (Sheet 1) ----------\n","df_clin_raw = pd.read_excel(\n","    EXCEL_PATH,\n","    sheet_name=1,\n","    engine=\"openpyxl\"\n",")\n","\n","BASELINE_COLS = [\n","    \"SUBJECTID\",\n","    \"age\",\n","    \"race_id\",\n","    \"ERpos\",\n","    \"PgRpos\",\n","    \"HR Pos\",\n","    \"Her2MostPos\",\n","    \"HR_HER2_CATEGORY\",\n","    \"HR_HER2_STATUS\",\n","    \"BilateralCa\",\n","    \"Laterality\",\n","    \"MRI LD Baseline\"\n","]\n","\n","df_base = df_clin_raw[BASELINE_COLS].copy()\n","df_base = df_base.rename(columns={\"SUBJECTID\": \"patient_id\"})\n","df_base[\"patient_id\"] = df_base[\"patient_id\"].astype(str)\n","\n","print(\"Baseline df shape:\", df_base.shape)\n","\n","# ---------- LOAD OUTCOMES (Sheet 3) ----------\n","df_out = pd.read_excel(\n","    EXCEL_PATH,\n","    sheet_name=3,\n","    engine=\"openpyxl\"\n",")\n","\n","df_out = df_out.rename(columns={\n","    \"SUBJECTID\": \"patient_id\",\n","    \"RFS\": \"time\",\n","    \"rfs_ind\": \"event\"\n","})\n","\n","df_out[\"patient_id\"] = df_out[\"patient_id\"].astype(str)\n","df_out[\"time\"] = pd.to_numeric(df_out[\"time\"], errors=\"coerce\")\n","df_out[\"event\"] = pd.to_numeric(df_out[\"event\"], errors=\"coerce\").fillna(0).astype(int)\n","\n","print(\"Outcome df shape:\", df_out.shape)\n","\n","# ---------- PREPROCESS BASELINE FEATURES ----------\n","num_cols = df_base.select_dtypes(include=[\"int64\", \"float64\"]).columns\n","cat_cols = df_base.select_dtypes(include=[\"object\"]).columns.drop(\"patient_id\")\n","\n","preproc = ColumnTransformer(\n","    transformers=[\n","        (\"num\", SimpleImputer(strategy=\"median\"), num_cols),\n","        (\"cat\", Pipeline([\n","            (\"impute\", SimpleImputer(strategy=\"most_frequent\")),\n","            (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n","        ]), cat_cols)\n","    ]\n",")\n","\n","X = preproc.fit_transform(df_base)\n","\n","feature_names = (\n","    list(num_cols) +\n","    list(\n","        preproc.named_transformers_[\"cat\"]\n","        .named_steps[\"onehot\"]\n","        .get_feature_names_out(cat_cols)\n","    )\n",")\n","\n","clin_feat_df = pd.DataFrame(\n","    X.toarray() if hasattr(X, \"toarray\") else X,\n","    columns=feature_names,\n","    index=df_base[\"patient_id\"]\n",")\n","\n","print(\"Clinical feature df shape:\", clin_feat_df.shape)\n","\n","# ---------- MERGE FEATURES + SURVIVAL ----------\n","clinical_baseline_df = (\n","    df_out.set_index(\"patient_id\")\n","    .join(clin_feat_df, how=\"inner\")\n",")\n","\n","# 沐･ FINAL NaN PURGE (MANDATORY)\n","clinical_baseline_df = clinical_baseline_df.fillna(0.0)\n","\n","# Absolute sanity check\n","assert not clinical_baseline_df.isna().any().any(), \"NaNs still present in clinical data\"\n","\n","\n","print(\"FINAL baseline clinical df shape:\", clinical_baseline_df.shape)\n","\n","# ---------- SAVE (STEP E) ----------\n","OUT_DIR = f\"{BASE}/clinical\"\n","os.makedirs(OUT_DIR, exist_ok=True)\n","\n","OUT_PATH = f\"{OUT_DIR}/clinical_baseline_processed.csv\"\n","clinical_baseline_df.to_csv(OUT_PATH)\n","\n","print(\"笨 SAVED:\", OUT_PATH)\n"],"metadata":{"id":"qNdGcqzONSNU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Columns that must NEVER be used as model inputs\n","leak_cols = [\n","    \"time\", \"event\",\n","    \"ERpos\", \"PgRpos\", \"HR Pos\", \"Her2MostPos\",\n","    \"HR_HER2_STATUS_HER2pos\", \"HR_HER2_STATUS_HRposHER2neg\"\n","]\n","\n","# Keep only safe baseline features\n","safe_clin_cols = [c for c in clinical_baseline_df.columns if c not in leak_cols]\n","\n","print(\"Clinical features used:\", len(safe_clin_cols))\n"],"metadata":{"id":"RN-9kIoXLFSu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Remove datetime columns safely\n","datetime_cols = clinical_baseline_df[safe_clin_cols].select_dtypes(\n","    include=[\"datetime64[ns]\", \"datetime64\"]\n",").columns.tolist()\n","\n","print(\"Dropping datetime columns:\", datetime_cols)\n","\n","safe_clin_cols = [c for c in safe_clin_cols if c not in datetime_cols]\n"],"metadata":{"id":"NHIwMxpgMzo6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["clinical_input_df = clinical_baseline_df[safe_clin_cols].select_dtypes(include=[np.number])\n","\n","print(\"Clinical input shape:\", clinical_input_df.shape)\n","print(\"Any non-numeric left:\",\n","      clinical_input_df.select_dtypes(exclude=[np.number]).shape[1])"],"metadata":{"id":"_fInyA_5Ldb4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["assert clinical_input_df.select_dtypes(include=[\"datetime64\", \"object\"]).shape[1] == 0\n"],"metadata":{"id":"Ug3iIlFhO7lz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def subtype_label(row):\n","    hr = (row[\"ERpos\"] == 1) or (row[\"PgRpos\"] == 1)\n","    her2 = (row[\"Her2MostPos\"] == 1)\n","\n","    if hr and not her2:\n","        return 0  # HR+/HER2-\n","    elif hr and her2:\n","        return 1  # HR+/HER2+\n","    elif (not hr) and her2:\n","        return 2  # HR-/HER2+\n","    else:\n","        return 3  # HR-/HER2- (TNBC)\n","\n","clinical_baseline_df[\"treat_label\"] = clinical_baseline_df.apply(\n","    subtype_label, axis=1\n",")\n","\n","print(clinical_baseline_df[\"treat_label\"].value_counts())\n"],"metadata":{"id":"Cyyo5QQsuiYP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ===== ROOT =====\n","DRIVE_BASE = \"/content/drive/MyDrive/personalised survival treatment\"\n","\n","# ===== IMAGE EMBEDDINGS (CONFIRMED) =====\n","IMG_EMB_DIR = \"/content/drive/MyDrive/personalised survival treatment/ispy1_embeddings\"\n","\n","# ===== CLINICAL DATA =====\n","CLIN_DIR  = os.path.join(DRIVE_BASE, \"clinical\")\n","CLIN_PATH = \"/content/drive/MyDrive/personalised survival treatment/clinical/clinical_baseline_processed.csv\"\n","\n","\n","# ===== MASTER TABLE (WILL BE CREATED) =====\n","MASTER_CSV = os.path.join(DRIVE_BASE, \"master_table.csv\")\n","\n","print(\"IMG_EMB_DIR exists:\", os.path.exists(IMG_EMB_DIR))\n","print(\"Number of image files:\", len(os.listdir(IMG_EMB_DIR)))\n","print(\"CLIN_PATH exists:\", os.path.exists(CLIN_PATH))\n"],"metadata":{"id":"8AvgZurc9Uno"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["img_map = {}\n","bad_imgs = []\n","\n","for f in os.listdir(IMG_EMB_DIR):\n","    if not f.endswith(\".npy\"):\n","        continue\n","    pid = f.replace(\".npy\", \"\")\n","    arr = np.load(os.path.join(IMG_EMB_DIR, f))\n","    if arr.shape != (512,) or np.isnan(arr).any():\n","        bad_imgs.append(pid)\n","        continue\n","    img_map[pid] = os.path.join(IMG_EMB_DIR, f)\n","\n","print(\"Valid image embeddings:\", len(img_map))\n","print(\"Bad image embeddings:\", len(bad_imgs))\n"],"metadata":{"id":"aKA14w4-AMcA"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"abbc1bb3"},"source":["from sklearn.model_selection import KFold\n","\n","def train_and_evaluate_fold(fold_idx, train_ids_fold, val_ids_fold, full_master_df, clinical_input_df, num_epochs=15, lr=5e-5):\n","\n","    print(f\"\\n--- Starting Fold {fold_idx + 1} ---\")\n","\n","    # Create train and validation DataFrames for the current fold\n","    train_df_fold = full_master_df[full_master_df[\"patient_id\"].isin(train_ids_fold)].reset_index(drop=True)\n","    val_df_fold   = full_master_df[full_master_df[\"patient_id\"].isin(val_ids_fold)].reset_index(drop=True)\n","\n","    # Create datasets and loaders for the current fold\n","    train_ds_fold = SurvivalDataset(train_df_fold, clinical_input_df)\n","    val_ds_fold   = SurvivalDataset(val_df_fold, clinical_input_df)\n","\n","    train_loader_fold = DataLoader(\n","        train_ds_fold,\n","        batch_size=16,\n","        shuffle=True,\n","        drop_last=True\n","    )\n","    val_loader_fold   = DataLoader(val_ds_fold, batch_size=len(val_ds_fold), shuffle=False)\n","\n","    # Re-initialize model and optimizer for each fold\n","    model_fold = FusionSurvTreatModel(\n","        clin_dim=clinical_input_df.shape[1]\n","    ).to(device)\n","    opt_fold = torch.optim.Adam(\n","        model_fold.parameters(),\n","        lr=lr\n","    )\n","\n","    # Training loop for the fold\n","    for epoch in range(num_epochs):\n","        model_fold.train()\n","        train_loss = 0\n","\n","        for b in train_loader_fold:\n","            if b[\"event\"].sum() == 0:\n","                continue\n","\n","            img = b[\"img\"].to(device)\n","            clin = b[\"clin\"].to(device)\n","            time = b[\"time\"].to(device)\n","            event = b[\"event\"].to(device)\n","            treat_label = b[\"treat_label\"].to(device)\n","\n","            risk, treat_logits = model_fold(clin, img)\n","\n","            if torch.isnan(risk).any() or torch.isnan(treat_logits).any():\n","                raise RuntimeError(\"NaN detected in model outputs\")\n","\n","            loss = multitask_loss(\n","                risk,\n","                time,\n","                event,\n","                torch.clamp(treat_logits, -10, 10),\n","                treat_label,\n","                alpha=0.25\n","            )\n","\n","            opt_fold.zero_grad()\n","            loss.backward()\n","            opt_fold.step()\n","            torch.nn.utils.clip_grad_norm_(model_fold.parameters(), 1.0)\n","            train_loss += loss.item()\n","\n","        print(f\"Fold {fold_idx + 1}, Epoch {epoch+1}: train loss = {train_loss/len(train_loader_fold):.4f}\")\n","\n","    # Evaluation for the fold\n","    model_fold.eval()\n","    all_risk, all_time, all_event = [], [], []\n","    all_logits, all_labels = [], []\n","\n","    with torch.no_grad():\n","        for b in val_loader_fold:\n","            img = b[\"img\"].to(device)\n","            clin = b[\"clin\"].to(device)\n","\n","            time = b[\"time\"].cpu().numpy()\n","            event = b[\"event\"].cpu().numpy()\n","            labels = b[\"treat_label\"].cpu().numpy()\n","\n","            risk, treat_logits = model_fold(clin, img)\n","\n","            all_risk.extend(risk.cpu().numpy())\n","            all_time.extend(time)\n","            all_event.extend(event)\n","\n","            all_logits.append(treat_logits.cpu().numpy())\n","            all_labels.append(labels)\n","\n","    val_cindex = concordance_index(\n","        all_time,\n","        -np.array(all_risk),\n","        all_event\n","    )\n","\n","    all_logits = np.vstack(all_logits)\n","    all_labels = np.concatenate(all_labels)\n","\n","    probs = softmax(all_logits, axis=1)\n","\n","    macro_auc = roc_auc_score(\n","        all_labels,\n","        probs,\n","        multi_class=\"ovr\",\n","        average=\"macro\"\n","    )\n","\n","    preds = np.argmax(probs, axis=1)\n","    acc = accuracy_score(all_labels, preds)\n","\n","    print(f\"Fold {fold_idx + 1} Results:\")\n","    print(f\"  Validation C-index (survival): {val_cindex:.4f}\")\n","    print(f\"  Validation Macro ROC-AUC (subtype): {macro_auc:.4f}\")\n","    print(f\"  Validation Accuracy (subtype): {acc:.4f}\")\n","\n","    return val_cindex, macro_auc, acc"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ca69f90c"},"source":["# Prepare data for KFold\n","all_patient_ids = patient_event[\"patient_id\"].values\n","all_events = patient_event[\"event\"].values\n","\n","# KFold setup\n","n_splits = 5\n","kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n","\n","# Lists to store results from each fold\n","all_cindex_scores = []\n","all_macro_auc_scores = []\n","all_accuracy_scores = []\n","\n","# Perform K-fold cross-validation\n","for fold_idx, (train_index, val_index) in enumerate(kf.split(all_patient_ids, all_events)):\n","    train_ids_fold = all_patient_ids[train_index]\n","    val_ids_fold   = all_patient_ids[val_index]\n","\n","    cindex, macro_auc, acc = train_and_evaluate_fold(\n","        fold_idx,\n","        train_ids_fold,\n","        val_ids_fold,\n","        master_df, # Use the original master_df which has all patients\n","        clinical_input_df\n","    )\n","\n","    all_cindex_scores.append(cindex)\n","    all_macro_auc_scores.append(macro_auc)\n","    all_accuracy_scores.append(acc)\n","\n","# Print average results\n","print(\"\\n=== Average K-Fold Results ===\")\n","print(f\"Average C-index: {np.mean(all_cindex_scores):.4f} \\u00B1 {np.std(all_cindex_scores):.4f}\")\n","print(f\"Average Macro ROC-AUC: {np.mean(all_macro_auc_scores):.4f} \\u00B1 {np.std(all_macro_auc_scores):.4f}\")\n","print(f\"Average Accuracy: {np.mean(all_accuracy_scores):.4f} \\u00B1 {np.std(all_accuracy_scores):.4f}\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["clinical_df = pd.read_csv(CLIN_PATH, index_col=0)\n","\n","# index is patient_id, just normalize format\n","clinical_df.index = clinical_df.index.astype(str)\n","clinical_df.index.name = \"patient_id\"\n","\n","print(\"Clinical DF shape:\", clinical_df.shape)\n","print(\"Index name:\", clinical_df.index.name)\n","print(\"First 5 patient IDs:\", clinical_df.index[:5].tolist())\n"],"metadata":{"id":"p8joFKemARiw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ===== Treatment-response proxy =====\n","# 1 = good outcome (no recurrence by 3 years), 0 = poor\n","\n","RESPONSE_TIME = 36 * 30  # ~3 years in days\n","\n","clinical_df[\"treat_response\"] = (\n","    (clinical_df[\"time\"] >= RESPONSE_TIME) & (clinical_df[\"event\"] == 0)\n",").astype(int)\n","\n","print(clinical_df[\"treat_response\"].value_counts())\n"],"metadata":{"id":"AjuoWl79FjxO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["rows = []\n","\n","for fname in os.listdir(IMG_EMB_DIR):\n","    if not fname.endswith(\".npy\"):\n","        continue\n","\n","    raw_pid = fname.replace(\".npy\", \"\")      # ISPY1_1001\n","    pid = raw_pid.replace(\"ISPY1_\", \"\")      # 1001\n","\n","    if pid not in clinical_df.index:\n","        continue\n","\n","    rows.append({\n","        \"patient_id\": pid,\n","        \"img_path\": os.path.join(IMG_EMB_DIR, fname),\n","        \"time\": clinical_df.loc[pid, \"time\"],\n","        \"event\": clinical_df.loc[pid, \"event\"]\n","    })\n","\n","master_df = pd.DataFrame(rows)\n","master_df.to_csv(MASTER_CSV, index=False)\n","\n","print(\"Master table size:\", master_df.shape)\n","master_df.head()\n"],"metadata":{"id":"4AR4ccdAA_C0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Ensure patient_id is index in clinical_baseline_df\n","assert clinical_baseline_df.index.name == \"patient_id\"\n","\n","# Merge treat_label into master_df\n","master_df = master_df.merge(\n","    clinical_baseline_df[[\"treat_label\"]],\n","    left_on=\"patient_id\",\n","    right_index=True,\n","    how=\"left\"\n",")\n","\n","print(master_df[\"treat_label\"].value_counts())\n"],"metadata":{"id":"kvnDW3mn0qs6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# One row per patient with event indicator\n","patient_event = (\n","    clinical_baseline_df[[\"event\"]]\n","    .reset_index()\n",")\n","\n","print(patient_event[\"event\"].value_counts())\n"],"metadata":{"id":"rvzImRdbcg05"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","train_ids, val_ids = train_test_split(\n","    patient_event[\"patient_id\"],\n","    test_size=0.2,\n","    random_state=42,\n","    stratify=patient_event[\"event\"]   # 沐･ THIS IS THE KEY\n",")\n","\n","print(\"Train event counts:\")\n","print(patient_event[patient_event[\"patient_id\"].isin(train_ids)][\"event\"].value_counts())\n","\n","print(\"\\nVal event counts:\")\n","print(patient_event[patient_event[\"patient_id\"].isin(val_ids)][\"event\"].value_counts())\n"],"metadata":{"id":"uctVLeQAZtUp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df = master_df[master_df[\"patient_id\"].isin(train_ids)].reset_index(drop=True)\n","val_df   = master_df[master_df[\"patient_id\"].isin(val_ids)].reset_index(drop=True)\n","\n","print(\"Train rows:\", train_df.shape)\n","print(\"Val rows:\", val_df.shape)\n"],"metadata":{"id":"jy27GzEdJpS3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class SurvivalDataset(Dataset):\n","    def __init__(self, master_df, clinical_df):\n","        self.df = master_df.reset_index(drop=True)\n","        self.clin = clinical_df.select_dtypes(include=[np.number])  # 沐 hard safety\n","\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        r = self.df.iloc[idx]\n","        pid = r.patient_id\n","\n","        img = np.load(r.img_path).astype(\"float32\")\n","        clin = (\n","          self.clin.loc[pid]\n","          .values\n","          .astype(\"float32\")\n","        )\n","\n","\n","        return {\n","                \"img\": torch.tensor(img),\n","                \"clin\": torch.tensor(clin),\n","                \"time\": torch.tensor(r.time, dtype=torch.float32),\n","                \"event\": torch.tensor(r.event, dtype=torch.float32),\n","                \"treat_label\": torch.tensor(r.treat_label, dtype=torch.long)\n","\n","\n","          }\n","\n"],"metadata":{"id":"jwrN6rpdBDQP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Joint Fusion Model"],"metadata":{"id":"Z6Pma9nF8aYi"}},{"cell_type":"code","source":["#final\n","train_ds = SurvivalDataset(train_df, clinical_input_df)\n","val_ds   = SurvivalDataset(val_df, clinical_input_df)\n","\n","train_loader = DataLoader(\n","    train_ds,\n","    batch_size=16,\n","    shuffle=True,\n","    drop_last=True\n",")\n","\n","val_loader   = DataLoader(val_ds, batch_size=len(val_ds), shuffle=False)\n"],"metadata":{"id":"Q9gl1AslHdzX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["b = next(iter(train_loader))\n","print(\"Clinical dtype:\", b[\"clin\"].dtype)\n","print(\"Clinical shape:\", b[\"clin\"].shape)\n","print(\"Any NaN:\", torch.isnan(b[\"clin\"]).any().item())\n"],"metadata":{"id":"Jofr5L-a0dSk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ds = SurvivalDataset(master_df, clinical_input_df)\n","loader = DataLoader(ds, batch_size=8, shuffle=True)\n","\n","batch = next(iter(loader))\n","print(batch[\"img\"].shape)\n","print(batch[\"clin\"].shape)\n"],"metadata":{"id":"8Oo0Z3U-X7WD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ds = SurvivalDataset(master_df, clinical_df)\n","loader = DataLoader(ds, batch_size=8, shuffle=True)\n","\n","batch = next(iter(loader))\n","print(batch[\"img\"].shape)     # (B, 512)\n","print(batch[\"clin\"].shape)    # (B, clin_dim)\n","print(batch[\"time\"][:5])\n","print(batch[\"event\"][:5])\n"],"metadata":{"id":"Z66h1YwFBEBJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","\n","class FusionSurvTreatModel(nn.Module):\n","    def __init__(self, clin_dim, img_dim=512):\n","        super().__init__()\n","\n","        # Clinical branch\n","        self.clin_proj = nn.Sequential(\n","            nn.Linear(clin_dim, 128),\n","            nn.ReLU()\n","        )\n","\n","        # Image branch\n","        self.img_proj = nn.Sequential(\n","            nn.Linear(img_dim, 128),\n","            nn.ReLU()\n","        )\n","\n","        fusion_dim = 256\n","\n","        # 沐･ Shared fusion representation\n","        self.shared_fusion = nn.Sequential(\n","            nn.Linear(fusion_dim, 128),\n","            nn.LayerNorm(128),\n","            nn.ReLU(),\n","            nn.Dropout(p=0.2)\n","        )\n","\n","        # Survival head\n","        self.surv_head = nn.Linear(128, 1)\n","\n","        # Subtype head (4-class)\n","        self.treat_head = nn.Linear(128, 4)\n","\n","    def forward(self, clin, img):\n","        c = self.clin_proj(clin)\n","        i = self.img_proj(img)\n","\n","        x = torch.cat([c, i], dim=1)     # (B, 256)\n","        z = self.shared_fusion(x)        # (B, 128)\n","\n","        risk = self.surv_head(z).squeeze(-1)\n","        treat_logits = self.treat_head(z)\n","\n","        return risk, treat_logits\n"],"metadata":{"id":"EaMI43HNBGhd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bce = nn.BCEWithLogitsLoss()\n","\n","def multitask_loss(risk, time, event, response_logit, response):\n","    loss_surv = cox_ph_loss(risk, time, event)\n","    loss_resp = bce(response_logit, response)\n","\n","    # Survival is primary, treatment head is auxiliary\n","    return loss_surv + 0.3 * loss_resp\n"],"metadata":{"id":"O-fwr63sGMGU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def cox_ph_loss(risk, time, event):\n","    order = torch.argsort(time, descending=True)\n","    risk = torch.clamp(risk[order], -20, 20)\n","    event = event[order]\n","\n","    log_cumsum = torch.logcumsumexp(risk, dim=0)\n","    loss = -(risk - log_cumsum) * event\n","    return loss.sum() / (event.sum() + 1e-8)\n"],"metadata":{"id":"BBc1h0VZBIU0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch.nn.functional as F\n","\n","def multitask_loss(risk, time, event, treat_logits, treat_label, alpha=0.25):\n","    surv_loss = cox_ph_loss(risk, time, event)\n","    treat_loss = F.cross_entropy(treat_logits, treat_label)\n","    return surv_loss + alpha * treat_loss\n"],"metadata":{"id":"1DUTEC0TwXf6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(b[\"treat_label\"].dtype)\n"],"metadata":{"id":"V5PykT5izlCr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch = next(iter(loader))\n","print(batch.keys())\n"],"metadata":{"id":"owwEu-HRHoco"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = FusionSurvTreatModel(\n","    clin_dim=train_ds.clin.shape[1]\n",").to(device)\n","\n","opt = torch.optim.Adam(\n","    model.parameters(),\n","    lr=5e-5\n",")\n"],"metadata":{"id":"ZgMn0RYDBNmT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(model.treat_head)\n","print(model.surv_head)"],"metadata":{"id":"1Df-JGTmyfx0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for epoch in range(15):\n","    model.train()\n","    train_loss = 0\n","\n","    for b in train_loader:\n","      if b[\"event\"].sum() == 0:\n","        continue\n","\n","      img = b[\"img\"].to(device)\n","      clin = b[\"clin\"].to(device)\n","      time = b[\"time\"].to(device)\n","      event = b[\"event\"].to(device)\n","      treat_label = b[\"treat_label\"].to(device)\n","\n","      risk, treat_logits = model(clin, img)\n","\n","      if torch.isnan(risk).any() or torch.isnan(treat_logits).any():\n","          raise RuntimeError(\"NaN detected in model outputs\")\n","\n","\n","      loss = multitask_loss(\n","            risk,\n","            time,\n","            event,\n","            torch.clamp(treat_logits, -10, 10),\n","            treat_label,\n","            alpha=0.25\n","        )\n","\n","      opt.zero_grad()\n","      loss.backward()\n","\n","      opt.step()\n","      torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","      train_loss += loss.item()\n","\n","    print(f\"Epoch {epoch+1}: train loss = {train_loss/len(train_loader):.4f}\")\n","\n"],"metadata":{"id":"memfTSBIxQWn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from lifelines.utils import concordance_index\n","from sklearn.metrics import roc_auc_score, accuracy_score\n","from scipy.special import softmax\n","import numpy as np\n","import torch\n","\n","model.eval()\n","\n","# -------------------------\n","# Containers\n","# -------------------------\n","all_risk = []\n","all_time = []\n","all_event = []\n","\n","all_logits = []\n","all_labels = []\n","\n","# -------------------------\n","# Forward pass on val set\n","# -------------------------\n","with torch.no_grad():\n","    for b in val_loader:\n","        img = b[\"img\"].to(device)\n","        clin = b[\"clin\"].to(device)\n","\n","        time = b[\"time\"].cpu().numpy()\n","        event = b[\"event\"].cpu().numpy()\n","        labels = b[\"treat_label\"].cpu().numpy()\n","\n","        risk, treat_logits = model(clin, img)\n","\n","        all_risk.extend(risk.cpu().numpy())\n","        all_time.extend(time)\n","        all_event.extend(event)\n","\n","        all_logits.append(treat_logits.cpu().numpy())\n","        all_labels.append(labels)\n","\n","# -------------------------\n","# Survival: C-index\n","# -------------------------\n","val_cindex = concordance_index(\n","    all_time,\n","    -np.array(all_risk),\n","    all_event\n",")\n","\n","# -------------------------\n","# Subtype: ROC-AUC + Accuracy\n","# -------------------------\n","all_logits = np.vstack(all_logits)\n","all_labels = np.concatenate(all_labels)\n","\n","probs = softmax(all_logits, axis=1)\n","\n","macro_auc = roc_auc_score(\n","    all_labels,\n","    probs,\n","    multi_class=\"ovr\",\n","    average=\"macro\"\n",")\n","\n","preds = np.argmax(probs, axis=1)\n","acc = accuracy_score(all_labels, preds)\n","\n","# -------------------------\n","# Print results\n","# -------------------------\n","print(f\"Validation C-index (survival): {val_cindex:.4f}\")\n","print(f\"Validation Macro ROC-AUC (subtype): {macro_auc:.4f}\")\n","print(f\"Validation Accuracy (subtype): {acc:.4f}\")\n"],"metadata":{"id":"GikfVyvXI9yt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Sequential Model"],"metadata":{"id":"Y_QwTBGFdHAP"}},{"cell_type":"code","source":["train_ds = SurvivalDataset(train_df, clinical_input_df)\n","train_loader = DataLoader(train_ds, batch_size=16, shuffle=True, drop_last=True)\n"],"metadata":{"id":"Tbs1H6T6lE2F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","\n","class FusionSurvOnlyModel(nn.Module):\n","    def __init__(self, clin_dim, img_dim=512):\n","        super().__init__()\n","\n","        # Clinical branch\n","        self.clin_proj = nn.Sequential(\n","            nn.Linear(clin_dim, 64),\n","            nn.BatchNorm1d(64),\n","            nn.ReLU()\n","        )\n","\n","        # Image branch\n","        self.img_proj = nn.Sequential(\n","            nn.Linear(img_dim, 64),\n","            nn.BatchNorm1d(64),\n","            nn.ReLU()\n","        )\n","\n","        # Fusion + survival head\n","        self.fusion = nn.Sequential(\n","            nn.Linear(128, 64),\n","            nn.ReLU(),\n","            nn.Linear(64, 1)\n","        )\n","\n","    def forward(self, clin, img):\n","        c = self.clin_proj(clin)\n","        i = self.img_proj(img)\n","        x = torch.cat([c, i], dim=1)\n","        risk = self.fusion(x).squeeze(-1)\n","        return risk\n"],"metadata":{"id":"6DafOHmhdGHI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def cox_ph_loss(risk, time, event):\n","    order = torch.argsort(time, descending=True)\n","    risk = torch.clamp(risk[order], -20, 20)\n","    event = event[order]\n","\n","    log_cumsum = torch.logcumsumexp(risk, dim=0)\n","    loss = -(risk - log_cumsum) * event\n","    return loss.sum() / (event.sum() + 1e-8)\n"],"metadata":{"id":"R4zP75u5dS2j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class FusionSurvOnlyModel(nn.Module):\n","    def __init__(self, clin_dim, img_dim=512):\n","        super().__init__()\n","\n","        self.clin_proj = nn.Sequential(\n","            nn.Linear(clin_dim, 128),\n","            nn.ReLU()\n","        )\n","\n","        self.img_proj = nn.Sequential(\n","            nn.Linear(img_dim, 128),\n","            nn.ReLU()\n","        )\n","\n","        self.fusion = nn.Sequential(\n","            nn.Linear(256, 128),\n","            nn.ReLU()\n","        )\n","\n","        self.surv_head = nn.Linear(128, 1)\n","\n","    def forward(self, clin, img):\n","        c = self.clin_proj(clin)\n","        i = self.img_proj(img)\n","        z = self.fusion(torch.cat([c, i], dim=1))\n","        risk = self.surv_head(z).squeeze(-1)\n","        return risk, z   # 筮 return embedding\n"],"metadata":{"id":"HAXnGg21dVY7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#final\n","clin_dim = clinical_input_df.shape[1]\n","\n","surv_model = FusionSurvOnlyModel(\n","    clin_dim=clin_dim\n",").to(device)\n","\n","opt = torch.optim.Adam(surv_model.parameters(), lr=5e-5)\n","\n","for epoch in range(15):\n","    surv_model.train()\n","    total_loss = 0\n","\n","    for b in train_loader:\n","        img = b[\"img\"].to(device)\n","        clin = b[\"clin\"].to(device)\n","        time = b[\"time\"].to(device)\n","        event = b[\"event\"].to(device)\n","\n","        risk, _ = surv_model(clin, img)\n","        loss = cox_ph_loss(risk, time, event)\n","\n","        opt.zero_grad()\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(surv_model.parameters(), 1.0)\n","        opt.step()\n","\n","        total_loss += loss.item()\n","\n","    print(f\"[Survival] Epoch {epoch+1}: loss = {total_loss/len(train_loader):.4f}\")\n"],"metadata":{"id":"xtmiuQ3mehRj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from lifelines.utils import concordance_index\n","import numpy as np\n","\n","surv_model.eval()\n","\n","all_risk = []\n","all_time = []\n","all_event = []\n","\n","with torch.no_grad():\n","    for b in val_loader:\n","        img = b[\"img\"].to(device)\n","        clin = b[\"clin\"].to(device)\n","\n","        time = b[\"time\"].cpu().numpy()\n","        event = b[\"event\"].cpu().numpy()\n","\n","        risk, _ = surv_model(clin, img)\n","\n","        all_risk.extend(risk.cpu().numpy())\n","        all_time.extend(time)\n","        all_event.extend(event)\n","\n","cindex = concordance_index(\n","    all_time,\n","    np.array(all_risk),\n","    all_event\n",")\n","\n","print(f\"Validation C-index (survival-only): {cindex:.4f}\")\n"],"metadata":{"id":"VHA4pn71p604"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for p in surv_model.parameters():\n","    p.requires_grad = False\n","\n","surv_model.eval()\n"],"metadata":{"id":"QMHLjyaIuGtB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch.nn as nn\n","\n","treatment_head = nn.Linear(128, 4).to(device)\n","opt_treat = torch.optim.Adam(treatment_head.parameters(), lr=1e-3)\n"],"metadata":{"id":"XgGXlfQTuWJ_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch.nn.functional as F\n","\n","for epoch in range(20):\n","    treatment_head.train()\n","    total_loss = 0\n","\n","    for b in train_loader:\n","        img = b[\"img\"].to(device)\n","        clin = b[\"clin\"].to(device)\n","        labels = b[\"treat_label\"].to(device)\n","\n","        # Extract frozen survival representation\n","        with torch.no_grad():\n","            _, z = surv_model(clin, img)\n","\n","        logits = treatment_head(z)\n","        loss = F.cross_entropy(logits, labels)\n","\n","        opt_treat.zero_grad()\n","        loss.backward()\n","        opt_treat.step()\n","\n","        total_loss += loss.item()\n","\n","    print(f\"[Treatment] Epoch {epoch+1}: loss = {total_loss/len(train_loader):.4f}\")\n"],"metadata":{"id":"WI1wZthhud9O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","from sklearn.metrics import roc_auc_score, accuracy_score\n","from scipy.special import softmax\n","\n","treatment_head.eval()\n","\n","all_logits = []\n","all_labels = []\n","\n","with torch.no_grad():\n","    for b in val_loader:\n","        img = b[\"img\"].to(device)\n","        clin = b[\"clin\"].to(device)\n","        labels = b[\"treat_label\"].cpu().numpy()\n","\n","        _, z = surv_model(clin, img)\n","        logits = treatment_head(z).cpu().numpy()\n","\n","        all_logits.append(logits)\n","        all_labels.append(labels)\n","\n","all_logits = np.vstack(all_logits)\n","all_labels = np.concatenate(all_labels)\n","\n","probs = softmax(all_logits, axis=1)\n","\n","macro_auc = roc_auc_score(\n","    all_labels,\n","    probs,\n","    multi_class=\"ovr\",\n","    average=\"macro\"\n",")\n","\n","preds = probs.argmax(axis=1)\n","acc = accuracy_score(all_labels, preds)\n","\n","print(f\"Treatment Macro ROC-AUC: {macro_auc:.4f}\")\n","print(f\"Treatment Accuracy: {acc:.4f}\")\n"],"metadata":{"id":"ukcZF5hIujQ9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Ablation study\n"],"metadata":{"id":"KSskV-7l52_2"}},{"cell_type":"code","source":["def cox_ph_loss(risk, time, event):\n","    order = torch.argsort(time, descending=True)\n","    risk = torch.clamp(risk[order], -20, 20)\n","    event = event[order]\n","\n","    log_cumsum = torch.logcumsumexp(risk, dim=0)\n","    loss = -(risk - log_cumsum) * event\n","\n","    return loss.sum() / (event.sum() + 1e-8)\n"],"metadata":{"id":"4SA7YBOl51nh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class ClinOnlySurv(nn.Module):\n","    def __init__(self, clin_dim):\n","        super().__init__()\n","        self.encoder = nn.Sequential(\n","            nn.Linear(clin_dim, 128),\n","            nn.ReLU()\n","        )\n","        self.head = nn.Linear(128, 1)\n","\n","    def forward(self, clin):\n","        z = self.encoder(clin)\n","        score = self.head(z).squeeze(-1)\n","        return score, z\n"],"metadata":{"id":"j42VSCOfzFp-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["clin_model = ClinOnlySurv(clin_dim=train_ds.clin.shape[1]).to(device)\n","opt = torch.optim.Adam(clin_model.parameters(), lr=5e-5)\n","\n","for epoch in range(15):\n","    clin_model.train()\n","    for b in train_loader:\n","        score, _ = clin_model(b[\"clin\"].to(device))\n","        loss = cox_ph_loss(\n","            score,\n","            b[\"time\"].to(device),\n","            b[\"event\"].to(device)\n","        )\n","\n","        opt.zero_grad()\n","        loss.backward()\n","        opt.step()\n","\n"],"metadata":{"id":"8jb8BBD1zI0M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class ImgOnlySurv(nn.Module):\n","    def __init__(self, img_dim=512):\n","        super().__init__()\n","        self.encoder = nn.Sequential(\n","            nn.Linear(img_dim, 128),\n","            nn.ReLU()\n","        )\n","        self.head = nn.Linear(128, 1)\n","\n","    def forward(self, img):\n","        z = self.encoder(img)\n","        score = self.head(z).squeeze(-1)\n","        return score, z\n"],"metadata":{"id":"TnEGakclzMVM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["img_model = ImgOnlySurv().to(device)\n","opt = torch.optim.Adam(img_model.parameters(), lr=5e-5)\n","\n","for epoch in range(15):\n","    img_model.train()\n","    for b in train_loader:\n","        score, _ = img_model(b[\"img\"].to(device))\n","        loss = cox_ph_loss(\n","            score,\n","            b[\"time\"].to(device),\n","            b[\"event\"].to(device)\n","        )\n","\n","        opt.zero_grad()\n","        loss.backward()\n","        opt.step()\n"],"metadata":{"id":"tLhy9NrUzQTW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fusion_model = FusionSurvOnlyModel(\n","    clin_dim=train_ds.clin.shape[1]\n",").to(device)\n"],"metadata":{"id":"RRDfVy0Dzf7v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from lifelines.utils import concordance_index\n","import numpy as np\n","\n","def eval_survival_robust(model, mode):\n","    model.eval()\n","    scores, times, events = [], [], []\n","\n","    with torch.no_grad():\n","        for b in val_loader:\n","            if mode == \"clin\":\n","                s, _ = model(b[\"clin\"].to(device))\n","            elif mode == \"img\":\n","                s, _ = model(b[\"img\"].to(device))\n","            else:\n","                s, _ = model(\n","                    b[\"clin\"].to(device),\n","                    b[\"img\"].to(device)\n","                )\n","\n","            scores.extend(s.cpu().numpy())\n","            times.extend(b[\"time\"].numpy())\n","            events.extend(b[\"event\"].numpy())\n","\n","    scores = np.array(scores)\n","    times = np.array(times)\n","    events = np.array(events)\n","\n","    c1 = concordance_index(times, scores, events)\n","    c2 = concordance_index(times, -scores, events)\n","\n","    return max(c1, c2), c1, c2\n"],"metadata":{"id":"uWp66EoBzWIK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Clin-only C-index:\", eval_survival_robust(clin_model, \"clin\"))\n","print(\"Img-only C-index:\", eval_survival_robust(img_model, \"img\"))\n","print(\"Fusion C-index:\", eval_survival_robust(fusion_model, \"fusion\"))\n"],"metadata":{"id":"2dp72t5pzdMQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","def train_treatment_head(get_z):\n","    head = nn.Linear(128, 4).to(device)\n","    opt = torch.optim.Adam(head.parameters(), lr=1e-3)\n","\n","    for epoch in range(20):\n","        head.train()\n","        total = 0.0\n","\n","        for b in train_loader:\n","            with torch.no_grad():\n","                z = get_z(b)          # (B, 128)\n","\n","            logits = head(z)\n","            loss = F.cross_entropy(\n","                logits,\n","                b[\"treat_label\"].to(device)\n","            )\n","\n","            opt.zero_grad()\n","            loss.backward()\n","            opt.step()\n","\n","            total += loss.item()\n","\n","        print(f\"[TREAT] Epoch {epoch+1}: {total/len(train_loader):.4f}\")\n","\n","    return head\n"],"metadata":{"id":"cP_b1yNZE2KA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["clin_treat_head = train_treatment_head(\n","    lambda b: clin_model(b[\"clin\"].to(device))[1]\n",")\n"],"metadata":{"id":"pu62BuTkE6Cg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["img_treat_head = train_treatment_head(\n","    lambda b: img_model(b[\"img\"].to(device))[1]\n",")\n"],"metadata":{"id":"DCo8mW-uE9c3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fusion_treat_head = train_treatment_head(\n","    lambda b: fusion_model(\n","        b[\"clin\"].to(device),\n","        b[\"img\"].to(device)\n","    )[1]\n",")\n"],"metadata":{"id":"UNIjXd__FEBi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","from sklearn.metrics import roc_auc_score, accuracy_score\n","from scipy.special import softmax\n","\n","def eval_treatment(get_z, head):\n","    head.eval()\n","    logits_all, labels_all = [], []\n","\n","    with torch.no_grad():\n","        for b in val_loader:\n","            z = get_z(b)\n","            logits = head(z).cpu().numpy()\n","\n","            logits_all.append(logits)\n","            labels_all.append(b[\"treat_label\"].numpy())\n","\n","    logits_all = np.vstack(logits_all)\n","    labels_all = np.concatenate(labels_all)\n","\n","    probs = softmax(logits_all, axis=1)\n","\n","    auc = roc_auc_score(\n","        labels_all,\n","        probs,\n","        multi_class=\"ovr\",\n","        average=\"macro\"\n","    )\n","    acc = accuracy_score(\n","        labels_all,\n","        probs.argmax(axis=1)\n","    )\n","\n","    return auc, acc\n"],"metadata":{"id":"XMuVYosJFJZZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Clin-only treatment:\",\n","      eval_treatment(\n","          lambda b: clin_model(b[\"clin\"].to(device))[1],\n","          clin_treat_head\n","      ))\n","\n","print(\"Img-only treatment:\",\n","      eval_treatment(\n","          lambda b: img_model(b[\"img\"].to(device))[1],\n","          img_treat_head\n","      ))\n","\n","print(\"Fusion treatment:\",\n","      eval_treatment(\n","          lambda b: fusion_model(\n","              b[\"clin\"].to(device),\n","              b[\"img\"].to(device)\n","          )[1],\n","          fusion_treat_head\n","      ))\n"],"metadata":{"id":"Ql11TVl3FNqi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import torch\n","\n","fusion_model.eval()\n","\n","Z = []\n","labels = []\n","events = []\n","\n","with torch.no_grad():\n","    for b in val_loader:\n","        clin = b[\"clin\"].to(device)\n","        img = b[\"img\"].to(device)\n","\n","        _, z = fusion_model(clin, img)\n","\n","        Z.append(z.cpu().numpy())\n","        labels.append(b[\"treat_label\"].numpy())\n","        events.append(b[\"event\"].numpy())\n","\n","Z = np.vstack(Z)              # (N, 128)\n","labels = np.concatenate(labels)\n","events = np.concatenate(events)\n","\n","print(\"Embedding shape:\", Z.shape)\n"],"metadata":{"id":"dVHvTTGQLowt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.decomposition import PCA\n","import matplotlib.pyplot as plt\n","\n","pca = PCA(n_components=2)\n","Z_pca = pca.fit_transform(Z)\n","\n","plt.figure(figsize=(6, 5))\n","sc = plt.scatter(\n","    Z_pca[:, 0],\n","    Z_pca[:, 1],\n","    c=labels,\n","    cmap=\"tab10\",\n","    s=60,\n","    alpha=0.85\n",")\n","plt.colorbar(sc, label=\"Subtype\")\n","plt.title(\"Fusion Embeddings (PCA)\")\n","plt.xlabel(\"PC1\")\n","plt.ylabel(\"PC2\")\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"id":"qXyWMYLkLs2P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install umap-learn\n"],"metadata":{"id":"IuUjJya9LwUH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import umap\n","\n","umap_model = umap.UMAP(\n","    n_neighbors=10,\n","    min_dist=0.2,\n","    n_components=2,\n","    random_state=42\n",")\n","\n","Z_umap = umap_model.fit_transform(Z)\n","\n","plt.figure(figsize=(6, 5))\n","sc = plt.scatter(\n","    Z_umap[:, 0],\n","    Z_umap[:, 1],\n","    c=labels,\n","    cmap=\"tab10\",\n","    s=60,\n","    alpha=0.85\n",")\n","plt.colorbar(sc, label=\"Subtype\")\n","plt.title(\"Fusion Embeddings (UMAP)\")\n","plt.xlabel(\"UMAP-1\")\n","plt.ylabel(\"UMAP-2\")\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"id":"rWB2O2HWL4WK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"tGHMz1x3k5SQ"},"execution_count":null,"outputs":[]}]}