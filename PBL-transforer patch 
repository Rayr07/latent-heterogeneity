{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eF4WYAF9XLv8","executionInfo":{"status":"ok","timestamp":1768132150359,"user_tz":-330,"elapsed":52670,"user":{"displayName":"Rishika Ray","userId":"02079523635456342422"}},"outputId":"8ab675c2-e04f-4ad5-8c84-22a16d260124"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hReading images from: /content/drive/MyDrive/permanent_data_folder/manifest-PyHQgfru6393647793776378\n","Saving patch features to: /content/drive/MyDrive/personalised survival treatment/ispy1_patch_features\n"]}],"source":["# 1. Setup\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","!pip install -q pydicom\n","\n","import os\n","import numpy as np\n","import pydicom\n","import torch\n","import torch.nn as nn\n","from torchvision import models, transforms\n","from tqdm import tqdm\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","\n","# 2. Define Paths (Based on your PBL-Colab PDF)\n","# Adjust these matches your exact Drive structure if different\n","ISPY_DICOM_ROOT = \"/content/drive/MyDrive/permanent_data_folder/manifest-PyHQgfru6393647793776378\"\n","OUTPUT_DIR = \"/content/drive/MyDrive/personalised survival treatment/ispy1_patch_features\"\n","\n","os.makedirs(OUTPUT_DIR, exist_ok=True)\n","print(f\"Reading images from: {ISPY_DICOM_ROOT}\")\n","print(f\"Saving patch features to: {OUTPUT_DIR}\")"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O2dT1ei_XdiG","executionInfo":{"status":"ok","timestamp":1768132151564,"user_tz":-330,"elapsed":1189,"user":{"displayName":"Rishika Ray","userId":"02079523635456342422"}},"outputId":"8a095f3a-4957-44a3-9041-03f9e2e73bf8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44.7M/44.7M [00:00<00:00, 67.1MB/s]\n"]}],"source":["# 3. Model & Transform Setup\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Load Pretrained ResNet\n","resnet = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n","resnet.fc = nn.Identity() # Remove classification layer\n","resnet = resnet.to(device).eval()\n","\n","# Transform: Resize patches to 224 for ResNet\n","patch_transform = transforms.Compose([\n","    transforms.ToPILImage(),\n","    transforms.Resize((224, 224)), # Resize small patches to ResNet input size\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","def extract_patches_from_image(image_array, patch_size=64, stride=32):\n","    \"\"\"\n","    Splits an image into overlapping patches.\n","    Returns: List of patch arrays\n","    \"\"\"\n","    patches = []\n","    h, w = image_array.shape\n","\n","    # Simple grid sliding window\n","    for y in range(0, h - patch_size + 1, stride):\n","        for x in range(0, w - patch_size + 1, stride):\n","            patch = image_array[y:y+patch_size, x:x+patch_size]\n","\n","            # Filter: Only keep patches that have actual tissue (not empty background)\n","            if patch.mean() > 0.05: # Threshold for \"not black background\"\n","                patches.append(patch)\n","\n","    return patches\n","\n","def process_patient(patient_folder_path):\n","    \"\"\"\n","    Reads DICOMs, extracts patches, returns [Num_Patches, 512] feature matrix.\n","    \"\"\"\n","    patient_patches = []\n","\n","    # 1. Walk through all DICOM files for this patient\n","    for root, dirs, files in os.walk(patient_folder_path):\n","        for file in files:\n","            if not file.endswith(\".dcm\"): continue\n","\n","            try:\n","                # Load DICOM\n","                dcm_path = os.path.join(root, file)\n","                ds = pydicom.dcmread(dcm_path)\n","\n","                if not hasattr(ds, 'pixel_array'): continue\n","                img = ds.pixel_array.astype(float)\n","\n","                # Normalize Image to 0-1\n","                img = (img - np.min(img)) / (np.max(img) - np.min(img) + 1e-6)\n","\n","                # 2. Extract Patches (e.g., 64x64 blocks)\n","                # We use the middle slice or valid slices containing tumor\n","                if np.mean(img) > 0.02: # Skip empty slices\n","                    patches = extract_patches_from_image(img, patch_size=64, stride=32)\n","\n","                    for p in patches:\n","                        # Convert 1-channel MRI patch to 3-channel (gray -> RGB)\n","                        p_3ch = np.stack([p, p, p], axis=-1)\n","                        p_3ch = (p_3ch * 255).astype(np.uint8)\n","                        patient_patches.append(p_3ch)\n","\n","            except Exception as e:\n","                continue\n","\n","    if len(patient_patches) == 0:\n","        return None\n","\n","    # 3. Batch process patches through ResNet\n","    # Stack all patches: [N, 64, 64, 3]\n","    features_list = []\n","    batch_size = 64\n","\n","    with torch.no_grad():\n","        for i in range(0, len(patient_patches), batch_size):\n","            batch_imgs = patient_patches[i : i+batch_size]\n","\n","            # Apply transforms (Resize -> Normalize)\n","            batch_tensors = torch.stack([patch_transform(img) for img in batch_imgs]).to(device)\n","\n","            # Extract Features: [Batch, 512]\n","            feats = resnet(batch_tensors)\n","            features_list.append(feats.cpu().numpy())\n","\n","    return np.concatenate(features_list, axis=0)"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"02ENH-ijYJ2F","executionInfo":{"status":"ok","timestamp":1768132151637,"user_tz":-330,"elapsed":39,"user":{"displayName":"Rishika Ray","userId":"02079523635456342422"}},"outputId":"7bde1fe9-1402-4bbc-d74e-321572ef96e6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Scanning: /content/drive/MyDrive/permanent_data_folder\n","\n","FOUND THESE FOLDERS (Copy the one that looks like 'manifest-...'):\n"," - manifest-1654812109500\n"," - manifest-PyHQgfru6393647793776378748\n"," - manifest-ISPY1\n"]}],"source":["import os\n","\n","# 1. Check if Drive is mounted\n","if not os.path.exists('/content/drive'):\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","\n","# 2. List the actual folders you have\n","parent_folder = \"/content/drive/MyDrive/permanent_data_folder\"\n","\n","print(f\"Scanning: {parent_folder}\")\n","try:\n","    items = os.listdir(parent_folder)\n","    print(\"\\nFOUND THESE FOLDERS (Copy the one that looks like 'manifest-...'):\")\n","    for item in items:\n","        print(f\" - {item}\")\n","except FileNotFoundError:\n","    print(f\"\\nERROR: The folder '{parent_folder}' does not exist either.\")\n","    print(\"Please check if 'permanent_data_folder' is spelled correctly or moved.\")"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vh-QqOi4Yp-l","executionInfo":{"status":"ok","timestamp":1768132153046,"user_tz":-330,"elapsed":1406,"user":{"displayName":"Rishika Ray","userId":"02079523635456342422"}},"outputId":"664dc58a-fb96-4151-a82a-d39258ecfbe7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Checking contents of: /content/drive/MyDrive/permanent_data_folder/manifest-PyHQgfru6393647793776378748\n","\n","ğŸ“‚ Found subfolder: 'ISPY1'\n","   -> It contains 132 items.\n","   -> First 5 examples: ['LICENSE', 'ISPY1_1049', 'ISPY1_1050', 'ISPY1_1051', 'ISPY1_1053']\n"]}],"source":["import os\n","\n","# Your current root\n","current_root = \"/content/drive/MyDrive/permanent_data_folder/manifest-PyHQgfru6393647793776378748\"\n","\n","print(f\"Checking contents of: {current_root}\")\n","items = os.listdir(current_root)\n","\n","for item in items:\n","    full_path = os.path.join(current_root, item)\n","    if os.path.isdir(full_path):\n","        print(f\"\\nğŸ“‚ Found subfolder: '{item}'\")\n","        sub_contents = os.listdir(full_path)\n","        print(f\"   -> It contains {len(sub_contents)} items.\")\n","        print(f\"   -> First 5 examples: {sub_contents[:5]}\")"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pcvfk7txXtkN","executionInfo":{"status":"ok","timestamp":1768132153059,"user_tz":-330,"elapsed":11,"user":{"displayName":"Rishika Ray","userId":"02079523635456342422"}},"outputId":"f22a708c-a9cc-48c3-a046-4b1001392fc3"},"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸ“Š Current Progress: 131 / 131 patients processed.\n","âœ… STATUS: COMPLETE! You are ready to run the Final Cross-Validation.\n"]}],"source":["import os\n","\n","# Your Folder\n","DATA_DIR = \"/content/drive/MyDrive/personalised survival treatment/ispy1_patch_features\"\n","\n","# Count\n","files = [f for f in os.listdir(DATA_DIR) if f.endswith('.npy')]\n","count = len(files)\n","\n","print(f\"ğŸ“Š Current Progress: {count} / 131 patients processed.\")\n","\n","if count >= 130:\n","    print(\"âœ… STATUS: COMPLETE! You are ready to run the Final Cross-Validation.\")\n","else:\n","    print(f\"â³ STATUS: Still processing. {131 - count} patients to go.\")"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMNJ1qNNGtoHgL1jZfNSgZE"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}