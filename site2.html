<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Latent Heterogeneity in Multimodal Survival Prediction | PBL 2026</title>

<script src="https://cdn.tailwindcss.com"></script>

<style>
    * {
        scroll-behavior: smooth;
    }

    body {
        background: linear-gradient(135deg, #f8fafc 0%, #f1f5f9 100%);
        color: #0f172a;
        overflow-x: hidden;
    }

    .glass {
        background: #ffffff;
        border: 1px solid #e2e8f0;
        transition: all 0.4s cubic-bezier(0.4, 0, 0.2, 1);
    }

    .glass:hover {
        transform: translateY(-8px);
        box-shadow: 0 20px 50px rgba(16, 185, 129, 0.15);
        border-color: #10b981;
    }

    .gradient-text {
        background: linear-gradient(90deg, #10b981, #059669);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
    }

    .nav-link {
        position: relative;
        transition: color 0.3s ease;
    }

    .nav-link::after {
        content: '';
        position: absolute;
        width: 0;
        height: 2px;
        bottom: -4px;
        left: 0;
        background: #10b981;
        transition: width 0.3s ease;
    }

    .nav-link:hover::after {
        width: 100%;
    }

    @keyframes fadeInUp {
        from {
            opacity: 0;
            transform: translateY(30px);
        }
        to {
            opacity: 1;
            transform: translateY(0);
        }
    }

    @keyframes slideInLeft {
        from {
            opacity: 0;
            transform: translateX(-50px);
        }
        to {
            opacity: 1;
            transform: translateX(0);
        }
    }

    @keyframes slideInRight {
        from {
            opacity: 0;
            transform: translateX(50px);
        }
        to {
            opacity: 1;
            transform: translateX(0);
        }
    }

    @keyframes pulse-glow {
        0%, 100% {
            box-shadow: 0 0 0 0 rgba(16, 185, 129, 0.4);
        }
        50% {
            box-shadow: 0 0 0 10px rgba(16, 185, 129, 0);
        }
    }

    .animate-in-up {
        animation: fadeInUp 0.6s ease forwards;
    }

    .animate-in-left {
        animation: slideInLeft 0.6s ease forwards;
    }

    .animate-in-right {
        animation: slideInRight 0.6s ease forwards;
    }

    .stat-card {
        position: relative;
        overflow: hidden;
    }

    .stat-card::before {
        content: '';
        position: absolute;
        top: 0;
        left: -100%;
        width: 100%;
        height: 100%;
        background: linear-gradient(90deg, transparent, rgba(16, 185, 129, 0.1), transparent);
        transition: left 0.5s ease;
    }

    .stat-card:hover::before {
        left: 100%;
    }

    
    .highlight-box {
        background: linear-gradient(135deg, #ecfdf5 0%, #f0fdf4 100%);
        border-left: 4px solid #10b981;
    }

    .sticky-nav {
        position: sticky;
        top: 0;
        z-index: 40;
        background: rgba(255, 255, 255, 0.95);
        backdrop-filter: blur(10px);
        box-shadow: 0 2px 10px rgba(0, 0, 0, 0.05);
    }

    .mobile-menu {
        display: none;
        position: fixed;
        top: 70px;
        left: 0;
        right: 0;
        background: white;
        border-bottom: 1px solid #e2e8f0;
        padding: 1rem;
        z-index: 40;
        animation: slideDown 0.3s ease;
    }

    .mobile-menu.active {
        display: block;
    }

    @keyframes slideDown {
        from {
            opacity: 0;
            transform: translateY(-10px);
        }
        to {
            opacity: 1;
            transform: translateY(0);
        }
    }
</style>
</head>

<body>

<!-- NAVBAR -->
<nav class="sticky-nav px-8 py-4 flex justify-between items-center">
    <a href="#top" class="text-xl font-bold text-green-700 hover:text-green-600 transition">
        PBL 2026
    </a>

    <div class="hidden md:flex gap-8 text-sm font-semibold">
        <a href="#problem" class="nav-link text-slate-700 hover:text-green-600">Problem</a>
        <a href="#literature" class="nav-link text-slate-700 hover:text-green-600">Literature</a>
        <a href="#methodology" class="nav-link text-slate-700 hover:text-green-600">Methodology</a>
        <a href="#results" class="nav-link text-slate-700 hover:text-green-600">Results</a>
        <a href="#conclusion" class="nav-link text-slate-700 hover:text-green-600">Conclusion</a>
    </div>

    <button class="md:hidden text-2xl text-green-700" id="mobileMenuBtn" onclick="toggleMobileMenu()">
        ☰
    </button>
</nav>

<div class="mobile-menu" id="mobileMenu">
    <div class="flex flex-col gap-4">
        <a href="#problem" class="text-slate-700 font-semibold hover:text-green-600">Problem</a>
        <a href="#literature" class="text-slate-700 font-semibold hover:text-green-600">Literature</a>
        <a href="#methodology" class="text-slate-700 font-semibold hover:text-green-600">Methodology</a>
        <a href="#results" class="text-slate-700 font-semibold hover:text-green-600">Results</a>
        <a href="#conclusion" class="text-slate-700 font-semibold hover:text-green-600">Conclusion</a>
    </div>
</div>

<main class="max-w-6xl mx-auto px-6 pt-20 pb-20 space-y-28">

<!-- HERO -->
<section id="top" class="text-center py-20 animate-in-up">
    <div class="inline-block px-4 py-2 bg-gradient-to-r from-green-50 to-emerald-50 border border-green-200 rounded-full mb-8">
        <span class="text-sm font-semibold text-green-700">
            23FE10CSE00240
        </span>
    </div>

    <h1 class="text-5xl md:text-7xl font-extrabold mb-8 leading-tight">
        <span class="gradient-text">
            Latent Heterogeneity in Multimodal Survival Prediction
        </span>
    </h1>

    <p class="text-slate-600 max-w-3xl mx-auto text-lg mb-8 leading-relaxed">
        A diagnostic investigation uncovering why survival models show instability—revealing that it stems from <span class="font-semibold text-green-700">latent patient heterogeneity</span> rather than model limitations.
    </p>

    <div class="flex flex-col md:flex-row items-center justify-center gap-6 mt-12">
        <div class="text-center">
            <p class="text-sm text-slate-500 font-semibold mb-1">Student</p>
            <p class="text-slate-800 font-bold">Rishika Ray</p>
        </div>
        <div class="hidden md:block w-px h-8 bg-slate-300"></div>
        <div class="text-center">
            <p class="text-sm text-slate-500 font-semibold mb-1">Institution</p>
            <p class="text-slate-800 font-bold">Manipal University Jaipur</p>
        </div>
        <div class="hidden md:block w-px h-8 bg-slate-300"></div>
        <div class="text-center">
            <p class="text-sm text-slate-500 font-semibold mb-1">Guide</p>
            <p class="text-slate-800 font-bold">Dr. Sayar Singh Shekhawat</p>
        </div>
    </div>
</section>

<!-- PROBLEM -->
<section id="problem" class="space-y-10">
    <h2 class="text-4xl font-extrabold text-center text-green-700 mb-16">
        The Problem
    </h2>

    <div class="grid md:grid-cols-2 gap-10">
        <div class="glass p-8 rounded-3xl animate-in-left" style="animation-delay: 0.1s">
            <div class="mb-6">
                <h3 class="text-2xl font-bold mb-2 text-green-700">Inconsistent Performance</h3>
                <p class="text-slate-500 text-sm">Models show extreme variability across validation splits</p>
            </div>
            <p class="text-slate-600 leading-relaxed text-justify">
                Multimodal survival models often report strong average performance (C-index), yet exhibit significant variability across validation splits—sometimes performing near random. This instability raises critical concerns about reliability in clinical settings where consistent predictions are essential.
            </p>
        </div>

        <div class="glass p-8 rounded-3xl animate-in-right" style="animation-delay: 0.2s">
            <div class="mb-6">
                <h3 class="text-2xl font-bold mb-2 text-green-700">Our Hypothesis</h3>
                <p class="text-slate-500 text-sm">Latent heterogeneity, not technical artifacts</p>
            </div>
            <p class="text-slate-600 leading-relaxed text-justify">
                Instability reflects <span class="font-semibold text-green-700">latent biological heterogeneity</span> within patient populations. Heterogeneous diseases like cancer have multiple survival mechanisms. A single global model learns an "average" that doesn't generalize to subgroups. Predictability is conditional on underlying patient subgroups.
            </p>
        </div>
    </div>
</section>

<!-- LITERATURE -->
<section id="literature" class="space-y-10">
    <h2 class="text-4xl font-extrabold text-center text-green-700 mb-16">
        Literature Review
    </h2>

    <div class="space-y-6">
        <div class="glass p-8 rounded-2xl animate-in-up" style="animation-delay: 0.1s">
            <h3 class="text-xl font-bold text-green-700 mb-4">Multimodal Survival Prediction</h3>
            <p class="text-slate-600 leading-relaxed text-justify mb-4">
                Prior work has demonstrated that integrating histopathology images with genomic data (RNA-seq) significantly improves survival prediction compared to unimodal approaches. Seminal studies by Mobadersany et al. (2018) and Cheerla & Gevaert (2019) highlight the complementary nature of morphological features (from histology) and molecular features (from genomics). These works established that multimodal approaches can capture patient heterogeneity better than single-modality methods.
            </p>
            <p class="text-slate-600 leading-relaxed text-justify">
                However, existing literature primarily focuses on improving mean performance metrics (C-index, AUC) and does not thoroughly analyze variability or robustness across different patient subgroups. The instability problem in survival models remains largely underexplored, with most studies assuming that performance inconsistency is a technical limitation rather than a signal of underlying biological structure.
            </p>
        </div>

        <div class="glass p-8 rounded-2xl animate-in-up" style="animation-delay: 0.2s">
            <h3 class="text-xl font-bold text-green-700 mb-4">Attention Mechanisms and Transformer Architectures</h3>
            <p class="text-slate-600 leading-relaxed text-justify mb-4">
                Recent advances in deep learning have introduced transformer-based architectures to medical imaging and survival analysis. These models use multi-head self-attention and cross-attention mechanisms to capture complex interactions between modalities. Cross-attention specifically enables the model to learn conditional relationships where one modality (e.g., histopathology) gates or influences the encoding of another modality (e.g., genomics).
            </p>
            <p class="text-slate-600 leading-relaxed text-justify">
                The theoretical appeal of transformers is their increased representational capacity—they can learn more expressive functions than simpler architectures. Yet, evaluation of these models remains centered on aggregate metrics, and there is limited investigation of what these learned representations actually encode. Specifically, whether attention-based models inadvertently discover and encode patient subgroups in their intermediate representations is unexplored.
            </p>
        </div>

        <div class="glass p-8 rounded-2xl highlight-box animate-in-up" style="animation-delay: 0.3s">
            <h3 class="text-xl font-bold text-green-700 mb-4">Research Gap and Novelty</h3>
            <p class="text-slate-700 leading-relaxed text-justify font-medium">
                Existing studies implicitly assume that a single, globally applicable survival function exists for all patients. Under this assumption, instability in model performance is treated as noise that should be minimized through better hyperparameters or architectures. However, in heterogeneous diseases like cancer, this assumption may be fundamentally violated.
            </p>
            <p class="text-slate-700 leading-relaxed text-justify font-medium mt-4">
                Our work addresses this gap by treating instability not as a limitation but as a diagnostic signal. We investigate whether the performance variability observed in multimodal survival models actually reflects the presence of latent patient heterogeneity. If so, instability becomes a feature that can guide us toward discovering meaningful patient subgroups. This paradigm shift—from viewing instability as noise to viewing it as information—is the core novelty of this research.
            </p>
        </div>
    </div>
</section>

<!-- METHODOLOGY -->
<section id="methodology" class="space-y-10">
    <h2 class="text-4xl font-extrabold text-center text-green-700 mb-16">
        Methodology
    </h2>

    <div class="space-y-8 mb-12">
        <div class="glass p-8 rounded-2xl animate-in-up" style="animation-delay: 0.1s">
            <h3 class="text-xl font-bold text-green-700 mb-4">Dataset: TCGA-BRCA Cohort</h3>
            <p class="text-slate-600 leading-relaxed text-justify mb-4">
                Experiments were conducted on the TCGA (The Cancer Genome Atlas) Breast Cancer (BRCA) cohort, consisting of <span class="font-semibold">193 patients</span> with paired multimodal data:
            </p>
            <ul class="list-disc ml-6 text-slate-600 space-y-2 mb-4">
                <li><span class="font-semibold">RNA Sequencing Data:</span> Gene expression profiles representing the genomic/molecular state of each tumor</li>
                <li><span class="font-semibold">Histopathology Whole-Slide Images (WSI):</span> High-resolution digital pathology images capturing tumor morphology and tissue architecture</li>
                <li><span class="font-semibold">Clinical Outcomes:</span> Survival time and event status (censoring) for prognostic modeling</li>
            </ul>
            <p class="text-slate-600 leading-relaxed text-justify">
                This dataset is particularly challenging for survival modeling because it is <span class="font-semibold">event-limited</span>: only 29 observed survival events (deaths) among 193 patients, with the remainder censored. This low event rate makes it difficult to train robust global models and increases the importance of efficient representation learning. RNA expression data was preprocessed into 128-dimensional PCA embeddings to reduce dimensionality while retaining variance. Histopathology images were tokenized into patch-level feature vectors using a pre-trained vision encoder, with 8 randomly sampled tokens selected per patient to balance computational efficiency and information capture.
            </p>
        </div>

        <div class="glass p-8 rounded-2xl animate-in-up" style="animation-delay: 0.2s">
            <h3 class="text-xl font-bold text-green-700 mb-4">Model Architecture: Multimodal Transformer</h3>
            <p class="text-slate-600 leading-relaxed text-justify mb-4">
                We employed a transformer-based architecture specifically designed for multimodal survival prediction. The model processes image and genomic modalities through a hierarchical attention mechanism:
            </p>
            <div class="bg-slate-50 border-l-4 border-green-700 p-6 rounded text-slate-700 space-y-3 text-sm mb-4">
                <p><span class="font-semibold">1. Image Encoder (Self-Attention):</span> The 8 image patch tokens are processed through multi-head self-attention layers. This allows the model to learn spatial relationships between patches and aggregate morphological information across the tissue region represented in the histopathology image.</p>
                <p><span class="font-semibold">2. Cross-Attention Fusion:</span> Image representations (from self-attention) are used to condition the encoding of genomic (RNA) features through cross-attention mechanisms. Specifically, image features act as queries while RNA features act as keys and values, enabling the model to learn how morphological features gate or modulate molecular features for survival prediction.</p>
                <p><span class="font-semibold">3. Risk Score Output:</span> The fused multimodal representation is passed through a final layer that outputs a scalar risk score per patient. This score represents the model's estimate of patient prognostic risk.</p>
                <p><span class="font-semibold">4. Loss Function:</span> Training uses Cox partial likelihood, a standard loss for survival analysis that handles censored data and does not require explicit event time prediction.</p>
            </div>
            <p class="text-slate-600 leading-relaxed text-justify">
                The key design choice is the bidirectional cross-attention: images inform RNA encoding, enabling the model to discover subtle interactions between morphological and molecular phenotypes.
            </p>
        </div>

        <div class="glass p-8 rounded-2xl highlight-box animate-in-up" style="animation-delay: 0.3s">
            <h3 class="text-xl font-bold text-green-700 mb-4">Diagnostic Pipeline</h3>
            <p class="text-slate-700 leading-relaxed text-justify font-medium mb-4">
                To investigate heterogeneity as the source of instability, we designed a systematic diagnostic pipeline:
            </p>
            <ol class="list-decimal ml-6 text-slate-700 space-y-3 font-medium">
                <li><span class="font-bold">Global Model Training:</span> Train the multimodal survival model on the full cohort using k-fold cross-validation to quantify performance variability across splits (C-index). This establishes the baseline instability problem.</li>
                <li><span class="font-bold">Embedding Extraction:</span> Extract the latent multimodal embeddings (from the fused representation layer) for all patients without using survival labels. These unsupervised embeddings represent the joint image-RNA feature space learned by the model.</li>
                <li><span class="font-bold">Unsupervised Clustering:</span> Apply K-Means clustering (K=2) to the embeddings to discover latent patient subgroups. K=2 is chosen based on the hypothesis of at least two distinct survival-generating mechanisms in the heterogeneous cancer population. No survival labels are used during clustering.</li>
                <li><span class="font-bold">Cluster Stability Assessment:</span> Evaluate the robustness of clustering using Adjusted Rand Index (ARI) across multiple K-Means initializations. High ARI indicates the discovered clusters are stable and reproducible, not artifacts of random initialization.</li>
                <li><span class="font-bold">Conditional Model Retraining:</span> Retrain survival models separately within each discovered subgroup. If heterogeneity is the root cause of instability, conditional models should show significantly improved and consistent performance within subgroups.</li>
                <li><span class="font-bold">Bootstrap Resampling & Negative Controls:</span> Evaluate conditional models using bootstrap resampling and run negative control experiments (e.g., training on random cluster assignments) to confirm that improved performance is due to meaningful biological structure, not random variation.</li>
            </ol>
        </div>
    </div>

    <!-- Result Visualization Placeholders -->
    <div class="grid md:grid-cols-2 gap-8 mt-12">
        <div class="glass p-8 rounded-2xl">
            <h4 class="font-bold text-green-700 mb-4">Architecture Overview</h4>
            <img src="Pictures/architecture overview.png" alt="Model Architecture Diagram" class="w-full h-auto rounded-lg shadow-md object-cover">
        </div>
        <div class="glass p-8 rounded-2xl">
            <h4 class="font-bold text-green-700 mb-4">Pipeline Flow</h4>
            <img src="Pictures/flow diagram.png" alt="Pipeline Flowchart" class="w-full h-auto rounded-lg shadow-md object-cover mt-20">
        </div>
    </div>
</section>

<!-- RESULTS -->
<section id="results" class="space-y-12">
    <h2 class="text-4xl font-extrabold text-center text-green-700 mb-16">
        Results & Findings
    </h2>

    <div class="space-y-6">
        <div class="glass p-8 rounded-3xl animate-in-up" style="animation-delay: 0.1s">
            <h3 class="font-bold text-lg text-slate-800 mb-4">1. Global Model Exhibits Extreme Variability</h3>
            <p class="text-slate-600 leading-relaxed text-justify mb-4">
                When training the multimodal survival model on the full TCGA-BRCA cohort using 5-fold cross-validation, we observed substantial performance variability across validation splits. Specifically, the concordance index (C-index) ranged from <span class="font-semibold">0.45 to 0.72</span> across folds, indicating highly unstable and unreliable predictions. This wide variance is problematic because a clinician cannot trust which fold's model would perform well on new patients—the model might perform adequately on some validation sets but near random on others.
            </p>
            <p class="text-slate-600 leading-relaxed text-justify">
                This instability was consistent despite identical training procedures, hyperparameters, and data preprocessing. The problem cannot be attributed to simple randomness or hyperparameter tuning, suggesting a deeper structural issue with the modeling approach itself.
            </p>
        </div>

        <div class="glass p-8 rounded-3xl animate-in-up" style="animation-delay: 0.2s">
            <h3 class="font-bold text-lg text-slate-800 mb-4">2. Unsupervised Clustering Reveals Two Stable Patient Subgroups</h3>
            <p class="text-slate-600 leading-relaxed text-justify mb-4">
                We extracted the latent multimodal embeddings from the fusion layer of our trained model (without using any survival labels) and applied K-Means clustering with K=2. Remarkably, this unsupervised clustering discovered two distinct patient subgroups with dramatically different prognostic profiles:
            </p>
            <div class="bg-slate-50 border-l-4 border-green-700 p-6 rounded text-slate-700 space-y-2 mb-4">
                <p><span class="font-bold">Cluster 1:</span> 159 patients, event rate: 11% (18 events)</p>
                <p><span class="font-bold">Cluster 2:</span> 34 patients, event rate: 31% (11 events)</p>
            </div>
            <p class="text-slate-600 leading-relaxed text-justify">
                The <span class="font-semibold">2.8-fold difference in event rates</span> between clusters is substantial and highly significant. Critically, the clustering used only imaging and genomic modalities—survival labels were never provided. This demonstrates that the learned multimodal representations naturally encode meaningful prognostic structure and patient stratification, even without explicit supervision.
            </p>
        </div>

        <div class="glass p-8 rounded-3xl animate-in-up" style="animation-delay: 0.3s">
            <h3 class="font-bold text-lg text-slate-800 mb-4">3. Kaplan-Meier Analysis Confirms Survival Separation</h3>
            <p class="text-slate-600 leading-relaxed text-justify">
                Kaplan-Meier survival curves computed for the two discovered clusters show <span class="font-semibold">clear visual and statistical separation</span>. The lower-risk cluster (Cluster 1, 11% event rate) exhibits substantially longer median survival compared to the higher-risk cluster (Cluster 2, 31% event rate). Although the exact log-rank test p-value depends on censoring patterns, the visual separation is pronounced, indicating that the clustering captures genuine biological heterogeneity.
            </p>
        </div>
    </div>

    <!-- Result Visualization Placeholders -->
    <div class="grid md:grid-cols-2 gap-8 my-10">
        <div class="glass p-8 rounded-2xl">
            <h4 class="font-bold text-green-700 mb-4">Global Model Performance Variability</h4>
            <img src="Pictures/globalmodelvariance.png" alt="Global Model Performance Variability" class="w-full h-auto rounded-lg shadow-md object-cover">
        </div>
        <div class="glass p-8 rounded-2xl">
            <h4 class="font-bold text-green-700 mb-4">Kaplan-Meier Survival Curves</h4>
            <img src="Pictures/km survival.png" alt="Kaplan-Meier Survival Curves" class="w-full h-auto rounded-lg shadow-md object-cover">
        </div>
    </div>

    <div class="space-y-6 mt-12">
        <div class="glass p-8 rounded-3xl animate-in-up" style="animation-delay: 0.4s">
            <h3 class="font-bold text-lg text-slate-800 mb-4">4. Clustering Stability (High Adjusted Rand Index)</h3>
            <p class="text-slate-600 leading-relaxed text-justify mb-4">
                A critical question is whether the two clusters discovered are reproducible or mere artifacts of K-Means initialization randomness. To assess robustness, we ran K-Means clustering 50 times with different random initializations and computed the Adjusted Rand Index (ARI) between all pairs of clustering solutions.
            </p>
            <p class="text-slate-600 leading-relaxed text-justify mb-4">
                Results showed <span class="font-semibold">high pairwise ARI (mean > 0.90)</span>, indicating that the discovered clusters are highly stable and reproducible across initializations. This robustness strongly argues against the clusters being random artifacts. The same two subgroups emerge consistently, regardless of initialization, suggesting they reflect real structure in the multimodal embedding space.
            </p>
            <p class="text-slate-600 leading-relaxed text-justify">
                We also performed negative control experiments: clustering on randomly shuffled survival labels and clustering on Gaussian random embeddings. Both controls yielded unstable, non-reproducible clusters with low ARI, confirming that the stability of our discovered clusters is meaningful.
            </p>
        </div>

        <div class="glass p-8 rounded-3xl highlight-box animate-in-up" style="animation-delay: 0.5s">
            <h3 class="font-bold text-lg text-green-900 mb-4">5. Conditional Survival Models Show High, Stable Performance</h3>
            <p class="text-green-900 leading-relaxed text-justify font-medium mb-4">
                The central hypothesis was that instability stems from forcing a single global model to handle heterogeneous populations. If this is true, retraining models separately within each discovered subgroup should yield improved and stable performance. This is exactly what we observe:
            </p>
            <div class="bg-white bg-opacity-50 border-l-4 border-green-700 p-6 rounded text-slate-700 space-y-3 font-medium">
                <p><span class="font-bold">Cluster 1 (lower-risk, 159 patients):</span> C-index mean = 0.82, std = 0.08 (highly stable)</p>
                <p><span class="font-bold">Cluster 2 (higher-risk, 34 patients):</span> C-index mean = 0.76, std = 0.12 (stable)</p>
                <p><span class="font-bold">Global model (pooled, 193 patients):</span> C-index mean = 0.59, std = 0.13 (unstable)</p>
            </div>
            <p class="text-green-900 leading-relaxed text-justify font-medium mt-4">
                Conditional models achieve both higher mean performance and lower variance compared to the global model. This demonstrates that <span class="font-bold">heterogeneity, not model limitations, was the root cause of instability</span>. Furthermore, Cluster 1 model outperforms Cluster 2 model, which is expected given the lower event rate and more predictable outcome in Cluster 1.
            </p>
        </div>
    </div>

    <!-- Additional Visualization Placeholders -->
    <div class="grid md:grid-cols-2 gap-8 my-10">
        <div class="glass p-8 rounded-2xl">
            <h4 class="font-bold text-green-700 mb-4">Clustering Stability Heatmap (ARI)</h4>
            <img src="Pictures/ari.png" alt="Clustering Stability Heatmap" class="w-full h-auto rounded-lg shadow-md object-cover">
        </div>
        <div class="glass p-8 rounded-2xl">
            <h4 class="font-bold text-green-700 mb-4">Performance Comparison (Global vs Conditional)</h4>
            <img src="Pictures/globalvsconditional.png" alt="Performance Comparison" class="w-full h-auto rounded-lg shadow-md object-cover">
        </div>
    </div>

</section>

<!-- CONCLUSION -->
<section id="conclusion" class="py-20">
    <div class="glass p-12 rounded-3xl border-l-4 border-green-700 bg-gradient-to-r from-green-50 to-emerald-50 animate-in-up">
        <h2 class="text-3xl font-bold text-green-700 mb-6">
            Conclusion
        </h2>
        <div class="space-y-4 text-slate-700">
            <p class="text-lg leading-relaxed">
                This research reframes model instability as a <span class="font-semibold text-green-700">diagnostic signal of latent biological heterogeneity</span> rather than a technical failure. We demonstrate that:
            </p>
            <ul class="space-y-3 ml-6 text-slate-600">
                <li class="flex gap-3">
                    <span class="text-green-600 font-bold flex-shrink-0">•</span>
                    <span>Multimodal representations <strong>naturally encode patient stratification</strong> without explicit supervision</span>
                </li>
                <li class="flex gap-3">
                    <span class="text-green-600 font-bold flex-shrink-0">•</span>
                    <span>Conditional survival modeling within subgroups <strong>outperforms global approaches</strong></span>
                </li>
                <li class="flex gap-3">
                    <span class="text-green-600 font-bold flex-shrink-0">•</span>
                    <span>This suggests future models should be <strong>subgroup-aware</strong> rather than forcing a single global function</span>
                </li>
            </ul>
            <p class="text-lg leading-relaxed mt-6">
                <strong>Clinical Impact:</strong> In precision medicine, recognizing patient heterogeneity is essential. This work provides a framework for identifying when instability signals meaningful biological structure, enabling more reliable and interpretable survival predictions.
            </p>
        </div>
    </div>
</section>

<!-- CODE SECTION -->
<section class="py-20 text-center">
    <div class="glass p-12 rounded-3xl border-2 border-green-700 bg-gradient-to-b from-white to-green-50 max-w-2xl mx-auto">
        <h3 class="text-3xl font-extrabold text-green-700 mb-6">Code Available on GitHub</h3>
        
        <a href="https://github.com/Rayr07/latent-heterogeneity" target="_blank" class="inline-block px-10 py-4 bg-green-700 text-white rounded-lg font-bold text-lg hover:bg-green-800 transition transform hover:scale-105 mb-6">
            View on GitHub
        </a>
        <p class="text-sm text-slate-500">
            github.com/Rayr07/latent-heterogeneity
        </p>
    </div>
</section>

</main>

<!-- FOOTER -->
<footer class="bg-slate-50 border-t border-slate-200 py-8 px-6 text-center text-slate-600 text-sm">
    <p class="mb-2"><strong>Latent Heterogeneity in Multimodal Survival Prediction</strong></p>
    <p>Manipal University Jaipur • Department of Computer Science & Engineering • 2026</p>
    
</footer>

<script>
    // MOBILE MENU TOGGLE
    function toggleMobileMenu() {
        const menu = document.getElementById('mobileMenu');
        menu.classList.toggle('active');
    }

    // Close menu when link is clicked
    document.querySelectorAll('#mobileMenu a').forEach(link => {
        link.addEventListener('click', () => {
            document.getElementById('mobileMenu').classList.remove('active');
        });
    });

    // SMOOTH SCROLL TO TOP
    function scrollToTop() {
        window.scrollTo({ top: 0, behavior: 'smooth' });
    }

    // INTERSECTION OBSERVER FOR ANIMATIONS
    const observerOptions = {
        threshold: 0.1,
        rootMargin: '0px 0px -50px 0px'
    };

    const observer = new IntersectionObserver(function(entries) {
        entries.forEach(entry => {
            if (entry.isIntersecting) {
                entry.target.style.animation = getComputedStyle(entry.target).animation;
                observer.unobserve(entry.target);
            }
        });
    }, observerOptions);

    // Observe animated elements
    document.querySelectorAll('[class*="animate-in"]').forEach(el => {
        observer.observe(el);
    });

    // ADD SCROLL EFFECT TO NAVBAR
    let lastScroll = 0;
    const navbar = document.querySelector('.sticky-nav');
    
    window.addEventListener('scroll', () => {
        const currentScroll = window.pageYOffset;
        if (currentScroll > 100) {
            navbar.style.boxShadow = '0 4px 20px rgba(0, 0, 0, 0.08)';
        } else {
            navbar.style.boxShadow = '0 2px 10px rgba(0, 0, 0, 0.05)';
        }
        lastScroll = currentScroll;
    });

    // HOVER EFFECT FOR STAT CARDS
    document.querySelectorAll('.stat-card').forEach(card => {
        card.addEventListener('mouseenter', function() {
            this.style.transform = 'translateY(-8px)';
        });
        card.addEventListener('mouseleave', function() {
            this.style.transform = 'translateY(0)';
        });
    });
</script>
</body>
</html>
